This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: kernel/**/*, vm/**/*, web/**/*
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
kernel/
  .cargo/
    config.toml
  src/
    allocator.rs
    main.rs
    uart.rs
  build.rs
  Cargo.toml
  link.x
  memory.x
vm/
  src/
    bus.rs
    clint.rs
    console.rs
    cpu.rs
    csr.rs
    decoder.rs
    dram.rs
    emulator.rs
    lib.rs
    main.rs
    mmu.rs
    plic.rs
    uart.rs
    virtio.rs
  Cargo.toml
web/
  public/
    custom_kernel
    file.svg
    fs.img
    globe.svg
    kernel
    next.svg
    riscv_vm_bg.wasm
    vercel.svg
    window.svg
  src/
    app/
      favicon.ico
      globals.css
      layout.tsx
      page.tsx
    hooks/
      useVM.ts
  .gitignore
  .yarnrc.yml
  eslint.config.mjs
  next.config.ts
  package.json
  postcss.config.mjs
  README.md
  tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="vm/src/clint.rs">
pub const CLINT_BASE: u64 = 0x0200_0000;
pub const CLINT_SIZE: u64 = 0x10000;

pub const MSIP_OFFSET: u64 = 0x0000;
pub const MTIME_OFFSET: u64 = 0xbff8;
pub const MTIMECMP_OFFSET: u64 = 0x4000;

pub const MAX_HARTS: usize = 8;

/// Time increment per CPU step (in timer ticks).
/// At 10MHz and ~1 instruction per cycle at ~10MHz CPU, this gives roughly real-time.
/// Adjust for desired timer granularity.
const MTIME_INCREMENT: u64 = 1;

pub struct Clint {
    pub msip: [u32; MAX_HARTS],
    pub mtimecmp: [u64; MAX_HARTS],
    /// Machine timer counter. Incremented by `tick()` each CPU step.
    pub mtime: u64,
    pub debug: bool,
}

impl Clint {
    pub fn new() -> Self {
        Self {
            msip: [0; MAX_HARTS],
            mtimecmp: [u64::MAX; MAX_HARTS], 
            mtime: 0,
            debug: false,
        }
    }

    /// Returns the current mtime value.
    pub fn mtime(&self) -> u64 {
        self.mtime
    }

    /// Sets mtime to a specific value (used for snapshot restore).
    pub fn set_mtime(&mut self, val: u64) {
        self.mtime = val;
    }

    /// Advance mtime by one tick. Called once per CPU step.
    pub fn tick(&mut self) {
        self.mtime = self.mtime.wrapping_add(MTIME_INCREMENT);
    }

    /// Backward compatibility: increment is now tick()
    pub fn increment(&mut self) {
        self.tick();
    }

    pub fn sync_time_micros(&mut self, _micros: u64) {
        // No-op for deterministic timer
    }

    /// Load from the CLINT register space.
    ///
    /// Offsets are relative to `CLINT_BASE`. Only naturally aligned 4- and
    /// 8-byte accesses are architecturally meaningful; other sizes return 0.
    pub fn load(&self, offset: u64, size: u64) -> u64 {
        match (offset, size) {
            // MSIP[hart], 32-bit
            (o, 4) if o >= MSIP_OFFSET && o < MSIP_OFFSET + (MAX_HARTS as u64 * 4) => {
                let hart_idx = ((o - MSIP_OFFSET) / 4) as usize;
                self.msip[hart_idx] as u64
            }

            // MTIME, 64-bit
            (MTIME_OFFSET, 8) => self.mtime(),
            // MTIME, low/high 32-bit words
            (MTIME_OFFSET, 4) => self.mtime() & 0xffff_ffff,
            (o, 4) if o == MTIME_OFFSET + 4 => self.mtime() >> 32,

            // MTIMECMP[hart], 64-bit and split 32-bit accesses
            (o, 8) if o >= MTIMECMP_OFFSET && o < MTIMECMP_OFFSET + (MAX_HARTS as u64 * 8) => {
                let hart_idx = ((o - MTIMECMP_OFFSET) / 8) as usize;
                self.mtimecmp[hart_idx]
            }
            (o, 4) if o >= MTIMECMP_OFFSET && o < MTIMECMP_OFFSET + (MAX_HARTS as u64 * 8) => {
                let hart_idx = ((o - MTIMECMP_OFFSET) / 8) as usize;
                let sub = (o - MTIMECMP_OFFSET) % 8;
                let val = self.mtimecmp[hart_idx];
                match sub {
                    0 => val & 0xffff_ffff,
                    4 => val >> 32,
                    _ => 0,
                }
            }

            // Other offsets/sizes are reserved -> read as zero.
            _ => 0,
        }
    }

    /// Store into the CLINT register space.
    ///
    /// Offsets are relative to `CLINT_BASE`. Mis-sized or strange offsets are
    /// ignored to keep the device side-effect free for unsupported accesses.
    pub fn store(&mut self, offset: u64, size: u64, value: u64) {
        match (offset, size) {
            // MSIP[hart], 32-bit
            (o, 4) if o >= MSIP_OFFSET && o < MSIP_OFFSET + (MAX_HARTS as u64 * 4) => {
                let hart_idx = ((o - MSIP_OFFSET) / 4) as usize;
                // Only the LSB matters for MSIP
                self.msip[hart_idx] = (value & 1) as u32;
            }

            // MTIME is read-only in this implementation (driven by wall clock)
            (MTIME_OFFSET, _) => {}
            (o, 4) if o == MTIME_OFFSET + 4 => {}

            // MTIMECMP[hart], 64-bit and split 32-bit writes
            (o, 8) if o >= MTIMECMP_OFFSET && o < MTIMECMP_OFFSET + (MAX_HARTS as u64 * 8) => {
                let hart_idx = ((o - MTIMECMP_OFFSET) / 8) as usize;
                self.mtimecmp[hart_idx] = value;
            }
            (o, 4) if o >= MTIMECMP_OFFSET && o < MTIMECMP_OFFSET + (MAX_HARTS as u64 * 8) => {
                let hart_idx = ((o - MTIMECMP_OFFSET) / 8) as usize;
                let sub = (o - MTIMECMP_OFFSET) % 8;
                let current = self.mtimecmp[hart_idx];
                self.mtimecmp[hart_idx] = match sub {
                    0 => (current & 0xffff_ffff_0000_0000) | (value & 0xffff_ffff),
                    4 => (current & 0x0000_0000_ffff_ffff) | (value << 32),
                    _ => current,
                };
            }

            _ => {}
        }
    }
}
</file>

<file path="vm/src/csr.rs">
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum Mode {
    User,
    Supervisor,
    Machine,
}

impl Mode {
    /// Encode privilege mode into the MPP/SPP field encoding.
    pub fn to_mpp(self) -> u64 {
        match self {
            Mode::User => 0b00,
            Mode::Supervisor => 0b01,
            Mode::Machine => 0b11,
        }
    }

    /// Decode MPP/SPP field into a privilege mode.
    pub fn from_mpp(bits: u64) -> Mode {
        match bits & 0b11 {
            0b00 => Mode::User,
            0b01 => Mode::Supervisor,
            // 0b10 is reserved; treat as Machine for WARL coercion.
            _ => Mode::Machine,
        }
    }
}

// Common CSR addresses used by the privileged architecture.
pub const CSR_SATP: u16 = 0x180;

pub const CSR_MSTATUS: u16 = 0x300;
pub const CSR_MISA: u16 = 0x301;
pub const CSR_MEDELEG: u16 = 0x302;
pub const CSR_MIDELEG: u16 = 0x303;
pub const CSR_MIE: u16 = 0x304;
pub const CSR_MTVEC: u16 = 0x305;

pub const CSR_MEPC: u16 = 0x341;
pub const CSR_MCAUSE: u16 = 0x342;
pub const CSR_MTVAL: u16 = 0x343;
pub const CSR_MIP: u16 = 0x344;

// Supervisor CSRs
pub const CSR_SSTATUS: u16 = 0x100;
pub const CSR_SIE: u16 = 0x104;
pub const CSR_STVEC: u16 = 0x105;
pub const CSR_SSCRATCH: u16 = 0x140;
pub const CSR_SEPC: u16 = 0x141;
pub const CSR_SCAUSE: u16 = 0x142;
pub const CSR_STVAL: u16 = 0x143;
pub const CSR_SIP: u16 = 0x144;

// Additional CSRs used by xv6 and Sstc
pub const CSR_TIME: u16 = 0xC01;      // time (read-only)
pub const CSR_MENVCFG: u16 = 0x30A;   // menvcfg (for Sstc enable bit 63)
pub const CSR_STIMECMP: u16 = 0x14D;  // stimecmp (Sstc)
pub const CSR_MCOUNTEREN: u16 = 0x306;

// Machine Information Registers (read-only)
pub const CSR_MVENDORID: u16 = 0xF11;  // Vendor ID
pub const CSR_MARCHID: u16 = 0xF12;    // Architecture ID
pub const CSR_MIMPID: u16 = 0xF13;     // Implementation ID
pub const CSR_MHARTID: u16 = 0xF14;    // Hardware thread ID
</file>

<file path="vm/src/decoder.rs">
use crate::Trap;

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum Register {
    X0,
    X1,
    X2,
    X3,
    X4,
    X5,
    X6,
    X7,
    X8,
    X9,
    X10,
    X11,
    X12,
    X13,
    X14,
    X15,
    X16,
    X17,
    X18,
    X19,
    X20,
    X21,
    X22,
    X23,
    X24,
    X25,
    X26,
    X27,
    X28,
    X29,
    X30,
    X31,
}

impl Register {
    pub fn from_u32(v: u32) -> Self {
        match v & 0x1F {
            0 => Register::X0,
            1 => Register::X1,
            2 => Register::X2,
            3 => Register::X3,
            4 => Register::X4,
            5 => Register::X5,
            6 => Register::X6,
            7 => Register::X7,
            8 => Register::X8,
            9 => Register::X9,
            10 => Register::X10,
            11 => Register::X11,
            12 => Register::X12,
            13 => Register::X13,
            14 => Register::X14,
            15 => Register::X15,
            16 => Register::X16,
            17 => Register::X17,
            18 => Register::X18,
            19 => Register::X19,
            20 => Register::X20,
            21 => Register::X21,
            22 => Register::X22,
            23 => Register::X23,
            24 => Register::X24,
            25 => Register::X25,
            26 => Register::X26,
            27 => Register::X27,
            28 => Register::X28,
            29 => Register::X29,
            30 => Register::X30,
            31 => Register::X31,
            _ => unreachable!(),
        }
    }

    pub fn to_usize(&self) -> usize {
        *self as usize
    }
}

#[derive(Debug, Clone, PartialEq)]
pub enum Op {
    Lui {
        rd: Register,
        imm: i64,
    },
    Auipc {
        rd: Register,
        imm: i64,
    },
    Jal {
        rd: Register,
        imm: i64,
    },
    Jalr {
        rd: Register,
        rs1: Register,
        imm: i64,
    },
    Branch {
        rs1: Register,
        rs2: Register,
        imm: i64,
        funct3: u32,
    },
    Load {
        rd: Register,
        rs1: Register,
        imm: i64,
        funct3: u32,
    },
    Store {
        rs1: Register,
        rs2: Register,
        imm: i64,
        funct3: u32,
    },
    OpImm {
        rd: Register,
        rs1: Register,
        imm: i64,
        funct3: u32,
        funct7: u32,
    }, // I-type ALU (ADDI etc)
    Op {
        rd: Register,
        rs1: Register,
        rs2: Register,
        funct3: u32,
        funct7: u32,
    }, // R-type ALU
    OpImm32 {
        rd: Register,
        rs1: Register,
        imm: i64,
        funct3: u32,
        funct7: u32,
    }, // ADDIW etc
    Op32 {
        rd: Register,
        rs1: Register,
        rs2: Register,
        funct3: u32,
        funct7: u32,
    }, // ADDW etc
    System {
        rd: Register,
        rs1: Register,
        funct3: u32,
        imm: u32,
    }, // CSRs / Ecall (imm used for csr addr usually)
    Amo {
        rd: Register,
        rs1: Register,
        rs2: Register,
        funct3: u32,
        funct5: u32,
        aq: bool,
        rl: bool,
    }, // RV64A atomics (LR/SC/AMO*)
    Fence, // FENCE / FENCE.I
}

pub fn decode(insn: u32) -> Result<Op, Trap> {
    let opcode = insn & 0x7F;
    let rd = Register::from_u32((insn >> 7) & 0x1F);
    let funct3 = (insn >> 12) & 0x7;
    let rs1 = Register::from_u32((insn >> 15) & 0x1F);
    let rs2 = Register::from_u32((insn >> 20) & 0x1F);
    let funct7 = (insn >> 25) & 0x7F;

    // Sign extension helpers
    let imm_i = ((insn as i32) >> 20) as i64;
    let imm_s = (((insn as i32) >> 25) << 5) as i64 | (((insn >> 7) & 0x1F) as i64);
    // B-type: imm[12|10:5|4:1|11]
    let imm_b = {
        let bit31 = (insn >> 31) & 1;
        let bit30_25 = (insn >> 25) & 0x3F;
        let bit11_8 = (insn >> 8) & 0xF;
        let bit7 = (insn >> 7) & 1;
        let val = (bit31 << 12) | (bit7 << 11) | (bit30_25 << 5) | (bit11_8 << 1);
        // Sign extend from bit 12
        ((val as i32) << 19 >> 19) as i64
    };
    // U-type: imm[31:12]
    let imm_u = ((insn as i32) & 0xFFFFF000u32 as i32) as i64;
    // J-type: imm[20|10:1|11|19:12]
    let imm_j = {
        let bit31 = (insn >> 31) & 1;
        let bit30_21 = (insn >> 21) & 0x3FF;
        let bit20 = (insn >> 20) & 1;
        let bit19_12 = (insn >> 12) & 0xFF;
        let val = (bit31 << 20) | (bit19_12 << 12) | (bit20 << 11) | (bit30_21 << 1);
        ((val as i32) << 11 >> 11) as i64
    };

    match opcode {
        0x37 => Ok(Op::Lui { rd, imm: imm_u }),
        0x17 => Ok(Op::Auipc { rd, imm: imm_u }),
        0x6F => Ok(Op::Jal { rd, imm: imm_j }),
        0x67 => Ok(Op::Jalr {
            rd,
            rs1,
            imm: imm_i,
        }),
        0x63 => Ok(Op::Branch {
            rs1,
            rs2,
            imm: imm_b,
            funct3,
        }),
        0x03 => Ok(Op::Load {
            rd,
            rs1,
            imm: imm_i,
            funct3,
        }),
        0x23 => Ok(Op::Store {
            rs1,
            rs2,
            imm: imm_s,
            funct3,
        }),
        0x13 => Ok(Op::OpImm {
            rd,
            rs1,
            imm: imm_i,
            funct3,
            funct7,
        }),
        0x33 => Ok(Op::Op {
            rd,
            rs1,
            rs2,
            funct3,
            funct7,
        }),
        0x1B => Ok(Op::OpImm32 {
            rd,
            rs1,
            imm: imm_i,
            funct3,
            funct7,
        }),
        0x3B => Ok(Op::Op32 {
            rd,
            rs1,
            rs2,
            funct3,
            funct7,
        }),
        0x2F => {
            // A-extension (atomics)
            let funct5 = (insn >> 27) & 0x1F;
            let aq = ((insn >> 26) & 1) != 0;
            let rl = ((insn >> 25) & 1) != 0;
            Ok(Op::Amo {
                rd,
                rs1,
                rs2,
                funct3,
                funct5,
                aq,
                rl,
            })
        }
        0x73 => {
            let i_imm = (insn >> 20) & 0xFFF;
            Ok(Op::System {
                rd,
                rs1,
                funct3,
                imm: i_imm,
            })
        }
        0x0F => Ok(Op::Fence),

        _ => Err(Trap::IllegalInstruction(insn as u64)),
    }
}

// -------- Compressed (C) extension expansion ---------------------------------
//
// These helpers expand 16-bit compressed instructions into canonical 32-bit
// encodings, which are then fed through the normal `decode()` function.

fn encode_i(imm: i32, rs1: u32, funct3: u32, rd: u32, opcode: u32) -> u32 {
    let imm12 = (imm as u32) & 0xFFF;
    (imm12 << 20) | (rs1 << 15) | (funct3 << 12) | (rd << 7) | opcode
}

fn encode_u(imm: i32, rd: u32, opcode: u32) -> u32 {
    // U-type: imm[31:12] in bits[31:12], low 12 bits zero.
    let imm20 = ((imm as u32) >> 12) & 0xFFFFF;
    (imm20 << 12) | (rd << 7) | opcode
}

fn encode_r(funct7: u32, rs2: u32, rs1: u32, funct3: u32, rd: u32, opcode: u32) -> u32 {
    (funct7 << 25) | (rs2 << 20) | (rs1 << 15) | (funct3 << 12) | (rd << 7) | opcode
}

fn encode_s(imm: i32, rs2: u32, rs1: u32, funct3: u32, opcode: u32) -> u32 {
    let imm12 = (imm as u32) & 0xFFF;
    let imm11_5 = (imm12 >> 5) & 0x7F;
    let imm4_0 = imm12 & 0x1F;
    (imm11_5 << 25)
        | (rs2 << 20)
        | (rs1 << 15)
        | (funct3 << 12)
        | (imm4_0 << 7)
        | opcode
}

fn encode_j(imm: i32, rd: u32) -> u32 {
    // J-type immediate, imm is already the signed byte offset.
    let imm20 = ((imm >> 20) & 0x1) as u32;
    let imm10_1 = ((imm >> 1) & 0x3FF) as u32;
    let imm11 = ((imm >> 11) & 0x1) as u32;
    let imm19_12 = ((imm >> 12) & 0xFF) as u32;
    (imm20 << 31) | (imm19_12 << 12) | (imm11 << 20) | (imm10_1 << 21) | (rd << 7) | 0x6F
}

fn encode_b(imm: i32, rs2: u32, rs1: u32, funct3: u32, opcode: u32) -> u32 {
    // B-type immediate, imm is signed byte offset (multiple of 2).
    let imm13 = (imm as u32) & 0x1FFF;
    let imm12 = (imm13 >> 12) & 0x1;
    let imm10_5 = (imm13 >> 5) & 0x3F;
    let imm4_1 = (imm13 >> 1) & 0xF;
    let imm11 = (imm13 >> 11) & 0x1;
    (imm12 << 31)
        | (imm10_5 << 25)
        | (rs2 << 20)
        | (rs1 << 15)
        | (funct3 << 12)
        | (imm4_1 << 8)
        | (imm11 << 7)
        | opcode
}

fn sext(value: u32, bits: u8) -> i32 {
    let shift = 32 - bits as i32;
    ((value << shift) as i32) >> shift
}

pub fn expand_compressed(insn: u16) -> Result<u32, Trap> {
    let opcode = insn & 0x3;
    let funct3 = (insn >> 13) & 0x7;

    match opcode {
        0b00 => expand_q0(insn, funct3),
        0b01 => expand_q1(insn, funct3),
        0b10 => expand_q2(insn, funct3),
        _ => Err(Trap::IllegalInstruction(insn as u64)),
    }
}

fn expand_q0(insn: u16, funct3: u16) -> Result<u32, Trap> {
    let insn_u = insn as u32;
    match funct3 {
        // C.ADDI4SPN -> ADDI rd', x2, nzuimm
        0b000 => {
            let nzuimm = (((insn_u >> 6) & 0x1) << 2)
                | (((insn_u >> 5) & 0x1) << 3)
                | (((insn_u >> 11) & 0x3) << 4)
                | (((insn_u >> 7) & 0xF) << 6);
            if nzuimm == 0 {
                return Err(Trap::IllegalInstruction(insn as u64));
            }
            let rd_prime = 8 + ((insn_u >> 2) & 0x7);
            Ok(encode_i(nzuimm as i32, 2, 0x0, rd_prime, 0x13))
        }
        // C.LW -> LW rd', uimm(rs1')
        0b010 => {
            let uimm =
                (((insn_u >> 6) & 0x1) << 2) | (((insn_u >> 10) & 0x7) << 3) | (((insn_u >> 5) & 0x1) << 6);
            let rd_prime = 8 + ((insn_u >> 2) & 0x7);
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            Ok(encode_i(uimm as i32, rs1_prime, 0x2, rd_prime, 0x03))
        }
        // C.LD -> LD rd', uimm(rs1')
        0b011 => {
            let uimm = (((insn_u >> 10) & 0x7) << 3) | (((insn_u >> 5) & 0x3) << 6);
            let rd_prime = 8 + ((insn_u >> 2) & 0x7);
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            Ok(encode_i(uimm as i32, rs1_prime, 0x3, rd_prime, 0x03))
        }
        // C.SW -> SW rs2', uimm(rs1')
        0b110 => {
            let uimm =
                (((insn_u >> 6) & 0x1) << 2) | (((insn_u >> 10) & 0x7) << 3) | (((insn_u >> 5) & 0x1) << 6);
            let rs2_prime = 8 + ((insn_u >> 2) & 0x7);
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            Ok(encode_s(uimm as i32, rs2_prime, rs1_prime, 0x2, 0x23))
        }
        // C.SD -> SD rs2', uimm(rs1')
        0b111 => {
            let uimm = (((insn_u >> 10) & 0x7) << 3) | (((insn_u >> 5) & 0x3) << 6);
            let rs2_prime = 8 + ((insn_u >> 2) & 0x7);
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            Ok(encode_s(uimm as i32, rs2_prime, rs1_prime, 0x3, 0x23))
        }
        _ => Err(Trap::IllegalInstruction(insn as u64)),
    }
}

fn expand_q1(insn: u16, funct3: u16) -> Result<u32, Trap> {
    let insn_u = insn as u32;
    match funct3 {
        // C.NOP / C.ADDI
        0b000 => {
            let rd = (insn_u >> 7) & 0x1F;
            let imm_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
            let imm = sext(imm_bits, 6);
            if rd == 0 {
                if imm == 0 {
                    // C.NOP
                    return Ok(encode_i(0, 0, 0x0, 0, 0x13));
                } else {
                    return Err(Trap::IllegalInstruction(insn as u64));
                }
            }
            Ok(encode_i(imm, rd, 0x0, rd, 0x13)) // ADDI rd, rd, imm
        }
        // RV64: C.ADDIW
        0b001 => {
            let rd = (insn_u >> 7) & 0x1F;
            let imm_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
            let imm = sext(imm_bits, 6);
            if rd == 0 {
                return Err(Trap::IllegalInstruction(insn as u64));
            }
            Ok(encode_i(imm, rd, 0x0, rd, 0x1B)) // ADDIW rd, rd, imm
        }
        // C.LI -> ADDI rd, x0, imm
        0b010 => {
            let rd = (insn_u >> 7) & 0x1F;
            let imm_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
            let imm = sext(imm_bits, 6);
            if rd == 0 {
                return Err(Trap::IllegalInstruction(insn as u64));
            }
            Ok(encode_i(imm, 0, 0x0, rd, 0x13))
        }
        // C.ADDI16SP / C.LUI
        0b011 => {
            let rd = (insn_u >> 7) & 0x1F;
            if rd == 2 {
                // C.ADDI16SP
                let mut nz = 0u32;
                nz |= ((insn_u >> 12) & 0x1) << 9;
                nz |= ((insn_u >> 3) & 0x3) << 7;
                nz |= ((insn_u >> 5) & 0x1) << 6;
                nz |= ((insn_u >> 2) & 0x1) << 5;
                nz |= ((insn_u >> 6) & 0x1) << 4;
                if nz == 0 {
                    return Err(Trap::IllegalInstruction(insn as u64));
                }
                let imm = sext(nz, 10);
                Ok(encode_i(imm, 2, 0x0, 2, 0x13)) // ADDI x2,x2,imm
            } else {
                // C.LUI -> LUI rd, imm
                let imm_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
                if rd == 0 || imm_bits == 0 {
                    return Err(Trap::IllegalInstruction(insn as u64));
                }
                let imm = sext(imm_bits, 6);
                Ok(encode_u(imm << 12, rd, 0x37))
            }
        }
        // C.SRLI / C.SRAI / C.ANDI / C.SUB/XOR/OR/AND
        0b100 => {
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            let rs2_prime = 8 + ((insn_u >> 2) & 0x7);
            let op = (insn_u >> 10) & 0x3;
            match op {
                // C.SRLI
                0b00 => {
                    let shamt_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
                    let shamt = shamt_bits & 0x3F; // RV64: 6-bit shamt
                    Ok(encode_i(shamt as i32, rs1_prime, 0x5, rs1_prime, 0x13)) // SRLI
                }
                // C.SRAI
                0b01 => {
                    let shamt_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
                    let shamt = shamt_bits & 0x3F;
                    // SRAI encoding: funct7=0b0100000, funct3=101
                    Ok(encode_i((0x20 << 6) | (shamt as i32), rs1_prime, 0x5, rs1_prime, 0x13))
                }
                // C.ANDI
                0b10 => {
                    let imm_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
                    let imm = sext(imm_bits, 6);
                    Ok(encode_i(imm, rs1_prime, 0x7, rs1_prime, 0x13))
                }
                // C.SUB / C.XOR / C.OR / C.AND (bit12=0) or C.SUBW / C.ADDW (bit12=1, RV64)
                0b11 => {
                    let bit12 = (insn_u >> 12) & 0x1;
                    let funct2 = (insn_u >> 5) & 0x3;
                    
                    if bit12 == 0 {
                        // C.SUB / C.XOR / C.OR / C.AND -> R-type with opcode 0x33
                        let (funct3, funct7) = match funct2 {
                            0b00 => (0x0, 0x20), // SUB
                            0b01 => (0x4, 0x00), // XOR
                            0b10 => (0x6, 0x00), // OR
                            0b11 => (0x7, 0x00), // AND
                            _ => unreachable!(),
                        };
                        Ok(
                            (funct7 << 25)
                                | (rs2_prime << 20)
                                | (rs1_prime << 15)
                                | (funct3 << 12)
                                | (rs1_prime << 7)
                                | 0x33,
                        )
                    } else {
                        // RV64C: C.SUBW / C.ADDW -> R-type with opcode 0x3B (Op32)
                        match funct2 {
                            0b00 => {
                                // C.SUBW -> SUBW rd', rd', rs2'
                                Ok(encode_r(0x20, rs2_prime, rs1_prime, 0x0, rs1_prime, 0x3B))
                            }
                            0b01 => {
                                // C.ADDW -> ADDW rd', rd', rs2'
                                Ok(encode_r(0x00, rs2_prime, rs1_prime, 0x0, rs1_prime, 0x3B))
                            }
                            // funct2 = 0b10, 0b11 are reserved in RV64C
                            _ => Err(Trap::IllegalInstruction(insn as u64)),
                        }
                    }
                }
                _ => Err(Trap::IllegalInstruction(insn as u64)),
            }
        }
        // C.J (unconditional jump)
        0b101 => {
            // C.J immediate: imm[11|4|9:8|10|6|7|3:1|5] with bit 0 implicitly 0
            let mut off = 0u32;
            off |= ((insn_u >> 12) & 0x1) << 11;
            off |= ((insn_u >> 11) & 0x1) << 4;
            off |= ((insn_u >> 9) & 0x3) << 8;
            off |= ((insn_u >> 8) & 0x1) << 10;
            off |= ((insn_u >> 7) & 0x1) << 6;
            off |= ((insn_u >> 6) & 0x1) << 7;
            off |= ((insn_u >> 3) & 0x7) << 1;
            off |= ((insn_u >> 2) & 0x1) << 5;
            // off already has bit 0 = 0 implicitly; sign-extend from bit 11
            let imm = sext(off, 12);
            Ok(encode_j(imm, 0)) // JAL x0, imm
        }
        // C.BEQZ
        0b110 => {
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            // C.BEQZ immediate: imm[8|4:3|7:6|2:1|5] with bit 0 implicitly 0
            let mut off = 0u32;
            off |= ((insn_u >> 12) & 0x1) << 8;
            off |= ((insn_u >> 10) & 0x3) << 3;
            off |= ((insn_u >> 5) & 0x3) << 6;
            off |= ((insn_u >> 3) & 0x3) << 1;
            off |= ((insn_u >> 2) & 0x1) << 5;
            // off already has bit 0 = 0 implicitly; sign-extend from bit 8
            let imm = sext(off, 9);
            Ok(encode_b(imm, 0, rs1_prime, 0x0, 0x63)) // BEQ rs1', x0, imm
        }
        // C.BNEZ
        0b111 => {
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            // C.BNEZ immediate: imm[8|4:3|7:6|2:1|5] with bit 0 implicitly 0
            let mut off = 0u32;
            off |= ((insn_u >> 12) & 0x1) << 8;
            off |= ((insn_u >> 10) & 0x3) << 3;
            off |= ((insn_u >> 5) & 0x3) << 6;
            off |= ((insn_u >> 3) & 0x3) << 1;
            off |= ((insn_u >> 2) & 0x1) << 5;
            // off already has bit 0 = 0 implicitly; sign-extend from bit 8
            let imm = sext(off, 9);
            Ok(encode_b(imm, 0, rs1_prime, 0x1, 0x63)) // BNE rs1', x0, imm
        }
        _ => Err(Trap::IllegalInstruction(insn as u64)),
    }
}

fn expand_q2(insn: u16, funct3: u16) -> Result<u32, Trap> {
    let insn_u = insn as u32;
    match funct3 {
        // C.SLLI
        0b000 => {
            let rd = (insn_u >> 7) & 0x1F;
            let imm_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
            let imm = imm_bits & 0x3F; // RV64: 6-bit shamt
            if rd == 0 {
                return Err(Trap::IllegalInstruction(insn as u64));
            }
            Ok(encode_i(imm as i32, rd, 0x1, rd, 0x13))
        }
        // C.LWSP
        0b010 => {
            let rd = (insn_u >> 7) & 0x1F;
            if rd == 0 {
                return Err(Trap::IllegalInstruction(insn as u64));
            }
            let uimm = (((insn_u >> 4) & 0x7) << 2)
                | (((insn_u >> 12) & 0x1) << 5)
                | (((insn_u >> 2) & 0x3) << 6);
            Ok(encode_i(uimm as i32, 2, 0x2, rd, 0x03))
        }
        // C.LDSP: LD rd, uimm(sp) - uimm[5|4:3|8:6] scaled by 8
        0b011 => {
            let rd = (insn_u >> 7) & 0x1F;
            if rd == 0 {
                return Err(Trap::IllegalInstruction(insn as u64));
            }
            // bit 12 -> uimm[5], bits [6:5] -> uimm[4:3], bits [4:2] -> uimm[8:6]
            let uimm = (((insn_u >> 12) & 0x1) << 5)
                | (((insn_u >> 5) & 0x3) << 3)
                | (((insn_u >> 2) & 0x7) << 6);
            Ok(encode_i(uimm as i32, 2, 0x3, rd, 0x03))
        }
        // C.JR / C.MV / C.EBREAK / C.JALR / C.ADD
        0b100 => {
            let rd = (insn_u >> 7) & 0x1F;
            let rs2 = (insn_u >> 2) & 0x1F;
            let bit12 = (insn_u >> 12) & 0x1;
            match (bit12, rs2, rd) {
                // C.JR: rs2=0, bit12=0, rd!=0
                (0, 0, rd) if rd != 0 => {
                    Ok(encode_i(0, rd, 0x0, 0, 0x67)) // JALR x0, rd, 0
                }
                // C.MV: bit12=0, rs2!=0, rd!=0
                (0, rs2, rd) if rs2 != 0 && rd != 0 => {
                    Ok(encode_r(0x00, rs2, 0, 0x0, rd, 0x33)) // ADD rd, x0, rs2
                }
                // C.EBREAK: bit12=1, rd=0, rs2=0
                (1, 0, 0) => Ok(0x0010_0073),
                // C.JALR: bit12=1, rs2=0, rd!=0
                (1, 0, rd) if rd != 0 => {
                    Ok(encode_i(0, rd, 0x0, 1, 0x67)) // JALR x1, rd, 0
                }
                // C.ADD: bit12=1, rs2!=0, rd!=0
                (1, rs2, rd) if rs2 != 0 && rd != 0 => {
                    Ok(encode_r(0x00, rs2, rd, 0x0, rd, 0x33)) // ADD rd, rd, rs2
                }
                _ => Err(Trap::IllegalInstruction(insn as u64)),
            }
        }
        // C.SWSP: SW rs2, uimm(sp) - uimm[5:2|7:6] scaled by 4
        0b110 => {
            let rs2 = (insn_u >> 2) & 0x1F;
            // bits [12:9] -> uimm[5:2], bits [8:7] -> uimm[7:6]
            let uimm = (((insn_u >> 9) & 0xF) << 2) | (((insn_u >> 7) & 0x3) << 6);
            Ok(encode_s(uimm as i32, rs2, 2, 0x2, 0x23))
        }
        // C.SDSP: SD rs2, uimm(sp) - uimm[5:3|8:6] scaled by 8
        0b111 => {
            let rs2 = (insn_u >> 2) & 0x1F;
            // bits [12:10] -> uimm[5:3], bits [9:7] -> uimm[8:6]
            let uimm = (((insn_u >> 10) & 0x7) << 3) | (((insn_u >> 7) & 0x7) << 6);
            Ok(encode_s(uimm as i32, rs2, 2, 0x3, 0x23))
        }
        _ => Err(Trap::IllegalInstruction(insn as u64)),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn decode_lui_and_jal() {
        // LUI x2, 0x12345
        let lui_insn: u32 = 0x12345137;
        let op = decode(lui_insn).unwrap();
        match op {
            Op::Lui { rd, imm } => {
                assert_eq!(rd, Register::X2);
                assert_eq!(imm, 0x0000_0000_1234_5000);
            }
            _ => panic!("Expected LUI op"),
        }

        // JAL x1, 8 (matches cpu::tests::test_jal)
        let jal_insn: u32 = (4 << 21) | (1 << 7) | 0x6F;
        let op = decode(jal_insn).unwrap();
        match op {
            Op::Jal { rd, imm } => {
                assert_eq!(rd, Register::X1);
                assert_eq!(imm, 8);
            }
            _ => panic!("Expected JAL op"),
        }
    }

    #[test]
    fn decode_illegal_opcode() {
        // Opcode with bits[6:0] not matching any valid RV64I opcode we implement.
        let bad: u32 = 0x0000_0000;
        let res = decode(bad);
        match res {
            Err(Trap::IllegalInstruction(bits)) => assert_eq!(bits, bad as u64),
            _ => panic!("Expected IllegalInstruction trap"),
        }
    }

    #[test]
    fn expand_compressed_basic_integer_ops() {
        // These 16-bit encodings come from assembling with rv64imac:
        //   addi x8, x2, 16          # C.ADDI4SPN
        //   addi x11,x11,1           # C.ADDI
        //   addiw x12,x12,1          # C.ADDIW
        //   addi x13,x0,-1           # C.LI
        //   addi x2, x2, 16          # C.ADDI16SP
        //   lui  x14,1               # C.LUI
        let c_addi4spn: u16 = 0x0800;
        let c_addi: u16 = 0x0585;
        let c_addiw: u16 = 0x2605;
        let c_li: u16 = 0x56FD;
        let c_addi16sp: u16 = 0x0141;
        let c_lui: u16 = 0x6705;

        // C.ADDI4SPN -> ADDI x8, x2, 16
        let op = decode(expand_compressed(c_addi4spn).unwrap()).unwrap();
        match op {
            Op::OpImm { rd, rs1, imm, funct3, .. } => {
                assert_eq!(rd, Register::X8);
                assert_eq!(rs1, Register::X2);
                assert_eq!(imm, 16);
                assert_eq!(funct3, 0);
            }
            _ => panic!("Expected OpImm from C.ADDI4SPN"),
        }

        // C.ADDI -> ADDI x11, x11, 1
        let op = decode(expand_compressed(c_addi).unwrap()).unwrap();
        match op {
            Op::OpImm { rd, rs1, imm, .. } => {
                assert_eq!(rd, Register::X11);
                assert_eq!(rs1, Register::X11);
                assert_eq!(imm, 1);
            }
            _ => panic!("Expected OpImm from C.ADDI"),
        }

        // C.ADDIW -> ADDIW x12, x12, 1
        let op = decode(expand_compressed(c_addiw).unwrap()).unwrap();
        match op {
            Op::OpImm32 { rd, rs1, imm, .. } => {
                assert_eq!(rd, Register::X12);
                assert_eq!(rs1, Register::X12);
                assert_eq!(imm, 1);
            }
            _ => panic!("Expected OpImm32 from C.ADDIW"),
        }

        // C.LI -> ADDI x13, x0, -1
        let op = decode(expand_compressed(c_li).unwrap()).unwrap();
        match op {
            Op::OpImm { rd, rs1, imm, .. } => {
                assert_eq!(rd, Register::X13);
                assert_eq!(rs1, Register::X0);
                assert_eq!(imm, -1);
            }
            _ => panic!("Expected OpImm from C.LI"),
        }

        // C.ADDI16SP -> ADDI x2, x2, 16
        let op = decode(expand_compressed(c_addi16sp).unwrap()).unwrap();
        match op {
            Op::OpImm { rd, rs1, imm, .. } => {
                assert_eq!(rd, Register::X2);
                assert_eq!(rs1, Register::X2);
                assert_eq!(imm, 16);
            }
            _ => panic!("Expected OpImm from C.ADDI16SP"),
        }

        // C.LUI -> LUI x14, 1
        let op = decode(expand_compressed(c_lui).unwrap()).unwrap();
        match op {
            Op::Lui { rd, imm } => {
                assert_eq!(rd, Register::X14);
                assert_eq!(imm, 0x0000_0000_0000_1000);
            }
            _ => panic!("Expected Lui from C.LUI"),
        }
    }
}
</file>

<file path="vm/src/emulator.rs">
use crate::bus::{SystemBus, DRAM_BASE};
use crate::cpu::Cpu;
use crate::Trap;
use goblin::elf::{program_header::PT_LOAD, Elf};
use std::fs::File;
use std::io::{Read, Write};
use std::path::Path;

use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use std::collections::HashMap;

/// Default DRAM size used when constructing an [`Emulator`] via [`Emulator::new`].
///
/// This is large enough for riscv-arch-test binaries and small kernels, while
/// still being reasonably light for host machines.
const DEFAULT_DRAM_MIB: usize = 128;

/// Default size of the signature region when only a base address is provided.
///
/// RISCOF test signatures are typically small; 4 KiB is a conservative
/// default and can be overridden via [`Emulator::set_signature_region`].
const DEFAULT_SIGNATURE_SIZE: u64 = 4 * 1024;

/// High-level emulator wrapper used by test harnesses (e.g. RISCOF backend).
///
/// This mirrors the sketch in `phase-6.md`:
///
/// ```ignore
/// let mut emu = Emulator::new();
/// emu.load_elf("test.elf")?;
/// emu.set_signature_addr(0x8001_0000);
/// while !emu.trapped() { emu.step()?; }
/// let sig = emu.read_signature()?;
/// ```
pub struct Emulator {
    /// CPU core (GPRs, CSRs, privilege mode, TLB, etc).
    pub cpu: Cpu,
    /// System bus with DRAM and all memory-mapped devices.
    pub bus: SystemBus,

    signature_addr: Option<u64>,
    signature_size: u64,

    trapped: bool,
    last_trap: Option<Trap>,

    /// Optional UART output callback invoked once per transmitted byte.
    ///
    /// This provides a deterministic, buffered integration point for hosts
    /// (CLI, web UI, tests) without requiring them to poll the UART FIFO.
    uart_callback: Option<Box<dyn FnMut(u8) + 'static>>,
}

impl Emulator {
    /// Create a new emulator instance with the default DRAM size and reset PC.
    ///
    /// The reset PC is initialised to the DRAM base (0x8000_0000) but will be
    /// overwritten by [`load_elf`] when an ELF image is loaded.
    pub fn new() -> Self {
        Self::with_memory(DEFAULT_DRAM_MIB * 1024 * 1024)
    }

    /// Create a new emulator instance with an explicit DRAM size in bytes.
    pub fn with_memory(dram_size_bytes: usize) -> Self {
        let dram_base = DRAM_BASE;
        let bus = SystemBus::new(dram_base, dram_size_bytes);
        let cpu = Cpu::new(dram_base);

        Self {
            cpu,
            bus,
            signature_addr: None,
            signature_size: 0,
            trapped: false,
            last_trap: None,
            uart_callback: None,
        }
    }

    /// Returns `true` once execution has terminated due to a trap or
    /// an explicit host-level stop condition.
    pub fn trapped(&self) -> bool {
        self.trapped
    }

    /// Returns the last architectural trap observed, if any.
    pub fn last_trap(&self) -> Option<&Trap> {
        self.last_trap.as_ref()
    }

    /// Register a UART output callback.
    ///
    /// The callback is invoked from [`step`] for each byte emitted by the
    /// emulated NS16550A UART. Hosts that prefer pull-based I/O can ignore
    /// this and call [`drain_uart_output`] instead.
    pub fn set_uart_callback<F>(&mut self, cb: F)
    where
        F: FnMut(u8) + 'static,
    {
        self.uart_callback = Some(Box::new(cb));
    }

    /// Push a single input byte into the UART RX FIFO.
    ///
    /// This models a host keystroke or serial input event in a buffered,
    /// deterministic way: given the same sequence of calls and instruction
    /// stream, the guest will see identical input ordering.
    pub fn push_key(&mut self, byte: u8) {
        self.bus.uart.push_input(byte);
    }

    /// Drain all pending UART output bytes into a vector.
    ///
    /// This is useful for tests or hosts that do not wish to use the callback
    /// interface.
    pub fn drain_uart_output(&mut self) -> Vec<u8> {
        let mut out = Vec::new();
        while let Some(b) = self.bus.uart.pop_output() {
            out.push(b);
        }
        out
    }

    /// Execute a single instruction.
    ///
    /// On success, returns `Ok(())`. On architectural traps, this records the
    /// trap in [`last_trap`] and sets [`trapped`] before returning `Err(trap)`.
    pub fn step(&mut self) -> Result<(), Trap> {
        match self.cpu.step(&mut self.bus) {
            Ok(()) => {
                // Deliver UART bytes to host callback if registered.
                if let Some(cb) = self.uart_callback.as_mut() {
                    while let Some(byte) = self.bus.uart.pop_output() {
                        cb(byte);
                    }
                }

                Ok(())
            }
            Err(trap) => {
                self.trapped = true;
                self.last_trap = Some(trap.clone());
                Err(trap)
            }
        }
    }

    /// Load an ELF image from disk into DRAM and update the CPU's PC to the
    /// ELF entry point.
    ///
    /// Returns the resolved entry PC on success.
    pub fn load_elf<P: AsRef<Path>>(
        &mut self,
        path: P,
    ) -> Result<u64, Box<dyn std::error::Error>> {
        let mut file = File::open(path)?;
        let mut buffer = Vec::new();
        file.read_to_end(&mut buffer)?;

        let entry_pc = load_elf_into_dram(&buffer, &mut self.bus)?;
        self.cpu.pc = entry_pc;
        Ok(entry_pc)
    }

    /// Configure the signature region used by `read_signature`.
    ///
    /// - `base` is the physical start address of the signature buffer.
    /// - `size` is the number of bytes to read.
    pub fn set_signature_region(&mut self, base: u64, size: u64) {
        self.signature_addr = Some(base);
        self.signature_size = size;
    }

    /// Convenience helper matching the `phase-6.md` sketch.
    ///
    /// This sets the base address and uses a default size of 4 KiB unless a
    /// region size has already been configured via [`set_signature_region`].
    pub fn set_signature_addr(&mut self, base: u64) {
        self.signature_addr = Some(base);
        if self.signature_size == 0 {
            self.signature_size = DEFAULT_SIGNATURE_SIZE;
        }
    }

    /// Read the configured signature region from DRAM.
    ///
    /// Returns an owned `Vec<u8>` which callers can hex-encode or compare
    /// against reference signatures.
    pub fn read_signature(&self) -> Result<Vec<u8>, String> {
        let base = self
            .signature_addr
            .ok_or_else(|| "signature address not configured".to_string())?;
        if self.signature_size == 0 {
            return Err("signature size is zero; call set_signature_region first".to_string());
        }

        let dram_base = self.bus.dram_base();
        let dram_size = self.bus.dram_size() as u64;

        if base < dram_base || base >= dram_base + dram_size {
            return Err(format!(
                "signature base 0x{base:016x} lies outside DRAM (0x{dram_base:016x}..0x{:016x})",
                dram_base + dram_size
            ));
        }

        let offset = (base - dram_base) as usize;
        let end = offset
            .checked_add(self.signature_size as usize)
            .ok_or_else(|| "signature range overflow".to_string())?;

        if end > self.bus.dram_size() {
            return Err("signature range extends beyond DRAM".to_string());
        }

        // SAFETY: bounds checked above.
        Ok(self.bus.dram.data[offset..end].to_vec())
    }
}

const SNAPSHOT_VERSION: &str = "2.0";

/// Serializable CPU state used in snapshots.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CpuSnapshot {
    pub pc: u64,
    pub mode: crate::csr::Mode,
    pub regs: [u64; 32],
    pub csrs: HashMap<u16, u64>,
}

/// Serializable CLINT state.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClintSnapshot {
    pub msip: [u32; crate::clint::MAX_HARTS],
    pub mtime: u64,
    pub mtimecmp: [u64; crate::clint::MAX_HARTS],
}

/// Serializable PLIC state.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PlicSnapshot {
    pub priority: Vec<u32>,
    pub pending: u32,
    pub enable: Vec<u32>,
    pub threshold: Vec<u32>,
    pub active: Vec<u32>,
}

/// Serializable UART state.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UartSnapshot {
    pub rx_fifo: Vec<u8>,
    pub tx_fifo: Vec<u8>,
    pub ier: u8,
    pub iir: u8,
    pub fcr: u8,
    pub lcr: u8,
    pub mcr: u8,
    pub lsr: u8,
    pub msr: u8,
    pub scr: u8,
    pub dll: u8,
    pub dlm: u8,
}

/// Serializable device state bundle.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeviceSnapshot {
    pub clint: ClintSnapshot,
    pub plic: PlicSnapshot,
    pub uart: UartSnapshot,
}

/// Memory region snapshot (currently we only snapshot DRAM as a single region).
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemRegionSnapshot {
    pub base: u64,
    pub size: u64,
    pub hash: String,
    pub data: Option<Vec<u8>>,
}

/// Full emulator snapshot including CPU, devices and DRAM.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Snapshot {
    pub version: String,
    pub cpu: CpuSnapshot,
    pub devices: DeviceSnapshot,
    pub memory: Vec<MemRegionSnapshot>,
}

impl Emulator {
    /// Capture a complete, deterministic snapshot of the current emulator state.
    pub fn snapshot(&self) -> Snapshot {
        let cpu = CpuSnapshot {
            pc: self.cpu.pc,
            mode: self.cpu.mode,
            regs: self.cpu.regs,
            csrs: self.cpu.export_csrs(),
        };

        let clint = ClintSnapshot {
            msip: self.bus.clint.msip,
            mtime: self.bus.clint.mtime,
            mtimecmp: self.bus.clint.mtimecmp,
        };

        let plic = PlicSnapshot {
            priority: self.bus.plic.priority.to_vec(),
            pending: self.bus.plic.pending,
            enable: self.bus.plic.enable.to_vec(),
            threshold: self.bus.plic.threshold.to_vec(),
            active: self.bus.plic.active.to_vec(),
        };

        let uart = UartSnapshot {
            rx_fifo: self.bus.uart.input.iter().copied().collect(),
            tx_fifo: self.bus.uart.output.iter().copied().collect(),
            ier: self.bus.uart.ier,
            iir: self.bus.uart.iir,
            fcr: self.bus.uart.fcr,
            lcr: self.bus.uart.lcr,
            mcr: self.bus.uart.mcr,
            lsr: self.bus.uart.lsr,
            msr: self.bus.uart.msr,
            scr: self.bus.uart.scr,
            dll: self.bus.uart.dll,
            dlm: self.bus.uart.dlm,
        };

        let mut hasher = Sha256::new();
        hasher.update(&self.bus.dram.data);
        let hash = hex::encode(hasher.finalize());

        let region = MemRegionSnapshot {
            base: self.bus.dram.base,
            size: self.bus.dram.data.len() as u64,
            hash,
            data: Some(self.bus.dram.data.clone()),
        };

        Snapshot {
            version: SNAPSHOT_VERSION.to_string(),
            cpu,
            devices: DeviceSnapshot { clint, plic, uart },
            memory: vec![region],
        }
    }

    /// Restore emulator state from a previously captured snapshot.
    pub fn apply_snapshot(&mut self, snapshot: &Snapshot) -> Result<(), String> {
        if snapshot.version != SNAPSHOT_VERSION {
            return Err(format!(
                "snapshot version mismatch: expected {}, found {}",
                SNAPSHOT_VERSION, snapshot.version
            ));
        }

        // Restore CPU core.
        self.cpu.pc = snapshot.cpu.pc;
        self.cpu.mode = snapshot.cpu.mode;
        self.cpu.regs = snapshot.cpu.regs;
        self.cpu.import_csrs(&snapshot.cpu.csrs);
        self.trapped = false;
        self.last_trap = None;

        // Restore CLINT.
        self.bus.clint.msip = snapshot.devices.clint.msip;
        self.bus.clint.set_mtime(snapshot.devices.clint.mtime);
        self.bus.clint.mtimecmp = snapshot.devices.clint.mtimecmp;

        // Restore PLIC (truncate if snapshot has more sources/contexts).
        for (i, &val) in snapshot.devices.plic.priority.iter().enumerate() {
            if i < self.bus.plic.priority.len() {
                self.bus.plic.priority[i] = val;
            }
        }
        self.bus.plic.pending = snapshot.devices.plic.pending;
        for (i, &val) in snapshot.devices.plic.enable.iter().enumerate() {
            if i < self.bus.plic.enable.len() {
                self.bus.plic.enable[i] = val;
            }
        }
        for (i, &val) in snapshot.devices.plic.threshold.iter().enumerate() {
            if i < self.bus.plic.threshold.len() {
                self.bus.plic.threshold[i] = val;
            }
        }
        for (i, &val) in snapshot.devices.plic.active.iter().enumerate() {
            if i < self.bus.plic.active.len() {
                self.bus.plic.active[i] = val;
            }
        }

        // Restore UART.
        self.bus.uart.input.clear();
        self.bus.uart.input.extend(snapshot.devices.uart.rx_fifo.iter().copied());
        self.bus.uart.output.clear();
        self.bus.uart.output.extend(snapshot.devices.uart.tx_fifo.iter().copied());
        self.bus.uart.ier = snapshot.devices.uart.ier;
        self.bus.uart.iir = snapshot.devices.uart.iir;
        self.bus.uart.fcr = snapshot.devices.uart.fcr;
        self.bus.uart.lcr = snapshot.devices.uart.lcr;
        self.bus.uart.mcr = snapshot.devices.uart.mcr;
        self.bus.uart.lsr = snapshot.devices.uart.lsr;
        self.bus.uart.msr = snapshot.devices.uart.msr;
        self.bus.uart.scr = snapshot.devices.uart.scr;
        self.bus.uart.dll = snapshot.devices.uart.dll;
        self.bus.uart.dlm = snapshot.devices.uart.dlm;
        self.bus.uart.update_interrupts();

        // Restore DRAM.
        let region = snapshot
            .memory
            .get(0)
            .ok_or_else(|| "snapshot missing primary memory region".to_string())?;

        let data = region
            .data
            .as_ref()
            .ok_or_else(|| "snapshot memory region has no inline data".to_string())?;

        if self.bus.dram.base != region.base {
            return Err(format!(
                "snapshot DRAM base mismatch: emulator=0x{:x}, snapshot=0x{:x}",
                self.bus.dram.base, region.base
            ));
        }
        if self.bus.dram.data.len() != data.len() {
            return Err(format!(
                "snapshot DRAM size mismatch: emulator={} bytes, snapshot={} bytes",
                self.bus.dram.data.len(),
                data.len()
            ));
        }

        let mut hasher = Sha256::new();
        hasher.update(data);
        let current_hash = hex::encode(hasher.finalize());
        if current_hash != region.hash {
            return Err(format!(
                "snapshot DRAM hash mismatch for base 0x{:x}",
                region.base
            ));
        }

        self.bus.dram.data.clone_from_slice(data);

        Ok(())
    }

    /// Construct a new emulator instance from a snapshot.
    pub fn from_snapshot(snapshot: Snapshot) -> Result<Self, String> {
        let region = snapshot
            .memory
            .get(0)
            .ok_or_else(|| "snapshot missing primary memory region".to_string())?;
        let dram_size = region
            .size
            .try_into()
            .map_err(|_| "snapshot DRAM size does not fit in usize".to_string())?;

        let mut emu = Emulator::with_memory(dram_size);
        emu.apply_snapshot(&snapshot)?;
        Ok(emu)
    }

    /// Save a snapshot to disk using bincode.
    pub fn save_snapshot_to_path<P: AsRef<Path>>(
        &self,
        path: P,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let snap = self.snapshot();
        let mut file = File::create(path)?;
        bincode::serialize_into(&mut file, &snap)?;
        file.flush()?;
        Ok(())
    }

    /// Load a snapshot from disk and construct a new emulator instance.
    pub fn load_snapshot_from_path<P: AsRef<Path>>(
        path: P,
    ) -> Result<Self, Box<dyn std::error::Error>> {
        let mut file = File::open(path)?;
        let snapshot: Snapshot = bincode::deserialize_from(&mut file)?;
        let emu = Emulator::from_snapshot(snapshot)
            .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;
        Ok(emu)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::bus::Bus;

    #[test]
    fn snapshot_roundtrip_preserves_state() {
        let mut emu = Emulator::with_memory(1024 * 1024);

        // Simple CPU state.
        emu.cpu.pc = DRAM_BASE + 0x1000;
        emu.cpu.write_reg(crate::decoder::Register::X5, 0xdead_beef_dead_beef);

        // Touch DRAM and devices.
        let addr = emu.bus.dram_base() + 0x80;
        emu.bus.write64(addr, 0x0123_4567_89ab_cdef).unwrap();
        emu.bus.clint.mtime = 1234;
        emu.bus.clint.mtimecmp[0] = 5678;
        emu.bus.uart.push_input(b'A');

        let snap = emu.snapshot();
        let bytes = bincode::serialize(&snap).unwrap();
        let snap2: Snapshot = bincode::deserialize(&bytes).unwrap();

        let emu2 = Emulator::from_snapshot(snap2).unwrap();

        assert_eq!(emu.cpu.pc, emu2.cpu.pc);
        assert_eq!(
            emu.cpu.read_reg(crate::decoder::Register::X5),
            emu2.cpu.read_reg(crate::decoder::Register::X5)
        );
        assert_eq!(emu.bus.dram.data, emu2.bus.dram.data);
        assert_eq!(emu.bus.clint.mtime, emu2.bus.clint.mtime);
        assert_eq!(emu.bus.clint.mtimecmp, emu2.bus.clint.mtimecmp);
        assert_eq!(emu.bus.uart.input, emu2.bus.uart.input);
    }
}

fn load_elf_into_dram(
    buffer: &[u8],
    bus: &mut SystemBus,
) -> Result<u64, Box<dyn std::error::Error>> {
    let elf = Elf::parse(buffer)?;
    let base = bus.dram_base();
    let dram_end = base + bus.dram_size() as u64;

    for ph in &elf.program_headers {
        if ph.p_type != PT_LOAD || ph.p_memsz == 0 {
            continue;
        }

        let file_size = ph.p_filesz as usize;
        let mem_size = ph.p_memsz as usize;
        let file_offset = ph.p_offset as usize;
        if file_offset + file_size > buffer.len() {
            return Err(format!(
                "ELF segment exceeds file bounds (offset 0x{:x})",
                file_offset
            )
            .into());
        }

        let target_addr = if ph.p_paddr != 0 {
            ph.p_paddr
        } else {
            ph.p_vaddr
        };
        if target_addr < base {
            return Err(format!(
                "Segment start 0x{:x} lies below DRAM base 0x{:x}",
                target_addr, base
            )
            .into());
        }
        let seg_end = target_addr
            .checked_add(mem_size as u64)
            .ok_or_else(|| "Segment end overflow".to_string())?;
        if seg_end > dram_end {
            return Err(format!(
                "Segment 0x{:x}-0x{:x} exceeds DRAM (end 0x{:x})",
                target_addr, seg_end, dram_end
            )
            .into());
        }

        let dram_offset = (target_addr - base) as u64;
        if file_size > 0 {
            let end = file_offset + file_size;
            bus.dram
                .load(&buffer[file_offset..end], dram_offset)
                .map_err(|e| format!("Failed to load segment: {}", e))?;
        }
        if mem_size > file_size {
            let zero_start = dram_offset as usize + file_size;
            bus.dram
                .zero_range(zero_start, mem_size - file_size)
                .map_err(|e| format!("Failed to zero bss: {}", e))?;
        }
        log::debug!(
            "Loaded segment: addr=0x{:x}, filesz=0x{:x}, memsz=0x{:x}",
            target_addr,
            file_size,
            mem_size
        );
    }

    Ok(elf.entry)
}
</file>

<file path="vm/src/mmu.rs">
use crate::bus::Bus;
use crate::csr::Mode;
use crate::Trap;

#[derive(Clone, Copy, PartialEq, Eq, Debug)]
pub enum AccessType {
    Instruction,
    Load,
    Store,
}

const PAGE_SIZE: u64 = 4096;
const PTE_SIZE: u64 = 8;
const MAX_LEVELS: usize = 4;

const TLB_SIZE: usize = 64;

#[derive(Clone, Copy, Debug)]
pub struct TlbEntry {
    pub vpn: u64,
    pub ppn: u64,
    pub valid: bool,
    pub asid: u64,
    pub global: bool, // Global mapping bit
    pub r: bool,
    pub w: bool,
    pub x: bool,
    pub u: bool,
    pub a: bool,
    pub d: bool,
}

impl Default for TlbEntry {
    fn default() -> Self {
        Self {
            vpn: 0,
            ppn: 0,
            valid: false,
            asid: 0,
            global: false,
            r: false,
            w: false,
            x: false,
            u: false,
            a: false,
            d: false,
        }
    }
}

pub struct Tlb {
    entries: [TlbEntry; TLB_SIZE],
}

impl Tlb {
    pub fn new() -> Self {
        Self {
            entries: [TlbEntry::default(); TLB_SIZE],
        }
    }

    pub fn flush(&mut self) {
        for entry in self.entries.iter_mut() {
            entry.valid = false;
        }
    }

    pub fn flush_asid(&mut self, asid: u64) {
        for entry in self.entries.iter_mut() {
            if !entry.global && entry.asid == asid {
                entry.valid = false;
            }
        }
    }

    pub fn flush_page(&mut self, vpn: u64, asid: u64) {
        let idx = (vpn as usize) % TLB_SIZE;
        let entry = &mut self.entries[idx];

        if entry.valid && entry.vpn == vpn {
            // For page-specific flush, invalidate matching ASID mappings.
            // Global mappings ignore ASID and are treated as matching.
            let match_asid = entry.global || entry.asid == asid;
            if match_asid {
                entry.valid = false;
            }
        }
    }

    pub fn lookup(&self, vpn: u64, asid: u64) -> Option<&TlbEntry> {
        let idx = (vpn as usize) % TLB_SIZE;
        let entry = &self.entries[idx];

        // Hit if: valid AND VPN matches AND (entry is global OR ASID matches).
        if entry.valid && entry.vpn == vpn && (entry.global || entry.asid == asid) {
            Some(entry)
        } else {
            None
        }
    }

    pub fn insert(&mut self, entry: TlbEntry) {
        let idx = (entry.vpn as usize) % TLB_SIZE;
        self.entries[idx] = entry;
    }
}

/// Sv39/Sv48 translation + A/D bit updates.
///
/// `addr` is a virtual address. Returns the translated physical address or a
/// `Trap` corresponding to the appropriate page/access fault.
pub fn translate(
    bus: &mut dyn Bus,
    tlb: &mut Tlb,
    mode: Mode,
    satp: u64,
    mstatus: u64,
    addr: u64,
    access_type: AccessType,
) -> Result<u64, Trap> {
    // No translation in Machine mode (always Bare).
    if mode == Mode::Machine {
        return Ok(addr);
    }

    let satp_mode = (satp >> 60) & 0xF;
    let current_asid = (satp >> 44) & 0xFFFF;

    let (levels, va_bits, vpn_full_mask): (usize, u64, u64) = match satp_mode {
        0 => {
            // Bare: no translation.
            return Ok(addr);
        }
        8 => {
            // Sv39
            let levels = 3;
            let va_bits = 39;
            let vpn_full_mask = (1u64 << (9 * levels)) - 1;
            (levels, va_bits, vpn_full_mask)
        }
        9 => {
            // Sv48 (supported by this MMU, though not required for virt).
            let levels = 4;
            let va_bits = 48;
            let vpn_full_mask = (1u64 << (9 * levels)) - 1;
            (levels, va_bits, vpn_full_mask)
        }
        _ => {
            // Unsupported mode: treat as Bare.
            return Ok(addr);
        }
    };

    // Check canonical form of the virtual address for the configured VA width.
    let sign_bit = va_bits - 1;
    let upper_mask = !((1u64 << va_bits) - 1);
    let sign = (addr >> sign_bit) & 1;
    let expected_upper = if sign == 1 { upper_mask } else { 0 };
    if (addr & upper_mask) != expected_upper {
        return Err(page_fault(access_type, addr));
    }

    let vpn_full = (addr >> 12) & vpn_full_mask;

    // TLB hit path.
    if let Some(entry) = tlb.lookup(vpn_full, current_asid) {
        if check_permission_tlb(mode, mstatus, entry, access_type) {
            // For now we do not lazily update A/D on TLB hits  page table
            // entries are already marked by the walk that inserted this entry.
            let offset = addr & 0xFFF;
            let pa = (entry.ppn << 12) | offset;
            return Ok(pa);
        } else {
            return Err(page_fault(access_type, addr));
        }
    }

    // Page table walk on TLB miss.
    let mut vpn = [0u64; MAX_LEVELS];
    for level in 0..levels {
        vpn[level] = (addr >> (12 + 9 * level as u64)) & 0x1FF;
    }

    let root_ppn = satp & ((1u64 << 44) - 1);
    let mut a = root_ppn * PAGE_SIZE;

    for i in (0..levels).rev() {
        let pte_addr = a + vpn[i] * PTE_SIZE;

        let pte = match bus.load(pte_addr, 8) {
            Ok(val) => val,
            Err(_) => return Err(access_fault(access_type, addr)),
        };

        let v = (pte >> 0) & 1;
        let r = (pte >> 1) & 1;
        let w = (pte >> 2) & 1;
        let x = (pte >> 3) & 1;

        // Invalid or malformed.
        if v == 0 || (r == 0 && w == 1) {
            return Err(page_fault(access_type, addr));
        }

        // Pointer to next level if R=X=0.
        if r == 0 && x == 0 {
            if i == 0 {
                return Err(page_fault(access_type, addr));
            }
            let ppn = (pte >> 10) & 0xFFF_FFFF_FFFF;
            a = ppn * PAGE_SIZE;
            continue;
        }

        // Leaf PTE.
        let mut entry = TlbEntry {
            vpn: vpn_full,
            ppn: (pte >> 10) & 0xFFF_FFFF_FFFF,
            valid: true,
            asid: current_asid,
            global: (pte >> 5) & 1 != 0, // G bit
            r: r != 0,
            w: w != 0,
            x: x != 0,
            u: (pte >> 4) & 1 != 0,
            a: (pte >> 6) & 1 != 0,
            d: (pte >> 7) & 1 != 0,
        };

        if !check_permission_tlb(mode, mstatus, &entry, access_type) {
            return Err(page_fault(access_type, addr));
        }

        // Superpage alignment checks (Sv39/48 spec).
        if i > 0 {
            let ppn_mask = (1 << (9 * i)) - 1;
            let ppn = (pte >> 10) & 0xFFF_FFFF_FFFF;
            if (ppn & ppn_mask) != 0 {
                return Err(page_fault(access_type, addr));
            }
        }

        // A/D bit updates: set in memory and in the cached entry.
        let mut new_pte = pte;
        let mut update = false;

        if !entry.a {
            new_pte |= 1 << 6;
            entry.a = true;
            update = true;
        }
        if matches!(access_type, AccessType::Store) && !entry.d {
            new_pte |= 1 << 7;
            entry.d = true;
            update = true;
        }

        if update {
            if bus.store(pte_addr, 8, new_pte).is_err() {
                return Err(access_fault(access_type, addr));
            }
        }

        let offset_in_page = addr & 0xFFF;

        // Construct final PPN, filling low parts from the VA on superpages.
        let ppn = (pte >> 10) & 0xFFF_FFFF_FFFF;
        let vpn_mask = (1 << (9 * i)) - 1;
        let result_ppn = (ppn & !vpn_mask) | ((addr >> 12) & vpn_mask);

        entry.ppn = result_ppn;
        tlb.insert(entry);

        let pa = (result_ppn << 12) | offset_in_page;
        return Ok(pa);
    }

    Err(page_fault(access_type, addr))
}

fn check_permission_tlb(mode: Mode, mstatus: u64, entry: &TlbEntry, access_type: AccessType) -> bool {
    let mxr = (mstatus >> 19) & 1;
    let sum = (mstatus >> 18) & 1;

    match mode {
        Mode::Supervisor => {
            if entry.u {
                if matches!(access_type, AccessType::Instruction) {
                    return false;
                }
                if sum == 0 {
                    return false;
                }
            }
        }
        Mode::User => {
            if !entry.u {
                return false;
            }
        }
        Mode::Machine => {}
    }

    match access_type {
        AccessType::Instruction => entry.x,
        AccessType::Store => entry.w,
        AccessType::Load => {
            if entry.r {
                true
            } else {
                mxr == 1 && entry.x
            }
        }
    }
}

fn page_fault(access_type: AccessType, addr: u64) -> Trap {
    match access_type {
        AccessType::Instruction => Trap::InstructionPageFault(addr),
        AccessType::Load => Trap::LoadPageFault(addr),
        AccessType::Store => Trap::StorePageFault(addr),
    }
}

fn access_fault(access_type: AccessType, addr: u64) -> Trap {
    match access_type {
        AccessType::Instruction => Trap::InstructionAccessFault(addr),
        AccessType::Load => Trap::LoadAccessFault(addr),
        AccessType::Store => Trap::StoreAccessFault(addr),
    }
}
</file>

<file path="vm/src/plic.rs">
use crate::dram::MemoryError;

pub const PLIC_BASE: u64 = 0x0C00_0000;
pub const PLIC_SIZE: u64 = 0x400_0000;

pub const UART_IRQ: u32 = 10;
pub const VIRTIO0_IRQ: u32 = 1;

const NUM_SOURCES: usize = 32;
const NUM_CONTEXTS: usize = 2; // 0 = M-mode hart0, 1 = S-mode hart0

pub struct Plic {
    pub priority: [u32; NUM_SOURCES],
    pub pending: u32, // Level-triggered mirror of device IRQ lines (bit per source)
    pub enable: [u32; NUM_CONTEXTS],
    pub threshold: [u32; NUM_CONTEXTS],
    pub active: [u32; NUM_CONTEXTS], // Per-context in-flight IRQs (claimed but not completed)
    pub debug: bool,
    // Multi-context arrays enable SMP readiness while preserving single-hart behavior.
}

impl Plic {
    pub fn new() -> Self {
        Self {
            priority: [0; NUM_SOURCES],
            pending: 0,
            enable: [0; NUM_CONTEXTS],
            threshold: [0; NUM_CONTEXTS],
            active: [0; NUM_CONTEXTS],
            debug: false,
        }
    }

    pub fn update_pending(&mut self, source: u32) {
        // Backward compatibility helper: set as pending (edge  level).
        // Bus.refresh_irqs() may later clear this if device line is low.
        if source < 32 {
            if self.debug {
                 eprintln!("[PLIC] Update Pending source={}", source);
            }
            self.pending |= 1 << source;
        }
    }

    // New: level-triggered source line setter
    pub fn set_source_level(&mut self, source: u32, level: bool) {
        if source >= 32 {
            return;
        }
        let was_pending = (self.pending & (1 << source)) != 0;
        if level {
            if self.debug && !was_pending {
                 eprintln!("[PLIC] IRQ Line High: source={} enable[0]=0x{:x} enable[1]=0x{:x} prio={}", 
                          source, self.enable[0], self.enable[1], self.priority[source as usize]);
            }
            self.pending |= 1 << source;
        } else {
            self.pending &= !(1 << source);
        }
    }

    pub fn load(&mut self, offset: u64, size: u64) -> Result<u64, MemoryError> {
        if size != 4 {
            return Ok(0); 
        }

        // Priority registers: 0x000000 .. 0x0000FC (4 bytes each)
        if offset < 0x001000 {
            let idx = (offset >> 2) as usize;
            if idx < NUM_SOURCES {
                return Ok(self.priority[idx] as u64);
            }
        }
        // Pending bits: 0x001000
        if offset == 0x001000 {
            return Ok(self.pending as u64);
        }
        // Enable per context: 0x002000 + 0x80 * context
        if offset >= 0x002000 && offset < 0x002000 + 0x80 * (NUM_CONTEXTS as u64) {
            let ctx = ((offset - 0x002000) / 0x80) as usize;
            let inner = (offset - 0x002000) % 0x80;
            if ctx < NUM_CONTEXTS && inner == 0 {
                return Ok(self.enable[ctx] as u64);
            }
        }
        // Context registers: threshold @ 0x200000 + 0x1000 * ctx, claim @ +4
        if offset >= 0x200000 {
            let ctx = ((offset - 0x200000) / 0x1000) as usize;
            if ctx < NUM_CONTEXTS {
                let base = 0x200000 + (0x1000 * ctx as u64);
                if offset == base {
                    return Ok(self.threshold[ctx] as u64);
                }
                if offset == base + 4 {
                    let claim = self.claim_interrupt_for(ctx);
                    if crate::plic::Plic::debug_trace() {
                        eprintln!("[PLIC] SCLAIM ctx={} -> {}", ctx, claim);
                    }
                    return Ok(claim as u64);
                }
            }
        }

        Ok(0)
    }

    fn debug_trace() -> bool {
        // Helper to check if trace logging is enabled without importing log everywhere if not needed
        // or just use std::env
        std::env::var("RUST_LOG").map(|s| s.contains("trace")).unwrap_or(false)
    }

    pub fn store(&mut self, offset: u64, size: u64, value: u64) -> Result<(), MemoryError> {
        if size != 4 {
            return Ok(());
        }
        let val = value as u32;

        // Priority
        if offset < 0x001000 {
            let idx = (offset >> 2) as usize;
            if idx < NUM_SOURCES {
                self.priority[idx] = val;
            }
            return Ok(());
        }
        // Pending is read-only to software
        if offset == 0x001000 {
            return Ok(());
        }
        // Enable per context
        if offset >= 0x002000 && offset < 0x002000 + 0x80 * (NUM_CONTEXTS as u64) {
            let ctx = ((offset - 0x002000) / 0x80) as usize;
            let inner = (offset - 0x002000) % 0x80;
            if ctx < NUM_CONTEXTS && inner == 0 {
                self.enable[ctx] = val;
            }
            return Ok(());
        }
        // Threshold / Claim-Complete per context
        if offset >= 0x200000 {
            let ctx = ((offset - 0x200000) / 0x1000) as usize;
            if ctx < NUM_CONTEXTS {
                let base = 0x200000 + (0x1000 * ctx as u64);
                if offset == base {
                    self.threshold[ctx] = val;
                    return Ok(());
                }
                if offset == base + 4 {
                    // Completion: value is the source ID to complete
                    let id = (val & 0xffff) as u32;
                    if id > 0 && (id as usize) < NUM_SOURCES {
                        // eprintln!("[PLIC] Completed IRQ {} for context {}", id, ctx);
                        self.active[ctx] &= !(1 << id);
                    }
                    return Ok(());
                }
            }
            return Ok(());
        }

        Ok(())
    }

    fn eligible_for_context(&self, source: usize, ctx: usize) -> bool {
        let pending = ((self.pending >> source) & 1) == 1;
        let enabled = ((self.enable[ctx] >> source) & 1) == 1;
        let over_threshold = self.priority[source] > self.threshold[ctx];
        let not_active = ((self.active[ctx] >> source) & 1) == 0;
        pending && enabled && over_threshold && not_active
    }

    pub fn claim_interrupt_for(&mut self, ctx: usize) -> u32 {
        let mut max_prio = 0;
        let mut max_id = 0;

        for i in 1..NUM_SOURCES {
            if self.eligible_for_context(i, ctx) {
                let prio = self.priority[i];
                if prio > max_prio {
                    max_prio = prio;
                    max_id = i as u32;
                }
            }
        }

        if max_id != 0 {
            // eprintln!("[PLIC] Claimed IRQ {} for context {} (prio {})", max_id, ctx, max_prio);
            // Mark in-flight for this context until completed.
            self.active[ctx] |= 1 << max_id;
        }
        max_id
    }
    
    pub fn is_interrupt_pending(&self) -> bool {
        // For current single-hart flow, report S-mode context (1) if available, else context 0.
        let ctx = if NUM_CONTEXTS > 1 { 1 } else { 0 };
        self.is_interrupt_pending_for(ctx)
    }

    pub fn is_interrupt_pending_for(&self, ctx: usize) -> bool {
        if ctx >= NUM_CONTEXTS {
            return false;
        }
        for i in 1..NUM_SOURCES {
            if self.eligible_for_context(i, ctx) {
                if self.debug {
                    eprintln!("[PLIC] Interrupt pending for ctx={} source={}", ctx, i);
                }
                return true;
            }
        }
        // Debug: show why no interrupt
        if self.debug && self.pending != 0 {
            for i in 1..NUM_SOURCES {
                let pending = ((self.pending >> i) & 1) == 1;
                let enabled = ((self.enable[ctx] >> i) & 1) == 1;
                let over_threshold = self.priority[i] > self.threshold[ctx];
                let not_active = ((self.active[ctx] >> i) & 1) == 0;
                if pending {
                    eprintln!("[PLIC] Source {} pending but not eligible for ctx={}: enabled={} over_threshold={} (prio={} > thresh={}) not_active={}", 
                             i, ctx, enabled, over_threshold, self.priority[i], self.threshold[ctx], not_active);
                }
            }
        }
        false
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_plic_claim_complete_context1() {
        let mut plic = Plic::new();
        // Priorities
        plic.priority[1] = 5;
        plic.priority[10] = 3;
        // Enable sources 1 and 10 for context 1 (S-mode)
        let enable_val = (1u32 << 1) | (1u32 << 10);
        let _ = plic.store(0x002000 + 0x80 * 1, 4, enable_val as u64);
        // Threshold 0 for context 1
        let _ = plic.store(0x200000 + 0x1000 * 1, 4, 0);
        // Assert device lines
        plic.set_source_level(1, true);
        plic.set_source_level(10, true);

        // Claim highest priority first (source 1)
        let id1 = plic.claim_interrupt_for(1);
        assert_eq!(id1, 1);
        // Next claim should return source 10 (since 1 is active)
        let id2 = plic.claim_interrupt_for(1);
        assert_eq!(id2, 10);
        // Complete source 1
        let _ = plic.store(0x200004 + 0x1000 * 1, 4, 1);
        // Claim again should allow source 1
        let id3 = plic.claim_interrupt_for(1);
        assert_eq!(id3, 1);
    }
}
</file>

<file path="vm/src/virtio.rs">
use crate::dram::{Dram, MemoryError};
use crate::bus::DRAM_BASE;

// MMIO register *values* expected by the xv6 VirtIO driver.
const MAGIC_VALUE: u64 = 0x7472_6976;
const VERSION: u64 = 2; // Legacy VirtIO MMIO version

const VENDOR_ID: u64 = 0x554d_4551;

// Common MMIO register offsets
const MAGIC_VALUE_OFFSET: u64 = 0x000;
const VERSION_OFFSET: u64 = 0x004;
const DEVICE_ID_OFFSET: u64 = 0x008;
const VENDOR_ID_OFFSET: u64 = 0x00c;
const DEVICE_FEATURES_OFFSET: u64 = 0x010;
const DEVICE_FEATURES_SEL_OFFSET: u64 = 0x014;
const DRIVER_FEATURES_OFFSET: u64 = 0x020;
const DRIVER_FEATURES_SEL_OFFSET: u64 = 0x024;
const GUEST_PAGE_SIZE_OFFSET: u64 = 0x028;
const QUEUE_SEL_OFFSET: u64 = 0x030;
const QUEUE_NUM_MAX_OFFSET: u64 = 0x034;
const QUEUE_NUM_OFFSET: u64 = 0x038;
const QUEUE_PFN_OFFSET: u64 = 0x040;
const QUEUE_READY_OFFSET: u64 = 0x044;
const QUEUE_NOTIFY_OFFSET: u64 = 0x050;
const INTERRUPT_STATUS_OFFSET: u64 = 0x060;
const INTERRUPT_ACK_OFFSET: u64 = 0x064;
const STATUS_OFFSET: u64 = 0x070;
const QUEUE_DESC_LOW_OFFSET: u64 = 0x080;
const QUEUE_DESC_HIGH_OFFSET: u64 = 0x084;
const QUEUE_DRIVER_LOW_OFFSET: u64 = 0x090;
const QUEUE_DRIVER_HIGH_OFFSET: u64 = 0x094;
const QUEUE_DEVICE_LOW_OFFSET: u64 = 0x0a0;
const QUEUE_DEVICE_HIGH_OFFSET: u64 = 0x0a4;
const CONFIG_GENERATION_OFFSET: u64 = 0x0fc;

// Device IDs
const VIRTIO_BLK_DEVICE_ID: u32 = 2;
const VIRTIO_RNG_DEVICE_ID: u32 = 4;
const VIRTIO_CONSOLE_DEVICE_ID: u32 = 3;

// VirtIO Block Features
#[allow(dead_code)]
const VIRTIO_BLK_F_SIZE_MAX: u64 = 1;
#[allow(dead_code)]
const VIRTIO_BLK_F_SEG_MAX: u64 = 2;
#[allow(dead_code)]
const VIRTIO_BLK_F_GEOMETRY: u64 = 4;
#[allow(dead_code)]
const VIRTIO_BLK_F_RO: u64 = 5;
#[allow(dead_code)]
const VIRTIO_BLK_F_BLK_SIZE: u64 = 6;
const VIRTIO_BLK_F_FLUSH: u64 = 9;

const QUEUE_SIZE: u32 = 16;

const VRING_DESC_F_NEXT: u64 = 1;
const VRING_DESC_F_WRITE: u64 = 2;

/// Trait for all VirtIO devices to implement.
pub trait VirtioDevice: Send {
    fn read(&mut self, offset: u64) -> Result<u64, MemoryError>;
    fn write(&mut self, offset: u64, val: u64, dram: &mut Dram) -> Result<(), MemoryError>;
    fn is_interrupting(&self) -> bool;
    fn device_id(&self) -> u32;
    fn reg_read_size(&self, _offset: u64) -> u64 {
        // Most registers are 4 bytes.
        // Config space (>= 0x100) might be different but for now we assume 4-byte access.
        4
    }
}

pub struct VirtioBlock {
    driver_features: u32,
    driver_features_sel: u32,
    device_features_sel: u32,
    page_size: u32,
    queue_sel: u32,
    queue_num: u32,
    queue_desc: u64,
    queue_avail: u64,
    queue_used: u64,
    queue_ready: bool,
    interrupt_status: u32,
    status: u32,
    disk: Vec<u8>,
    last_avail_idx: u16,
    pub debug: bool,
}

impl VirtioBlock {
    pub fn new(disk_image: Vec<u8>) -> Self {
        Self {
            driver_features: 0,
            driver_features_sel: 0,
            device_features_sel: 0,
            page_size: 4096,
            queue_sel: 0,
            queue_num: 0,
            queue_desc: 0,
            queue_avail: 0,
            queue_used: 0,
            queue_ready: false,
            interrupt_status: 0,
            status: 0,
            disk: disk_image,
            last_avail_idx: 0,
            debug: false,
        }
    }

    fn phys_to_offset(&self, addr: u64) -> Result<u64, MemoryError> {
        if addr < DRAM_BASE {
            return Err(MemoryError::OutOfBounds(addr));
        }
        Ok(addr - DRAM_BASE)
    }

    fn process_queue(&mut self, dram: &mut Dram) -> Result<(), MemoryError> {
        let avail_idx_addr = self.queue_avail.wrapping_add(2);
        let avail_idx = dram.load_16(self.phys_to_offset(avail_idx_addr)?)? as u16;

        let mut processed_any = false;
        while self.last_avail_idx != avail_idx {
            let qsz = if self.queue_num > 0 { self.queue_num } else { QUEUE_SIZE };
            let ring_slot = (self.last_avail_idx as u32 % qsz) as u64;
            let head_idx_addr = self.queue_avail.wrapping_add(4).wrapping_add(ring_slot * 2);
            let head_desc_idx = dram.load_16(self.phys_to_offset(head_idx_addr)?)? as u16;

            if self.debug {
                 eprintln!("[VirtioBlock] Processing queue idx={} head_desc={}", self.last_avail_idx, head_desc_idx);
            }

            let desc_idx = head_desc_idx;

            let desc_addr0 = self.queue_desc.wrapping_add((desc_idx as u64) * 16);
            let off_desc_addr0 = self.phys_to_offset(desc_addr0)?;
            let header_addr = dram.load_64(off_desc_addr0)?;
            let header_len = dram.load_32(off_desc_addr0 + 8)?;
            let header_flags = dram.load_16(off_desc_addr0 + 12)? as u64;
            let mut next_desc_idx = dram.load_16(off_desc_addr0 + 14)?;

            if header_len < 16 {
                if self.debug {
                     eprintln!("[VirtioBlock] Header too short: {}", header_len);
                }
                // Consume malformed descriptor to avoid loop
                self.last_avail_idx = self.last_avail_idx.wrapping_add(1);
                processed_any = true;
                continue;
            }

            let off_header_addr = self.phys_to_offset(header_addr)?;
            let blk_type = dram.load_32(off_header_addr)?;
            let _blk_reserved = dram.load_32(off_header_addr + 4)?;
            let blk_sector = dram.load_64(off_header_addr + 8)?;

            if self.debug {
                 eprintln!("[VirtioBlock] Request type={} sector={}", blk_type, blk_sector);
            }

            let mut data_len_done: u32 = 0;

            if (header_flags & VRING_DESC_F_NEXT) != 0 {
                let desc2_addr = self.queue_desc.wrapping_add((next_desc_idx as u64) * 16);
                let off_desc2_addr = self.phys_to_offset(desc2_addr)?;
                let data_addr = dram.load_64(off_desc2_addr)?;
                let data_len = dram.load_32(off_desc2_addr + 8)?;
                let flags2 = dram.load_16(off_desc2_addr + 12)? as u64;
                next_desc_idx = dram.load_16(off_desc2_addr + 14)?;

                if blk_type == 0 { // IN (Read)
                    let offset = blk_sector * 512;
                    if offset + (data_len as u64) <= self.disk.len() as u64 {
                        let slice = &self.disk[offset as usize..(offset as usize + data_len as usize)];
                        dram.write_bytes(self.phys_to_offset(data_addr)?, slice)?;
                        data_len_done = data_len as u32;
                    }
                } else if blk_type == 1 { // OUT (Write)
                    let offset = blk_sector * 512;
                    if offset + (data_len as u64) <= self.disk.len() as u64 {
                        for i in 0..data_len {
                            let b = dram.load_8(self.phys_to_offset(data_addr + i as u64)?)? as u8;
                            self.disk[offset as usize + i as usize] = b;
                        }
                        data_len_done = data_len as u32;
                    }
                }

                if (flags2 & VRING_DESC_F_NEXT) != 0 {
                    let desc3_addr = self.queue_desc.wrapping_add((next_desc_idx as u64) * 16);
                    let off_desc3_addr = self.phys_to_offset(desc3_addr)?;
                    let status_addr = dram.load_64(off_desc3_addr)?;
                    dram.store_8(self.phys_to_offset(status_addr)?, 0)?; // Status: OK
                }
            }

            let used_idx_addr = self.queue_used.wrapping_add(2);
            let mut used_idx = dram.load_16(self.phys_to_offset(used_idx_addr)?)? as u16;
            let elem_addr = self.queue_used.wrapping_add(4).wrapping_add((used_idx as u64 % qsz as u64) * 8);
            let off_elem_addr = self.phys_to_offset(elem_addr)?;
            dram.store_32(off_elem_addr, head_desc_idx as u64)?;
            dram.store_32(off_elem_addr + 4, data_len_done as u64)?;
            used_idx = used_idx.wrapping_add(1);
            dram.store_16(self.phys_to_offset(used_idx_addr)?, used_idx as u64)?;

            self.last_avail_idx = self.last_avail_idx.wrapping_add(1);
            processed_any = true;
        }

        if processed_any {
            self.interrupt_status |= 1;
        }

        Ok(())
    }
}

impl VirtioDevice for VirtioBlock {
    fn device_id(&self) -> u32 {
        VIRTIO_BLK_DEVICE_ID
    }

    fn is_interrupting(&self) -> bool {
        self.interrupt_status != 0
    }

    fn read(&mut self, offset: u64) -> Result<u64, MemoryError> {
        let val = match offset {
            MAGIC_VALUE_OFFSET => MAGIC_VALUE,
            VERSION_OFFSET => VERSION,
            DEVICE_ID_OFFSET => VIRTIO_BLK_DEVICE_ID as u64,
            VENDOR_ID_OFFSET => VENDOR_ID,
            DEVICE_FEATURES_OFFSET => {
                if self.device_features_sel == 0 {
                    1u64 << VIRTIO_BLK_F_FLUSH
                } else {
                    0
                }
            }
            DEVICE_FEATURES_SEL_OFFSET => self.device_features_sel as u64,
            DRIVER_FEATURES_OFFSET => self.driver_features as u64,
            DRIVER_FEATURES_SEL_OFFSET => self.driver_features_sel as u64,
            GUEST_PAGE_SIZE_OFFSET => self.page_size as u64,
            QUEUE_NUM_MAX_OFFSET => QUEUE_SIZE as u64,
            QUEUE_SEL_OFFSET => self.queue_sel as u64,
            QUEUE_NUM_OFFSET => self.queue_num as u64,
            QUEUE_READY_OFFSET => if self.queue_ready { 1 } else { 0 },
            INTERRUPT_STATUS_OFFSET => self.interrupt_status as u64,
            STATUS_OFFSET => self.status as u64,
            CONFIG_GENERATION_OFFSET => 0,
            _ if offset >= 0x100 => {
                if offset == 0x100 {
                     let cap = self.disk.len() as u64 / 512;
                     cap & 0xffffffff
                } else if offset == 0x104 {
                     let cap = self.disk.len() as u64 / 512;
                     cap >> 32
                } else {
                    0
                }
            }
            _ => 0,
        };
        Ok(val)
    }

    fn write(&mut self, offset: u64, val: u64, dram: &mut Dram) -> Result<(), MemoryError> {
        let val32 = val as u32;

        match offset {
            DEVICE_FEATURES_SEL_OFFSET => { 
                self.device_features_sel = val32; 
            }
            DRIVER_FEATURES_OFFSET => { 
                self.driver_features = val32; 
            }
            DRIVER_FEATURES_SEL_OFFSET => { 
                self.driver_features_sel = val32; 
            }
            QUEUE_SEL_OFFSET => { 
                self.queue_sel = val32; 
            }
            QUEUE_NUM_OFFSET => { 
                self.queue_num = val32; 
            }
            GUEST_PAGE_SIZE_OFFSET => { 
                self.page_size = val32; 
            }
            QUEUE_PFN_OFFSET => {
                let pfn = val32 as u64;
                if pfn != 0 {
                    let desc = pfn * (self.page_size as u64);
                    self.queue_desc = desc;
                    self.queue_avail = desc + 16 * (self.queue_num as u64);
                    let avail_size = 2 + 2 * (self.queue_num as u64) + 2;
                    let used = (self.queue_avail + avail_size + (self.page_size as u64) - 1) & !((self.page_size as u64) - 1);
                    self.queue_used = used;
                    self.queue_ready = true;
                    if self.debug {
                        eprintln!("[VirtIO] Queue configured: desc=0x{:x} avail=0x{:x} used=0x{:x}", self.queue_desc, self.queue_avail, self.queue_used);
                    }
                }
            }
            QUEUE_READY_OFFSET => { 
                self.queue_ready = val32 != 0; 
            }
            QUEUE_NOTIFY_OFFSET => {
                if val32 == 0 {
                    self.process_queue(dram)?;
                }
            }
            INTERRUPT_ACK_OFFSET => {
                self.interrupt_status &= !val32;
            }
            STATUS_OFFSET => { 
                if val32 == 0 {
                    // Reset
                    self.status = 0;
                    self.queue_ready = false;
                    self.interrupt_status = 0;
                    self.last_avail_idx = 0;
                } else {
                    self.status = val32; 
                }
            }
            QUEUE_DESC_LOW_OFFSET => { 
                self.queue_desc = (self.queue_desc & 0xffffffff00000000) | (val32 as u64); 
            }
            QUEUE_DESC_HIGH_OFFSET => { 
                self.queue_desc = (self.queue_desc & 0x00000000ffffffff) | ((val32 as u64) << 32); 
            }
            QUEUE_DRIVER_LOW_OFFSET => { 
                self.queue_avail = (self.queue_avail & 0xffffffff00000000) | (val32 as u64); 
            }
            QUEUE_DRIVER_HIGH_OFFSET => { 
                self.queue_avail = (self.queue_avail & 0x00000000ffffffff) | ((val32 as u64) << 32); 
            }
            QUEUE_DEVICE_LOW_OFFSET => { 
                self.queue_used = (self.queue_used & 0xffffffff00000000) | (val32 as u64); 
            }
            QUEUE_DEVICE_HIGH_OFFSET => { 
                self.queue_used = (self.queue_used & 0x00000000ffffffff) | ((val32 as u64) << 32); 
            }
            _ => {}
        }
        Ok(())
    }
}

pub struct VirtioRng {
    driver_features: u32,
    driver_features_sel: u32,
    device_features_sel: u32,
    page_size: u32,
    queue_sel: u32,
    queue_num: u32,
    queue_desc: u64,
    queue_avail: u64,
    queue_used: u64,
    queue_ready: bool,
    interrupt_status: u32,
    status: u32,
    last_avail_idx: u16,
    pub debug: bool,
}

impl VirtioRng {
    pub fn new() -> Self {
        Self {
            driver_features: 0,
            driver_features_sel: 0,
            device_features_sel: 0,
            page_size: 4096,
            queue_sel: 0,
            queue_num: 0,
            queue_desc: 0,
            queue_avail: 0,
            queue_used: 0,
            queue_ready: false,
            interrupt_status: 0,
            status: 0,
            last_avail_idx: 0,
            debug: false,
        }
    }

    fn phys_to_offset(&self, addr: u64) -> Result<u64, MemoryError> {
        if addr < DRAM_BASE {
            return Err(MemoryError::OutOfBounds(addr));
        }
        Ok(addr - DRAM_BASE)
    }

    fn process_queue(&mut self, dram: &mut Dram) -> Result<(), MemoryError> {
        let avail_idx_addr = self.queue_avail.wrapping_add(2);
        let avail_idx = dram.load_16(self.phys_to_offset(avail_idx_addr)?)? as u16;

        let mut processed_any = false;
        while self.last_avail_idx != avail_idx {
            let ring_slot = (self.last_avail_idx as u32 % QUEUE_SIZE) as u64;
            let head_idx_addr = self.queue_avail.wrapping_add(4).wrapping_add(ring_slot * 2);
            let head_desc_idx = dram.load_16(self.phys_to_offset(head_idx_addr)?)? as u16;

            let desc_addr0 = self.queue_desc.wrapping_add((head_desc_idx as u64) * 16);
            let off_desc_addr0 = self.phys_to_offset(desc_addr0)?;
            let buffer_addr = dram.load_64(off_desc_addr0)?;
            let buffer_len = dram.load_32(off_desc_addr0 + 8)?;
            let flags = dram.load_16(off_desc_addr0 + 12)? as u64;

            if (flags & VRING_DESC_F_WRITE) != 0 {
                // Fill with pseudo-random data
                for i in 0..buffer_len {
                    dram.store_8(self.phys_to_offset(buffer_addr + i as u64)?, ((i as u8).wrapping_add(42)).into())?;
                }
            }

            let used_idx_addr = self.queue_used.wrapping_add(2);
            let mut used_idx = dram.load_16(self.phys_to_offset(used_idx_addr)?)? as u16;
            let elem_addr = self.queue_used.wrapping_add(4).wrapping_add((used_idx as u64 % QUEUE_SIZE as u64) * 8);
            let off_elem_addr = self.phys_to_offset(elem_addr)?;
            dram.store_32(off_elem_addr, head_desc_idx as u64)?;
            dram.store_32(off_elem_addr + 4, buffer_len as u64)?;
            used_idx = used_idx.wrapping_add(1);
            dram.store_16(self.phys_to_offset(used_idx_addr)?, used_idx as u64)?;

            self.last_avail_idx = self.last_avail_idx.wrapping_add(1);
            processed_any = true;
        }

        if processed_any {
            self.interrupt_status |= 1;
        }

        Ok(())
    }
}

impl VirtioDevice for VirtioRng {
    fn device_id(&self) -> u32 {
        VIRTIO_RNG_DEVICE_ID
    }

    fn is_interrupting(&self) -> bool {
        self.interrupt_status != 0
    }

    fn read(&mut self, offset: u64) -> Result<u64, MemoryError> {
        let val = match offset {
            MAGIC_VALUE_OFFSET => MAGIC_VALUE,
            VERSION_OFFSET => VERSION,
            DEVICE_ID_OFFSET => VIRTIO_RNG_DEVICE_ID as u64,
            VENDOR_ID_OFFSET => VENDOR_ID,
            DEVICE_FEATURES_OFFSET => 0,
            DEVICE_FEATURES_SEL_OFFSET => self.device_features_sel as u64,
            DRIVER_FEATURES_OFFSET => self.driver_features as u64,
            DRIVER_FEATURES_SEL_OFFSET => self.driver_features_sel as u64,
            GUEST_PAGE_SIZE_OFFSET => self.page_size as u64,
            QUEUE_NUM_MAX_OFFSET => QUEUE_SIZE as u64,
            QUEUE_SEL_OFFSET => self.queue_sel as u64,
            QUEUE_NUM_OFFSET => self.queue_num as u64,
            QUEUE_READY_OFFSET => if self.queue_ready { 1 } else { 0 },
            INTERRUPT_STATUS_OFFSET => self.interrupt_status as u64,
            STATUS_OFFSET => self.status as u64,
            CONFIG_GENERATION_OFFSET => 0,
            _ => 0,
        };
        Ok(val)
    }

    fn write(&mut self, offset: u64, val: u64, dram: &mut Dram) -> Result<(), MemoryError> {
        let val32 = val as u32;
        match offset {
            DEVICE_FEATURES_SEL_OFFSET => { self.device_features_sel = val32; }
            DRIVER_FEATURES_OFFSET => { self.driver_features = val32; }
            DRIVER_FEATURES_SEL_OFFSET => { self.driver_features_sel = val32; }
            QUEUE_SEL_OFFSET => { self.queue_sel = val32; }
            QUEUE_NUM_OFFSET => { self.queue_num = val32; }
            GUEST_PAGE_SIZE_OFFSET => { self.page_size = val32; }
            QUEUE_PFN_OFFSET => {
                let pfn = val32 as u64;
                if pfn != 0 {
                    let desc = pfn * (self.page_size as u64);
                    self.queue_desc = desc;
                    self.queue_avail = desc + 16 * (self.queue_num as u64);
                    let avail_size = 2 + 2 * (self.queue_num as u64) + 2;
                    let used = (self.queue_avail + avail_size + (self.page_size as u64) - 1) & !((self.page_size as u64) - 1);
                    self.queue_used = used;
                    self.queue_ready = true;
                }
            }
            QUEUE_READY_OFFSET => { self.queue_ready = val32 != 0; }
            QUEUE_NOTIFY_OFFSET => {
                if val32 == 0 {
                    self.process_queue(dram)?;
                }
            }
            INTERRUPT_ACK_OFFSET => {
                self.interrupt_status &= !val32;
            }
            STATUS_OFFSET => { 
                if val32 == 0 {
                    self.status = 0;
                    self.queue_ready = false;
                    self.interrupt_status = 0;
                    self.last_avail_idx = 0;
                } else {
                    self.status = val32; 
                }
            }
            QUEUE_DESC_LOW_OFFSET => { self.queue_desc = (self.queue_desc & 0xffffffff00000000) | (val32 as u64); }
            QUEUE_DESC_HIGH_OFFSET => { self.queue_desc = (self.queue_desc & 0x00000000ffffffff) | ((val32 as u64) << 32); }
            QUEUE_DRIVER_LOW_OFFSET => { self.queue_avail = (self.queue_avail & 0xffffffff00000000) | (val32 as u64); }
            QUEUE_DRIVER_HIGH_OFFSET => { self.queue_avail = (self.queue_avail & 0x00000000ffffffff) | ((val32 as u64) << 32); }
            QUEUE_DEVICE_LOW_OFFSET => { self.queue_used = (self.queue_used & 0xffffffff00000000) | (val32 as u64); }
            QUEUE_DEVICE_HIGH_OFFSET => { self.queue_used = (self.queue_used & 0x00000000ffffffff) | ((val32 as u64) << 32); }
            _ => {}
        }
        Ok(())
    }
}
</file>

<file path="web/.yarnrc.yml">
nodeLinker: node-modules
</file>

<file path="kernel/.cargo/config.toml">
[build]
target = "riscv64gc-unknown-none-elf"
</file>

<file path="kernel/src/allocator.rs">
use core::alloc::{GlobalAlloc, Layout};
use core::sync::atomic::{AtomicUsize, Ordering};

// MMIO address to report current heap usage in bytes
const MMIO_MEM_USAGE: *mut u64 = 0x2000_0000 as *mut u64;

unsafe extern "C" {
    static mut _sheap: u8;
    static mut _eheap: u8;
}

static HEAP_PTR: AtomicUsize = AtomicUsize::new(0);
static HEAP_START: AtomicUsize = AtomicUsize::new(0);
static HEAP_END: AtomicUsize = AtomicUsize::new(0);

pub fn init() {
    unsafe {
        let start = _sheap as *const u8 as usize;
        let end = _eheap as *const u8 as usize;
        HEAP_START.store(start, Ordering::Relaxed);
        HEAP_END.store(end, Ordering::Relaxed);
        HEAP_PTR.store(start, Ordering::Relaxed);
        // Report initial usage (0)
        core::ptr::write_volatile(MMIO_MEM_USAGE, 0);
    }
}

pub struct BumpAllocator;

#[inline]
fn align_up(addr: usize, align: usize) -> usize {
    let mask = align - 1;
    (addr + mask) & !mask
}

unsafe impl GlobalAlloc for BumpAllocator {
    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {
        let start = HEAP_START.load(Ordering::Relaxed);
        let end = HEAP_END.load(Ordering::Relaxed);

        loop {
            let current = HEAP_PTR.load(Ordering::Relaxed);
            let aligned = align_up(current, layout.align());
            let next = match aligned.checked_add(layout.size()) {
                Some(n) => n,
                None => return core::ptr::null_mut(),
            };
            if next > end {
                return core::ptr::null_mut();
            }
            if HEAP_PTR
                .compare_exchange(current, next, Ordering::SeqCst, Ordering::Relaxed)
                .is_ok()
            {
                // Report new usage
                let used = (next - start) as u64;
                core::ptr::write_volatile(MMIO_MEM_USAGE, used);
                return aligned as *mut u8;
            }
        }
    }

    unsafe fn dealloc(&self, _ptr: *mut u8, _layout: Layout) {
        // No-op: simple bump allocator does not support free.
        // Optionally, could report here as well, but we keep usage monotonic.
    }
}

#[global_allocator]
static GLOBAL_ALLOCATOR: BumpAllocator = BumpAllocator;
</file>

<file path="kernel/src/main.rs">
#![no_std]
#![no_main]

mod allocator;
mod uart;
extern crate alloc;
use alloc::vec::Vec;
use panic_halt as _;
use riscv_rt::entry;

#[entry]
fn main() -> ! {
    uart::write_line("Booting RISC-V kernel CLI...");
    uart::write_line("Type 'help' for a list of commands.");
    // Initialize simple bump allocator
    allocator::init();
    print_prompt();

    let console = uart::Console::new();
    let mut buffer = [0u8; 128];
    let mut len = 0usize;
    let mut count: usize = 0;

    loop {
        let byte = console.read_byte();

        // 0 means "no input" in our UART model
        if byte == 0 {
            continue;
        }

        match byte {
            b'\r' | b'\n' => {
                uart::write_line("");
                handle_line(&buffer, len, &mut count);
                print_prompt();
                len = 0;
            }
            // Backspace / Delete
            8 | 0x7f => {
                if len > 0 {
                    len -= 1;
                    // Move cursor back, erase char, move back again.
                    // (Simple TTY-style backspace handling.)
                    uart::write_str("\u{8} \u{8}");
                }
            }
            _ => {
                if len < buffer.len() {
                    buffer[len] = byte;
                    len += 1;
                    uart::Console::new().write_byte(byte);
                }
            }
        }
    }
}

fn print_prompt() {
    uart::write_str("risk-v> ");
}

fn handle_line(buffer: &[u8], len: usize, count: &mut usize) {
    // Trim leading/trailing whitespace (spaces and tabs only)
    let mut start = 0;
    let mut end = len;

    while start < end && (buffer[start] == b' ' || buffer[start] == b'\t') {
        start += 1;
    }
    while end > start && (buffer[end - 1] == b' ' || buffer[end - 1] == b'\t') {
        end -= 1;
    }

    if start >= end {
        // Empty line -> keep old behaviour: bump counter
        uart::write_line("Available commands:");
        uart::write_line("  help           - show this help");
        uart::write_line("  hello          - increment and print the counter");
        uart::write_line("  count          - show current counter value");
        uart::write_line("  echo <text>    - print <text>");
        uart::write_line("  clear          - print a few newlines");
        uart::write_line("  alloc <bytes>  - allocate bytes (leaked) to test heap usage");
        return;
    }

    let line = &buffer[start..end];

    // Split into command and arguments (first whitespace)
    let mut i = 0;
    while i < line.len() && line[i] != b' ' && line[i] != b'\t' {
        i += 1;
    }
    let cmd = &line[..i];

    let mut arg_start = i;
    while arg_start < line.len() && (line[arg_start] == b' ' || line[arg_start] == b'\t') {
        arg_start += 1;
    }
    let args = &line[arg_start..];

    if eq_cmd(cmd, b"help") {
        uart::write_line("Available commands:");
        uart::write_line("  help           - show this help");
        uart::write_line("  hello          - increment and print the counter");
        uart::write_line("  count          - show current counter value");
        uart::write_line("  echo <text>    - print <text>");
        uart::write_line("  clear          - print a few newlines");
        uart::write_line("  alloc <bytes>  - allocate bytes (leaked) to test heap usage");
    } else if eq_cmd(cmd, b"hello") {
        *count += 400;
        uart::write_str("Hello, count ");
        uart::write_u64(*count as u64);
        uart::write_line("");
    } else if eq_cmd(cmd, b"count") {
        uart::write_str("Current count: ");
        uart::write_u64(*count as u64);
        uart::write_line("");
    } else if eq_cmd(cmd, b"clear") {
        for _ in 0..20 {
            uart::write_line("");
        }
    } else if eq_cmd(cmd, b"echo") {
        uart::write_bytes(args);
        uart::write_line("");
    } else if eq_cmd(cmd, b"alloc") {
        // Parse decimal size from args
        let mut n: usize = 0;
        let mut ok = false;
        for &b in args {
            if b >= b'0' && b <= b'9' {
                ok = true;
                let d = (b - b'0') as usize;
                n = n.saturating_mul(10).saturating_add(d);
            } else if b == b' ' || b == b'\t' {
                if ok {
                    break;
                }
            } else {
                ok = false;
                break;
            }
        }
        if ok && n > 0 {
            // Allocate and leak
            let mut v: Vec<u8> = Vec::with_capacity(n);
            v.resize(n, 0);
            core::mem::forget(v);
            uart::write_str("Allocated ");
            uart::write_u64(n as u64);
            uart::write_line(" bytes (leaked).");
        } else {
            uart::write_line("Usage: alloc <bytes>");
        }
    } else {
        uart::write_str("Unknown command: ");
        uart::write_bytes(cmd);
        uart::write_line("");
    }
}

fn eq_cmd(a: &[u8], b: &[u8]) -> bool {
    if a.len() != b.len() {
        return false;
    }
    let mut i = 0;
    while i < a.len() {
        if a[i] != b[i] {
            return false;
        }
        i += 1;
    }
    true
}
</file>

<file path="kernel/src/uart.rs">
use core::fmt::{self, Write};

const UART_BASE: usize = 0x1000_0000;

pub struct Console;

impl Console {
    pub const fn new() -> Self {
        Self
    }

    #[inline(always)]
    fn data_reg() -> *mut u8 {
        UART_BASE as *mut u8
    }

    pub fn write_byte(&mut self, byte: u8) {
        unsafe {
            core::ptr::write_volatile(Self::data_reg(), byte);
        }
    }

    pub fn read_byte(&self) -> u8 {
        unsafe { core::ptr::read_volatile(Self::data_reg() as *const u8) }
    }
}

impl Write for Console {
    fn write_str(&mut self, s: &str) -> fmt::Result {
        for byte in s.bytes() {
            self.write_byte(byte);
        }
        Ok(())
    }
}

/// Write a raw string to the UART without using `core::fmt`.
pub fn write_str(s: &str) {
    let mut console = Console::new();
    let _ = console.write_str(s);
}

/// Write a raw string followed by `\n`.
pub fn write_line(s: &str) {
    write_str(s);
    write_str("\n");
}

/// Write a raw byte slice to the UART.
pub fn write_bytes(bytes: &[u8]) {
    let mut console = Console::new();
    for &b in bytes {
        console.write_byte(b);
    }
}

/// Write an unsigned integer in decimal.
pub fn write_u64(mut n: u64) {
    let mut console = Console::new();

    if n == 0 {
        console.write_byte(b'0');
        return;
    }

    let mut buf = [0u8; 20]; // enough for u64
    let mut i = 0;

    while n > 0 && i < buf.len() {
        let digit = (n % 10) as u8;
        buf[i] = b'0' + digit;
        n /= 10;
        i += 1;
    }

    while i > 0 {
        i -= 1;
        console.write_byte(buf[i]);
    }
}

#[macro_export]
macro_rules! print {
    ($($arg:tt)*) => ({
        $crate::uart::print_fmt(core::format_args!($($arg)*));
    });
}

#[macro_export]
macro_rules! println {
    () => ($crate::print!("\n"));
    ($fmt:expr $(, $($arg:tt)*)?) => ({
        $crate::uart::print_fmt(core::format_args!(concat!($fmt, "\n") $(, $($arg)*)?));
    });
}
</file>

<file path="kernel/build.rs">
use std::env;
use std::fs;
use std::path::PathBuf;

fn main() {
    println!("cargo:rerun-if-changed=memory.x");

    let out_dir = PathBuf::from(env::var("OUT_DIR").expect("OUT_DIR not set"));
    let target_script = out_dir.join("memory.x");
    fs::copy("memory.x", &target_script).expect("failed to copy memory.x");
    let link_script = out_dir.join("link.x");
    fs::copy("link.x", &link_script).expect("failed to copy link.x");
    println!("cargo:rustc-link-search={}", out_dir.display());
    println!("cargo:rustc-link-arg=-T{}", target_script.display());
    println!("cargo:rustc-link-arg=-T{}", link_script.display());
    println!("cargo:rerun-if-changed=build.rs");
}
</file>

<file path="kernel/Cargo.toml">
[package]
name = "kernel"
version = "0.1.0"
edition = "2021"

[dependencies]
riscv = "0.10.1"
riscv-rt = "0.11.0"
panic-halt = "0.2.0"

[profile.release]
strip = true
lto = true
</file>

<file path="kernel/link.x">
PROVIDE(_stext = ORIGIN(REGION_TEXT));
PROVIDE(_stack_start = ORIGIN(REGION_STACK) + LENGTH(REGION_STACK));
PROVIDE(_max_hart_id = 0);
PROVIDE(_hart_stack_size = 128K);
PROVIDE(_heap_size = 128K);

PROVIDE(UserSoft = DefaultHandler);
PROVIDE(SupervisorSoft = DefaultHandler);
PROVIDE(MachineSoft = DefaultHandler);
PROVIDE(UserTimer = DefaultHandler);
PROVIDE(SupervisorTimer = DefaultHandler);
PROVIDE(MachineTimer = DefaultHandler);
PROVIDE(UserExternal = DefaultHandler);
PROVIDE(SupervisorExternal = DefaultHandler);
PROVIDE(MachineExternal = DefaultHandler);

PROVIDE(DefaultHandler = DefaultInterruptHandler);
PROVIDE(ExceptionHandler = DefaultExceptionHandler);

/* # Pre-initialization function */
/* If the user overrides this using the `#[pre_init]` attribute or by creating a `__pre_init` function,
   then the function this points to will be called before the RAM is initialized. */
PROVIDE(__pre_init = default_pre_init);

/* A PAC/HAL defined routine that should initialize custom interrupt controller if needed. */
PROVIDE(_setup_interrupts = default_setup_interrupts);

/* # Multi-processing hook function
   fn _mp_hook() -> bool;

   This function is called from all the harts and must return true only for one hart,
   which will perform memory initialization. For other harts it must return false
   and implement wake-up in platform-dependent way (e.g. after waiting for a user interrupt).
*/
PROVIDE(_mp_hook = default_mp_hook);

/* # Start trap function override
  By default uses the riscv crates default trap handler
  but by providing the `_start_trap` symbol external crates can override.
*/
PROVIDE(_start_trap = default_start_trap);

SECTIONS
{
  .text.dummy (NOLOAD) :
  {
    /* This section is intended to make _stext address work */
    . = ABSOLUTE(_stext);
  } > REGION_TEXT

  .text _stext :
  {
    /* Put reset handler first in .text section so it ends up as the entry */
    /* point of the program. */
    KEEP(*(.init));
    KEEP(*(.init.rust));
    . = ALIGN(4);
    *(.trap);
    *(.trap.rust);

    *(.text .text.*);
  } > REGION_TEXT

  .rodata : ALIGN(4)
  {
    *(.srodata .srodata.*);
    *(.rodata .rodata.*);

    /* 4-byte align the end (VMA) of this section.
       This is required by LLD to ensure the LMA of the following .data
       section will have the correct alignment. */
    . = ALIGN(4);
  } > REGION_RODATA

  .data : ALIGN(4)
  {
    _sidata = LOADADDR(.data);
    _sdata = .;
    /* Must be called __global_pointer$ for linker relaxations to work. */
    PROVIDE(__global_pointer$ = . + 0x800);
    *(.sdata .sdata.* .sdata2 .sdata2.*);
    *(.data .data.*);
    . = ALIGN(4);
    _edata = .;
  } > REGION_DATA AT > REGION_RODATA

  .bss (NOLOAD) :
  {
    _sbss = .;
    *(.sbss .sbss.* .bss .bss.*);
    . = ALIGN(4);
    _ebss = .;
  } > REGION_BSS

  /* fictitious region that represents the memory available for the heap */
  .heap (NOLOAD) :
  {
    _sheap = .;
    . += _heap_size;
    . = ALIGN(4);
    _eheap = .;
  } > REGION_HEAP

  /* fictitious region that represents the memory available for the stack */
  .stack (NOLOAD) :
  {
    _estack = .;
    . = ABSOLUTE(_stack_start);
    _sstack = .;
  } > REGION_STACK

  /* fake output .got section */
  /* Dynamic relocations are unsupported. This section is only used to detect
     relocatable code in the input files and raise an error if relocatable code
     is found */
  .got (INFO) :
  {
    KEEP(*(.got .got.*));
  }

  /DISCARD/ :
  {
    *(.eh_frame)
    *(.eh_frame_hdr)
  }
}

/* Do not exceed this mark in the error messages above                                    | */
ASSERT(ORIGIN(REGION_TEXT) % 4 == 0, "
ERROR(riscv-rt): the start of the REGION_TEXT must be 4-byte aligned");

ASSERT(ORIGIN(REGION_RODATA) % 4 == 0, "
ERROR(riscv-rt): the start of the REGION_RODATA must be 4-byte aligned");

ASSERT(ORIGIN(REGION_DATA) % 4 == 0, "
ERROR(riscv-rt): the start of the REGION_DATA must be 4-byte aligned");

ASSERT(ORIGIN(REGION_HEAP) % 4 == 0, "
ERROR(riscv-rt): the start of the REGION_HEAP must be 4-byte aligned");

ASSERT(ORIGIN(REGION_TEXT) % 4 == 0, "
ERROR(riscv-rt): the start of the REGION_TEXT must be 4-byte aligned");

ASSERT(ORIGIN(REGION_STACK) % 4 == 0, "
ERROR(riscv-rt): the start of the REGION_STACK must be 4-byte aligned");

ASSERT(_stext % 4 == 0, "
ERROR(riscv-rt): `_stext` must be 4-byte aligned");

ASSERT(_sdata % 4 == 0 && _edata % 4 == 0, "
BUG(riscv-rt): .data is not 4-byte aligned");

ASSERT(_sidata % 4 == 0, "
BUG(riscv-rt): the LMA of .data is not 4-byte aligned");

ASSERT(_sbss % 4 == 0 && _ebss % 4 == 0, "
BUG(riscv-rt): .bss is not 4-byte aligned");

ASSERT(_sheap % 4 == 0, "
BUG(riscv-rt): start of .heap is not 4-byte aligned");

ASSERT(_stext + SIZEOF(.text) < ORIGIN(REGION_TEXT) + LENGTH(REGION_TEXT), "
ERROR(riscv-rt): The .text section must be placed inside the REGION_TEXT region.
Set _stext to an address smaller than 'ORIGIN(REGION_TEXT) + LENGTH(REGION_TEXT)'");

ASSERT(SIZEOF(.stack) > (_max_hart_id + 1) * _hart_stack_size, "
ERROR(riscv-rt): .stack section is too small for allocating stacks for all the harts.
Consider changing `_max_hart_id` or `_hart_stack_size`.");

ASSERT(SIZEOF(.got) == 0, "
.got section detected in the input files. Dynamic relocations are not
supported. If you are linking to C code compiled using the `gcc` crate
then modify your build script to compile the C code _without_ the
-fPIC flag. See the documentation of the `gcc::Config.fpic` method for
details.");

/* Do not exceed this mark in the error messages above                                    | */
</file>

<file path="kernel/memory.x">
MEMORY
{
    /* 
     * RAM starts at 0x80000000.
     * We allocate 512MB.
     */
    RAM : ORIGIN = 0x80000000, LENGTH = 512M
}

REGION_ALIAS("REGION_TEXT", RAM);
REGION_ALIAS("REGION_RODATA", RAM);
REGION_ALIAS("REGION_DATA", RAM);
REGION_ALIAS("REGION_BSS", RAM);
REGION_ALIAS("REGION_HEAP", RAM);
REGION_ALIAS("REGION_STACK", RAM);
</file>

<file path="vm/src/bus.rs">
use crate::clint::{Clint, CLINT_BASE, CLINT_SIZE};
use crate::plic::{Plic, PLIC_BASE, PLIC_SIZE};
use crate::uart::{Uart, UART_BASE, UART_SIZE};
use crate::virtio::VirtioDevice;
use crate::Trap;
use crate::dram::Dram;

/// Default DRAM base for the virt platform.
pub const DRAM_BASE: u64 = 0x8000_0000;

/// Base address of the RISC-V test finisher MMIO region.
pub const TEST_FINISHER_BASE: u64 = 0x0010_0000;
pub const TEST_FINISHER_SIZE: u64 = 0x1000;

/// VirtIO MMIO base address (for the first device).
pub const VIRTIO_BASE: u64 = 0x1000_1000;
/// Size of each VirtIO MMIO region.
pub const VIRTIO_STRIDE: u64 = 0x1000;

pub trait Bus {
    fn read8(&mut self, addr: u64) -> Result<u8, Trap>;
    fn read16(&mut self, addr: u64) -> Result<u16, Trap>;
    fn read32(&mut self, addr: u64) -> Result<u32, Trap>;
    fn read64(&mut self, addr: u64) -> Result<u64, Trap>;

    fn write8(&mut self, addr: u64, val: u8) -> Result<(), Trap>;
    fn write16(&mut self, addr: u64, val: u16) -> Result<(), Trap>;
    fn write32(&mut self, addr: u64, val: u32) -> Result<(), Trap>;
    fn write64(&mut self, addr: u64, val: u64) -> Result<(), Trap>;

    /// Generic load helper used by the MMU for page-table walks.
    fn load(&mut self, addr: u64, size: u64) -> Result<u64, Trap> {
        match size {
            1 => self.read8(addr).map(|v| v as u64),
            2 => self.read16(addr).map(|v| v as u64),
            4 => self.read32(addr).map(|v| v as u64),
            8 => self.read64(addr),
            _ => Err(Trap::Fatal(format!("Unsupported bus load size: {}", size))),
        }
    }

    /// Generic store helper used by the MMU for page-table A/D updates.
    fn store(&mut self, addr: u64, size: u64, value: u64) -> Result<(), Trap> {
        match size {
            1 => self.write8(addr, value as u8),
            2 => self.write16(addr, value as u16),
            4 => self.write32(addr, value as u32),
            8 => self.write64(addr, value),
            _ => Err(Trap::Fatal(format!("Unsupported bus store size: {}", size))),
        }
    }

    fn fetch_u32(&mut self, addr: u64) -> Result<u32, Trap> {
        if addr % 4 != 0 {
            return Err(Trap::InstructionAddressMisaligned(addr));
        }
        // Map LoadAccessFault to InstructionAccessFault for fetch
        self.read32(addr).map_err(|e| match e {
            Trap::LoadAccessFault(a) => Trap::InstructionAccessFault(a),
            Trap::LoadAddressMisaligned(a) => Trap::InstructionAddressMisaligned(a),
            _ => e,
        })
    }

    fn poll_interrupts(&mut self) -> u64 {
        0
    }
}

// A simple system bus that just wraps DRAM for now (Phase 1)
pub struct SystemBus {
    pub dram: Dram,
    pub clint: Clint,
    pub plic: Plic,
    pub uart: Uart,
    pub virtio_devices: Vec<Box<dyn VirtioDevice>>,
}

impl SystemBus {
    pub fn new(dram_base: u64, dram_size: usize) -> Self {
        Self {
            dram: Dram::new(dram_base, dram_size),
            clint: Clint::new(),
            plic: Plic::new(),
            uart: Uart::new(),
            virtio_devices: Vec::new(),
        }
    }

    pub fn dram_base(&self) -> u64 {
        self.dram.base
    }

    pub fn dram_size(&self) -> usize {
        self.dram.data.len()
    }

    pub fn check_interrupts(&mut self) -> u64 {
        // 0. Advance CLINT timer each step
        self.clint.tick();
        
        // 1. Update PLIC with UART status
        let uart_irq = self.uart.interrupting;
        self.plic.set_source_level(crate::plic::UART_IRQ, uart_irq);

        // 1b. Update PLIC with VirtIO interrupts
        // We map VirtIO devices to IRQs starting at VIRTIO0_IRQ (1).
        // Device 0 -> IRQ 1
        // Device 1 -> IRQ 2
        // ...
        // Device 7 -> IRQ 8
        // Note: xv6 expects VIRTIO0 at IRQ 1.
        for (i, dev) in self.virtio_devices.iter().enumerate() {
            let irq = crate::plic::VIRTIO0_IRQ + i as u32;
            if irq < 32 { // PLIC limit
                let intr = dev.is_interrupting();
                if intr && log::log_enabled!(log::Level::Trace) {
                     log::trace!("[Bus] VirtIO dev {} interrupting (irq {})", i, irq);
                }
                self.plic.set_source_level(irq, intr);
            }
        }

        // 2. Calculate MIP bits
        let mut mip = 0;

        // MSIP (Machine Software Interrupt) - Bit 3
        if self.clint.msip[0] & 1 != 0 {
            mip |= 1 << 3;
        }

        // MTIP (Machine Timer Interrupt) - Bit 7
        if self.clint.mtime >= self.clint.mtimecmp[0] {
            mip |= 1 << 7;
        }

        // SEIP (Supervisor External Interrupt) - Bit 9
        if self.plic.is_interrupt_pending_for(1) {
            mip |= 1 << 9;
        }

        // MEIP (Machine External Interrupt) - Bit 11
        if self.plic.is_interrupt_pending_for(0) {
            mip |= 1 << 11;
        }

        mip
    }

    fn get_virtio_device(&mut self, addr: u64) -> Option<(usize, u64)> {
        if addr >= VIRTIO_BASE {
            let offset = addr - VIRTIO_BASE;
            let idx = (offset / VIRTIO_STRIDE) as usize;
            if idx < self.virtio_devices.len() {
                return Some((idx, offset % VIRTIO_STRIDE));
            }
        }
        None
    }
}

impl Bus for SystemBus {
    fn poll_interrupts(&mut self) -> u64 {
        self.check_interrupts()
    }

    fn read8(&mut self, addr: u64) -> Result<u8, Trap> {
        // Test finisher region: reads are harmless and return zero.
        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Ok(0);
        }

        if let Some(off) = self.dram.offset(addr) {
            return Ok(self.dram.data[off]);
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            let val = self.clint.load(offset, 1);
            return Ok(val as u8);
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            let val = self.plic.load(offset, 1).map_err(|_| Trap::LoadAccessFault(addr))?;
            return Ok(val as u8);
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             let val = self.uart.load(offset, 1).map_err(|_| Trap::LoadAccessFault(addr))?;
             return Ok(val as u8);
        }

        if let Some((idx, offset)) = self.get_virtio_device(addr) {
            // Emulate narrow MMIO reads by extracting from the 32-bit register value
            let aligned = offset & !3;
            let word = self.virtio_devices[idx].read(aligned).map_err(|_| Trap::LoadAccessFault(addr))?;
            let shift = ((offset & 3) * 8) as u64;
            return Ok(((word >> shift) & 0xff) as u8);
        }

        Err(Trap::LoadAccessFault(addr))
    }

    fn read16(&mut self, addr: u64) -> Result<u16, Trap> {
        if addr % 2 != 0 {
            return Err(Trap::LoadAddressMisaligned(addr));
        }

        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Ok(0);
        }

        if let Some(off) = self.dram.offset(addr) {
            if off + 2 > self.dram.data.len() {
                return Err(Trap::LoadAccessFault(addr));
            }
            let bytes = &self.dram.data[off..off + 2];
            return Ok(u16::from_le_bytes(bytes.try_into().unwrap()));
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            let val = self.clint.load(offset, 2);
            return Ok(val as u16);
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            let val = self.plic.load(offset, 2).map_err(|_| Trap::LoadAccessFault(addr))?;
            return Ok(val as u16);
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             let val = self.uart.load(offset, 2).map_err(|_| Trap::LoadAccessFault(addr))?;
             return Ok(val as u16);
        }

        if let Some((idx, offset)) = self.get_virtio_device(addr) {
            let aligned = offset & !3;
            let word = self.virtio_devices[idx].read(aligned).map_err(|_| Trap::LoadAccessFault(addr))?;
            let shift = ((offset & 3) * 8) as u64;
            return Ok(((word >> shift) & 0xffff) as u16);
        }

        Err(Trap::LoadAccessFault(addr))
    }

    fn read32(&mut self, addr: u64) -> Result<u32, Trap> {
        if addr % 4 != 0 {
            return Err(Trap::LoadAddressMisaligned(addr));
        }

        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Ok(0);
        }

        if let Some(off) = self.dram.offset(addr) {
            if off + 4 > self.dram.data.len() {
                return Err(Trap::LoadAccessFault(addr));
            }
            let bytes = &self.dram.data[off..off + 4];
            return Ok(u32::from_le_bytes(bytes.try_into().unwrap()));
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            let val = self.clint.load(offset, 4);
            return Ok(val as u32);
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            let val = self.plic.load(offset, 4).map_err(|_| Trap::LoadAccessFault(addr))?;
            return Ok(val as u32);
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             let val = self.uart.load(offset, 4).map_err(|_| Trap::LoadAccessFault(addr))?;
             return Ok(val as u32);
        }

        if let Some((idx, offset)) = self.get_virtio_device(addr) {
            let val = self.virtio_devices[idx].read(offset).map_err(|_| Trap::LoadAccessFault(addr))?;
            return Ok(val as u32);
        }

        Err(Trap::LoadAccessFault(addr))
    }

    fn read64(&mut self, addr: u64) -> Result<u64, Trap> {
        if addr % 8 != 0 {
            return Err(Trap::LoadAddressMisaligned(addr));
        }

        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Ok(0);
        }

        if let Some(off) = self.dram.offset(addr) {
            if off + 8 > self.dram.data.len() {
                return Err(Trap::LoadAccessFault(addr));
            }
            let bytes = &self.dram.data[off..off + 8];
            return Ok(u64::from_le_bytes(bytes.try_into().unwrap()));
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            let val = self.clint.load(offset, 8);
            return Ok(val);
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            let val = self.plic.load(offset, 8).map_err(|_| Trap::LoadAccessFault(addr))?;
            return Ok(val);
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             let val = self.uart.load(offset, 8).map_err(|_| Trap::LoadAccessFault(addr))?;
             return Ok(val);
        }

        if let Some((idx, offset)) = self.get_virtio_device(addr) {
            let low = self.virtio_devices[idx].read(offset).map_err(|_| Trap::LoadAccessFault(addr))?;
            let high = self.virtio_devices[idx].read(offset + 4).map_err(|_| Trap::LoadAccessFault(addr + 4))?;
            return Ok((low as u64) | ((high as u64) << 32));
        }

        Err(Trap::LoadAccessFault(addr))
    }

    fn write8(&mut self, addr: u64, val: u8) -> Result<(), Trap> {
        // Any write in the test finisher region signals a requested trap to the host.
        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Err(Trap::RequestedTrap(val as u64));
        }

        if let Some(off) = self.dram.offset(addr) {
            self.dram.data[off] = val;
            return Ok(());
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            self.clint.store(offset, 1, val as u64);
            return Ok(());
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            self.plic.store(offset, 1, val as u64).map_err(|_| Trap::StoreAccessFault(addr))?;
            return Ok(());
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             self.uart.store(offset, 1, val as u64).map_err(|_| Trap::StoreAccessFault(addr))?;
             return Ok(());
        }

        if let Some((_idx, _offset)) = self.get_virtio_device(addr) {
            // VirtIO registers are 32-bit. Byte writes are not strictly supported by the spec for all registers.
            // We ignore them for now to be safe.
            return Ok(());
        }

        Err(Trap::StoreAccessFault(addr))
    }

    fn write16(&mut self, addr: u64, val: u16) -> Result<(), Trap> {
        if addr % 2 != 0 {
            return Err(Trap::StoreAddressMisaligned(addr));
        }

        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Err(Trap::RequestedTrap(val as u64));
        }

        if let Some(off) = self.dram.offset(addr) {
            if off + 2 > self.dram.data.len() {
                return Err(Trap::StoreAccessFault(addr));
            }
            let bytes = val.to_le_bytes();
            self.dram.data[off..off + 2].copy_from_slice(&bytes);
            return Ok(());
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            self.clint.store(offset, 2, val as u64);
            return Ok(());
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            self.plic.store(offset, 2, val as u64).map_err(|_| Trap::StoreAccessFault(addr))?;
            return Ok(());
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             self.uart.store(offset, 2, val as u64).map_err(|_| Trap::StoreAccessFault(addr))?;
             return Ok(());
        }

        if let Some((_idx, _offset)) = self.get_virtio_device(addr) {
            return Ok(());
        }

        Err(Trap::StoreAccessFault(addr))
    }

    fn write32(&mut self, addr: u64, val: u32) -> Result<(), Trap> {
        if addr % 4 != 0 {
            return Err(Trap::StoreAddressMisaligned(addr));
        }

        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Err(Trap::RequestedTrap(val as u64));
        }

        if let Some(off) = self.dram.offset(addr) {
            if off + 4 > self.dram.data.len() {
                return Err(Trap::StoreAccessFault(addr));
            }
            let bytes = val.to_le_bytes();
            self.dram.data[off..off + 4].copy_from_slice(&bytes);
            return Ok(());
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            self.clint.store(offset, 4, val as u64);
            return Ok(());
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            self.plic.store(offset, 4, val as u64).map_err(|_| Trap::StoreAccessFault(addr))?;
            return Ok(());
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             self.uart.store(offset, 4, val as u64).map_err(|_| Trap::StoreAccessFault(addr))?;
             return Ok(());
        }

        if let Some((idx, offset)) = self.get_virtio_device(addr) {
            self.virtio_devices[idx].write(offset, val as u64, &mut self.dram)
                .map_err(|_| Trap::StoreAccessFault(addr))?;
            return Ok(());
        }

        Err(Trap::StoreAccessFault(addr))
    }

    fn write64(&mut self, addr: u64, val: u64) -> Result<(), Trap> {
        if addr % 8 != 0 {
            return Err(Trap::StoreAddressMisaligned(addr));
        }

        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Err(Trap::RequestedTrap(val));
        }

        if let Some(off) = self.dram.offset(addr) {
            if off + 8 > self.dram.data.len() {
                return Err(Trap::StoreAccessFault(addr));
            }
            let bytes = val.to_le_bytes();
            self.dram.data[off..off + 8].copy_from_slice(&bytes);
            return Ok(());
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            self.clint.store(offset, 8, val);
            return Ok(());
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            self.plic.store(offset, 8, val).map_err(|_| Trap::StoreAccessFault(addr))?;
            return Ok(());
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             self.uart.store(offset, 8, val).map_err(|_| Trap::StoreAccessFault(addr))?;
             return Ok(());
        }

        if let Some((_idx, _offset)) = self.get_virtio_device(addr) {
            // VirtIO registers are 32-bit. 64-bit writes are not typically supported directly via MMIO
            // except for legacy queue PFN which is 32-bit anyway.
            return Ok(());
        }

        Err(Trap::StoreAccessFault(addr))
    }
}
</file>

<file path="vm/src/cpu.rs">
use crate::bus::Bus;
use crate::clint::{CLINT_BASE, MTIME_OFFSET};
use crate::csr::{
    Mode, CSR_MCAUSE, CSR_MEPC, CSR_MISA, CSR_MSTATUS, CSR_MTVEC, CSR_MTVAL, CSR_MIDELEG,
    CSR_MIE, CSR_MIP, CSR_SATP, CSR_MEDELEG, CSR_STVEC, CSR_SEPC, CSR_SCAUSE, CSR_STVAL, CSR_SIE,
    CSR_SSTATUS, CSR_SIP, CSR_TIME, CSR_MENVCFG, CSR_STIMECMP,
};
use crate::decoder::{self, Op, Register};
use crate::mmu::{self, AccessType as MmuAccessType, Tlb};
use crate::Trap;
use std::collections::HashMap;

pub struct Cpu {
    pub regs: [u64; 32],
    pub pc: u64,
    /// Reservation set address for LR/SC (granule-aligned), or None if no reservation.
    reservation: Option<u64>,
    /// Simple CSR storage for Zicsr (12-bit CSR address space).
    csrs: [u64; 4096],
    /// Current privilege mode (Machine/Supervisor/User).
    pub mode: Mode,
    /// Per-hart TLB for Sv39/Sv48 translation.
    pub tlb: Tlb,
}

impl Cpu {
    pub fn new(pc: u64) -> Self {
        let mut csrs = [0u64; 4096];
        // misa: rv64imac_zicsr_zifencei (value from phase-0.md)
        const MISA_RV64IMAC_ZICSR_ZIFENCEI: u64 = 0x4000_0000_0018_1125;
        csrs[CSR_MISA as usize] = MISA_RV64IMAC_ZICSR_ZIFENCEI;

        // mstatus initial value: all zeros except UXL/SXL can be left as 0 (WARL).
        csrs[CSR_MSTATUS as usize] = 0;

        Self {
            regs: [0; 32],
            pc,
            reservation: None,
            csrs,
            mode: Mode::Machine,
            tlb: Tlb::new(),
        }
    }

    /// Export the current CSR image into a compact map suitable for
    /// serialization in snapshots.
    pub fn export_csrs(&self) -> HashMap<u16, u64> {
        let mut map = HashMap::new();
        for (idx, &val) in self.csrs.iter().enumerate() {
            if val != 0 {
                map.insert(idx as u16, val);
            }
        }
        map
    }

    /// Restore CSRs from a previously exported map.
    ///
    /// Any CSR not present in the map is reset to 0. This is intentionally
    /// low-level and bypasses architectural WARL checks; it is only used for
    /// snapshot/restore.
    pub fn import_csrs(&mut self, map: &HashMap<u16, u64>) {
        self.csrs = [0u64; 4096];
        for (&addr, &val) in map.iter() {
            let idx = addr as usize;
            if idx < self.csrs.len() {
                self.csrs[idx] = val;
            }
        }
    }

    pub fn read_reg(&self, reg: Register) -> u64 {
        if reg == Register::X0 {
            0
        } else {
            self.regs[reg.to_usize()]
        }
    }

    pub fn write_reg(&mut self, reg: Register, val: u64) {
        if reg != Register::X0 {
            self.regs[reg.to_usize()] = val;
        }
    }

    fn reservation_granule(addr: u64) -> u64 {
        const GRANULE: u64 = 64;
        addr & !(GRANULE - 1)
    }

    fn clear_reservation_if_conflict(&mut self, addr: u64) {
        if let Some(res) = self.reservation {
            if Self::reservation_granule(res) == Self::reservation_granule(addr) {
                self.reservation = None;
            }
        }
    }

    pub fn read_csr(&self, addr: u16) -> Result<u64, Trap> {
        // Privilege checks per RISC-V privileged spec:
        // CSR address bits [9:8] encode the lowest privilege level that can access:
        //   00 = User, 01 = Supervisor, 10 = Hypervisor (reserved), 11 = Machine
        let required_priv = (addr >> 8) & 0x3;
        let current_priv = match self.mode {
            Mode::User => 0,
            Mode::Supervisor => 1,
            Mode::Machine => 3,
        };
        if current_priv < required_priv {
            return Err(Trap::IllegalInstruction(addr as u64));
        }

        match addr {
            CSR_SSTATUS => {
                let mstatus = self.csrs[CSR_MSTATUS as usize];
                // Mask for sstatus view: SIE(1), SPIE(5), SPP(8), FS(13:14), XS(15:16), SUM(18), MXR(19), UXL(32:33), SD(63)
                // Simplified mask for this emulator:
                let mask = (1 << 1) | (1 << 5) | (1 << 8) | (3 << 13) | (1 << 18) | (1 << 19);
                Ok(mstatus & mask)
            }
            CSR_SIE => {
                let mie = self.csrs[CSR_MIE as usize];
                // Mask delegated interrupts: SSIP(1), STIP(5), SEIP(9)
                let mask = (1 << 1) | (1 << 5) | (1 << 9);
                Ok(mie & mask)
            }
            CSR_SIP => {
                let mip = self.csrs[CSR_MIP as usize];
                let mask = (1 << 1) | (1 << 5) | (1 << 9);
                Ok(mip & mask)
            }
            _ => Ok(self.csrs[addr as usize]),
        }
    }

    pub fn write_csr(&mut self, addr: u16, val: u64) -> Result<(), Trap> {
        // Read-only CSRs have bits [11:10] == 0b11
        let read_only = (addr >> 10) & 0x3 == 0x3;
        if read_only {
            // Writes to read-only CSRs are ignored (WARL behavior for some, illegal for others)
            // For simplicity, we just ignore the write
            return Ok(());
        }
        
        // Privilege checks per RISC-V privileged spec:
        // CSR address bits [9:8] encode the lowest privilege level that can access
        let required_priv = (addr >> 8) & 0x3;
        let current_priv = match self.mode {
            Mode::User => 0,
            Mode::Supervisor => 1,
            Mode::Machine => 3,
        };
        if current_priv < required_priv {
            return Err(Trap::IllegalInstruction(addr as u64));
        }

        match addr {
            CSR_SSTATUS => {
                let mut mstatus = self.csrs[CSR_MSTATUS as usize];
                let mask = (1 << 1) | (1 << 5) | (1 << 8) | (3 << 13) | (1 << 18) | (1 << 19);
                mstatus = (mstatus & !mask) | (val & mask);
                self.csrs[CSR_MSTATUS as usize] = mstatus;
                Ok(())
            }
            CSR_SIE => {
                let mut mie = self.csrs[CSR_MIE as usize];
                let mask = (1 << 1) | (1 << 5) | (1 << 9);
                mie = (mie & !mask) | (val & mask);
                self.csrs[CSR_MIE as usize] = mie;
                Ok(())
            }
            CSR_SIP => {
                let mut mip = self.csrs[CSR_MIP as usize];
                // Only SSIP is writable in SIP
                let mask = 1 << 1;
                mip = (mip & !mask) | (val & mask);
                self.csrs[CSR_MIP as usize] = mip;
                Ok(())
            }
            _ => {
                self.csrs[addr as usize] = val;
                Ok(())
            }
        }
    }

    /// Map a `Trap` into (is_interrupt, cause, tval) per privileged spec, or `None` if it's a host-only error.
    fn trap_to_cause_tval(trap: &Trap) -> Option<(bool, u64, u64)> {
        match *trap {
            Trap::InstructionAddressMisaligned(addr) => Some((false, 0, addr)),
            Trap::InstructionAccessFault(addr) => Some((false, 1, addr)),
            Trap::IllegalInstruction(bits) => Some((false, 2, bits)),
            Trap::Breakpoint => Some((false, 3, 0)),
            Trap::LoadAddressMisaligned(addr) => Some((false, 4, addr)),
            Trap::LoadAccessFault(addr) => Some((false, 5, addr)),
            Trap::StoreAddressMisaligned(addr) => Some((false, 6, addr)),
            Trap::StoreAccessFault(addr) => Some((false, 7, addr)),
            Trap::EnvironmentCallFromU => Some((false, 8, 0)),
            Trap::EnvironmentCallFromS => Some((false, 9, 0)),
            Trap::EnvironmentCallFromM => Some((false, 11, 0)),
            Trap::InstructionPageFault(addr) => Some((false, 12, addr)),
            Trap::LoadPageFault(addr) => Some((false, 13, addr)),
            Trap::StorePageFault(addr) => Some((false, 15, addr)),
            
            Trap::SupervisorSoftwareInterrupt => Some((true, 1, 0)),
            Trap::MachineSoftwareInterrupt => Some((true, 3, 0)),
            Trap::SupervisorTimerInterrupt => Some((true, 5, 0)),
            Trap::MachineTimerInterrupt => Some((true, 7, 0)),
            Trap::SupervisorExternalInterrupt => Some((true, 9, 0)),
            Trap::MachineExternalInterrupt => Some((true, 11, 0)),

            Trap::RequestedTrap(_) | Trap::Fatal(_) => None,
        }
    }

    fn handle_trap<T>(&mut self, trap: Trap, pc: u64, _insn_raw: Option<u32>) -> Result<T, Trap> {
        // Fatal/host-only traps bypass architectural trap entry.
        if let Some((is_interrupt, cause, tval)) = Self::trap_to_cause_tval(&trap) {
            // Determine delegation target per medeleg/mideleg
            let medeleg = self.csrs[CSR_MEDELEG as usize];
            let mideleg = self.csrs[CSR_MIDELEG as usize];
            let deleg_bit = 1u64 << (cause as u64);

            let deleg_to_s = match self.mode {
                // Delegation to a lower privilege is only meaningful when not in Machine mode
                Mode::Machine => false,
                _ => {
                    if is_interrupt {
                        (mideleg & deleg_bit) != 0
                    } else {
                        (medeleg & deleg_bit) != 0
                    }
                }
            };

            if deleg_to_s {
                // Supervisor trap entry (do not modify M-mode CSRs)
                // Save faulting PC and tval to supervisor CSRs
                self.csrs[CSR_SEPC as usize] = pc;
                self.csrs[CSR_STVAL as usize] = tval;
                let scause_val = ((is_interrupt as u64) << 63) | (cause & 0x7FFF_FFFF_FFFF_FFFF);
                self.csrs[CSR_SCAUSE as usize] = scause_val;

                // Update mstatus: SPP, SPIE, clear SIE
                let mut mstatus = self.csrs[CSR_MSTATUS as usize];
                if log::log_enabled!(log::Level::Trace) {
                    log::trace!("Trap to S-mode: mstatus_before={:x}", mstatus);
                }
                
                let sie = (mstatus >> 1) & 1;
                // SPIE <= SIE
                mstatus = (mstatus & !(1 << 5)) | (sie << 5);
                // SIE <= 0
                mstatus &= !(1 << 1);
                // SPP <= current privilege (1 if S, 0 if U)
                let spp = match self.mode {
                    Mode::Supervisor => 1,
                    _ => 0,
                };
                mstatus = (mstatus & !(1 << 8)) | (spp << 8);
                self.csrs[CSR_MSTATUS as usize] = mstatus;
                
                if log::log_enabled!(log::Level::Trace) {
                    log::trace!("Trap to S-mode: mstatus_after={:x}", mstatus);
                }

                self.mode = Mode::Supervisor;

                // Set PC to stvec (vectored if interrupt and mode==1)
                let stvec = self.csrs[CSR_STVEC as usize];
                let base = stvec & !0b11;
                let mode = stvec & 0b11;
                let vectored = mode == 1;
                let target_pc = if is_interrupt && vectored {
                    base.wrapping_add(4 * cause)
                } else {
                    base
                };
                self.pc = target_pc;
            } else {
                // Machine trap entry (default)
                // Save faulting PC and tval.
                self.csrs[CSR_MEPC as usize] = pc;
                self.csrs[CSR_MTVAL as usize] = tval;

                let mcause_val = ((is_interrupt as u64) << 63) | (cause & 0x7FFF_FFFF_FFFF_FFFF);
                self.csrs[CSR_MCAUSE as usize] = mcause_val;

                // Update mstatus: MPP, MPIE, clear MIE
                let mut mstatus = self.csrs[CSR_MSTATUS as usize];
                let mie = (mstatus >> 3) & 1;
                // MPIE <= MIE, MIE <= 0
                mstatus = (mstatus & !(1 << 7)) | (mie << 7);
                mstatus &= !(1 << 3);
                // MPP <= current mode.
                let mpp = self.mode.to_mpp();
                mstatus = (mstatus & !(0b11 << 11)) | (mpp << 11);
                self.csrs[CSR_MSTATUS as usize] = mstatus;
                self.mode = Mode::Machine;

                // Set PC to mtvec (vectored if interrupt and mode==1)
                let mtvec = self.csrs[CSR_MTVEC as usize];
                let base = mtvec & !0b11;
                let mode = mtvec & 0b11;
                let vectored = mode == 1;
                let target_pc = if is_interrupt && vectored {
                    base.wrapping_add(4 * cause)
                } else {
                    base
                };
                self.pc = target_pc;
            }
        }

        Err(trap)
    }

    /// Translate a virtual address to a physical address using the MMU.
    ///
    /// On translation failure, this enters the trap handler and returns the
    /// trap via `Err`.
    fn translate_addr(
        &mut self,
        bus: &mut dyn Bus,
        vaddr: u64,
        access: MmuAccessType,
        pc: u64,
        insn_raw: Option<u32>,
    ) -> Result<u64, Trap> {
        let satp = self.csrs[CSR_SATP as usize];
        let mstatus = self.csrs[CSR_MSTATUS as usize];
        match mmu::translate(bus, &mut self.tlb, self.mode, satp, mstatus, vaddr, access) {
            Ok(pa) => Ok(pa),
            Err(trap) => self.handle_trap(trap, pc, insn_raw),
        }
    }

    fn fetch_and_expand(&mut self, bus: &mut dyn Bus) -> Result<(u32, u8), Trap> {
        let pc = self.pc;
        if pc % 2 != 0 {
            return self.handle_trap(Trap::InstructionAddressMisaligned(pc), pc, None);
        }

        // Fetch first halfword via MMU (instruction access).
        let pa_low = self.translate_addr(bus, pc, MmuAccessType::Instruction, pc, None)?;
        let half = match bus.read16(pa_low) {
            Ok(v) => v,
            Err(e) => {
                // Map load faults from the bus into instruction faults.
                let mapped = match e {
                    Trap::LoadAccessFault(_) => Trap::InstructionAccessFault(pc),
                    Trap::LoadAddressMisaligned(_) => Trap::InstructionAddressMisaligned(pc),
                    other => other,
                };
                return self.handle_trap(mapped, pc, None);
            }
        };

        if half & 0x3 != 0x3 {
            // Compressed 16-bit instruction
            let insn32 = match decoder::expand_compressed(half) {
                Ok(v) => v,
                Err(trap) => return self.handle_trap(trap, pc, None),
            };
            Ok((insn32, 2))
        } else {
            // 32-bit instruction; fetch high half via MMU as well.
            let pc_hi = pc.wrapping_add(2);
            let pa_hi = self.translate_addr(bus, pc_hi, MmuAccessType::Instruction, pc, None)?;
            let hi = match bus.read16(pa_hi) {
                Ok(v) => v,
                Err(e) => {
                    let mapped = match e {
                        Trap::LoadAccessFault(_) => Trap::InstructionAccessFault(pc),
                        Trap::LoadAddressMisaligned(_) => Trap::InstructionAddressMisaligned(pc),
                        other => other,
                    };
                    return self.handle_trap(mapped, pc, None);
                }
            };
            let insn32 = (half as u32) | ((hi as u32) << 16);
            Ok((insn32, 4))
        }
    }

    fn check_pending_interrupt(&self) -> Option<Trap> {
        let mstatus = self.csrs[CSR_MSTATUS as usize];
        let mip = self.csrs[CSR_MIP as usize];
        let mie = self.csrs[CSR_MIE as usize];
        let mideleg = self.csrs[CSR_MIDELEG as usize];

        // SIE is a shadow of MIE for supervisor interrupt bits (SSIP=1, STIP=5, SEIP=9)
        let sie_mask: u64 = (1 << 1) | (1 << 5) | (1 << 9);
        let sie = mie & sie_mask;

        // Mask delegated interrupts out of machine set, and into supervisor set.
        let m_pending = (mip & mie) & !mideleg;
        let s_pending = (mip & sie) & mideleg;

        // Machine mode global enable:
        // Enabled if (currently in Machine and MIE==1) OR (currently below Machine).
        let m_enabled = match self.mode {
            Mode::Machine => ((mstatus >> 3) & 1) == 1, // MIE
            _ => true,
        };
        if m_enabled {
            if (m_pending & (1 << 11)) != 0 { return Some(Trap::MachineExternalInterrupt); } // MEIP
            if (m_pending & (1 << 3)) != 0 { return Some(Trap::MachineSoftwareInterrupt); }   // MSIP
            if (m_pending & (1 << 7)) != 0 { return Some(Trap::MachineTimerInterrupt); }      // MTIP
        }

        // Supervisor mode global enable:
        // Enabled if (currently in Supervisor and SIE==1) OR (currently in User).
        let s_enabled = match self.mode {
            Mode::Machine => false,
            Mode::Supervisor => ((mstatus >> 1) & 1) == 1, // SIE
            Mode::User => true,
        };
        
        // DEBUG: Check if we are about to trap for interrupt when we shouldn't
        if s_enabled && s_pending != 0 {
             if log::log_enabled!(log::Level::Trace) {
                 log::trace!("Interrupt pending: s_pending={:x} mstatus={:x} mode={:?}", s_pending, mstatus, self.mode);
             }
        }

        if s_enabled {
            if (s_pending & (1 << 9)) != 0 { return Some(Trap::SupervisorExternalInterrupt); } // SEIP
            if (s_pending & (1 << 1)) != 0 { return Some(Trap::SupervisorSoftwareInterrupt); } // SSIP
            if (s_pending & (1 << 5)) != 0 { return Some(Trap::SupervisorTimerInterrupt); }    // STIP
        }

        None
    }

    pub fn step(&mut self, bus: &mut dyn Bus) -> Result<(), Trap> {
        // Poll device-driven interrupts into MIP mask.
        let mut hw_mip = bus.poll_interrupts();

        // Sstc support: raise STIP (bit 5) when time >= stimecmp and Sstc enabled.
        // menvcfg[63] gate is optional; xv6 enables it.
        let menvcfg = self.csrs[CSR_MENVCFG as usize];
        let sstc_enabled = ((menvcfg >> 63) & 1) == 1;
        let stimecmp = self.csrs[CSR_STIMECMP as usize];
        if sstc_enabled && stimecmp != 0 {
            // Read CLINT MTIME directly (physical address).
            if let Ok(now) = bus.read64(CLINT_BASE + MTIME_OFFSET) {
                if now >= stimecmp {
                    hw_mip |= 1 << 5; // STIP
                }
            }
        }

        // Update MIP: preserve software-writable bits (SSIP=bit1, STIP=bit5 if not Sstc),
        // but always update hardware-driven bits (MSIP=3, MTIP=7, SEIP=9, MEIP=11).
        // SSIP (bit 1) is software-writable and should be preserved.
        // STIP (bit 5) is normally read-only but Sstc makes it hardware-driven.
        let hw_bits: u64 = (1 << 3) | (1 << 7) | (1 << 9) | (1 << 11); // MSIP, MTIP, SEIP, MEIP
        let hw_bits_with_stip: u64 = hw_bits | (1 << 5); // Include STIP when Sstc enabled
        
        let mask = if sstc_enabled { hw_bits_with_stip } else { hw_bits };
        let old_mip = self.csrs[CSR_MIP as usize];
        self.csrs[CSR_MIP as usize] = (old_mip & !mask) | (hw_mip & mask);
        
        if let Some(trap) = self.check_pending_interrupt() {
            return self.handle_trap(trap, self.pc, None);
        }

        let pc = self.pc;
        // Fetch (supports compressed 16-bit and regular 32-bit instructions)
        let (insn_raw, insn_len) = self.fetch_and_expand(bus)?;
        // Decode
        let op = match decoder::decode(insn_raw) {
            Ok(v) => v,
            Err(trap) => return self.handle_trap(trap, pc, Some(insn_raw)),
        };

        let mut next_pc = pc.wrapping_add(insn_len as u64);

        match op {
            Op::Lui { rd, imm } => {
                self.write_reg(rd, imm as u64);
            }
            Op::Auipc { rd, imm } => {
                self.write_reg(rd, pc.wrapping_add(imm as u64));
            }
            Op::Jal { rd, imm } => {
                self.write_reg(rd, pc.wrapping_add(insn_len as u64));
                next_pc = pc.wrapping_add(imm as u64);
                if next_pc % 2 != 0 {
                    return self.handle_trap(
                        Trap::InstructionAddressMisaligned(next_pc),
                        pc,
                        Some(insn_raw),
                    );
                }
            }
            Op::Jalr { rd, rs1, imm } => {
                let target = self.read_reg(rs1).wrapping_add(imm as u64) & !1;
                self.write_reg(rd, pc.wrapping_add(insn_len as u64));
                next_pc = target;
                if next_pc % 2 != 0 {
                    return self.handle_trap(
                        Trap::InstructionAddressMisaligned(next_pc),
                        pc,
                        Some(insn_raw),
                    );
                }
            }
            Op::Branch {
                rs1,
                rs2,
                imm,
                funct3,
            } => {
                let val1 = self.read_reg(rs1);
                let val2 = self.read_reg(rs2);
                let taken = match funct3 {
                    0 => val1 == val2,                   // BEQ
                    1 => val1 != val2,                   // BNE
                    4 => (val1 as i64) < (val2 as i64),  // BLT
                    5 => (val1 as i64) >= (val2 as i64), // BGE
                    6 => val1 < val2,                    // BLTU
                    7 => val1 >= val2,                   // BGEU
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                if taken {
                    next_pc = pc.wrapping_add(imm as u64);
                    if next_pc % 2 != 0 {
                        return self.handle_trap(
                            Trap::InstructionAddressMisaligned(next_pc),
                            pc,
                            Some(insn_raw),
                        );
                    }
                }
            }
            Op::Load {
                rd,
                rs1,
                imm,
                funct3,
            } => {
                let addr = self.read_reg(rs1).wrapping_add(imm as u64);
                let val = match funct3 {
                    0 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read8(pa) {
                        Ok(v) => (v as i8) as i64 as u64, // LB
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    1 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read16(pa) {
                        Ok(v) => (v as i16) as i64 as u64, // LH
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    2 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read32(pa) {
                        Ok(v) => (v as i32) as i64 as u64, // LW
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    3 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read64(pa) {
                        Ok(v) => v, // LD
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    4 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read8(pa) {
                        Ok(v) => v as u64, // LBU
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    5 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read16(pa) {
                        Ok(v) => v as u64, // LHU
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    6 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read32(pa) {
                        Ok(v) => v as u64, // LWU
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                self.write_reg(rd, val);
            }
            Op::Store {
                rs1,
                rs2,
                imm,
                funct3,
            } => {
                let addr = self.read_reg(rs1).wrapping_add(imm as u64);
                let pa = self.translate_addr(bus, addr, MmuAccessType::Store, pc, Some(insn_raw))?;
                // Any store to the reservation granule clears LR/SC reservation.
                self.clear_reservation_if_conflict(addr);
                let val = self.read_reg(rs2);
                let res = match funct3 {
                    0 => bus.write8(pa, val as u8),   // SB
                    1 => bus.write16(pa, val as u16), // SH
                    2 => bus.write32(pa, val as u32), // SW
                    3 => bus.write64(pa, val),        // SD
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                if let Err(e) = res {
                    return self.handle_trap(e, pc, Some(insn_raw));
                }
            }
            Op::OpImm {
                rd,
                rs1,
                imm,
                funct3,
                funct7,
            } => {
                let val1 = self.read_reg(rs1);
                let res = match funct3 {
                    0 => val1.wrapping_add(imm as u64), // ADDI
                    2 => {
                        if (val1 as i64) < imm {
                            1
                        } else {
                            0
                        }
                    } // SLTI
                    3 => {
                        if val1 < (imm as u64) {
                            1
                        } else {
                            0
                        }
                    } // SLTIU
                    4 => val1 ^ (imm as u64),           // XORI
                    6 => val1 | (imm as u64),           // ORI
                    7 => val1 & (imm as u64),           // ANDI
                    1 => {
                        // SLLI
                        let shamt = imm & 0x3F;
                        val1 << shamt
                    }
                    5 => {
                        // SRLI / SRAI
                        let shamt = imm & 0x3F;
                        if funct7 & 0x20 != 0 {
                            // SRAI
                            ((val1 as i64) >> shamt) as u64
                        } else {
                            // SRLI
                            val1 >> shamt
                        }
                    }
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                self.write_reg(rd, res);
            }
            Op::Op {
                rd,
                rs1,
                rs2,
                funct3,
                funct7,
            } => {
                let val1 = self.read_reg(rs1);
                let val2 = self.read_reg(rs2);
                let res = match (funct3, funct7) {
                    (0, 0x00) => val1.wrapping_add(val2), // ADD
                    (0, 0x20) => val1.wrapping_sub(val2), // SUB
                    // M-extension (RV64M) - MUL/DIV/REM on XLEN=64
                    (0, 0x01) => {
                        // MUL: low 64 bits of signed(rs1) * signed(rs2)
                        let a = val1 as i64 as i128;
                        let b = val2 as i64 as i128;
                        (a.wrapping_mul(b) as i64) as u64
                    }
                    (1, 0x00) => val1 << (val2 & 0x3F), // SLL
                    (1, 0x01) => {
                        // MULH: high 64 bits of signed * signed
                        let a = val1 as i64 as i128;
                        let b = val2 as i64 as i128;
                        ((a.wrapping_mul(b) >> 64) as i64) as u64
                    }
                    (2, 0x00) => {
                        if (val1 as i64) < (val2 as i64) {
                            1
                        } else {
                            0
                        }
                    } // SLT
                    (2, 0x01) => {
                        // MULHSU: high 64 bits of signed * unsigned
                        let a = val1 as i64 as i128;
                        let b = val2 as u64 as i128;
                        ((a.wrapping_mul(b) >> 64) as i64) as u64
                    }
                    (3, 0x00) => {
                        if val1 < val2 {
                            1
                        } else {
                            0
                        }
                    } // SLTU
                    (3, 0x01) => {
                        // MULHU: high 64 bits of unsigned * unsigned
                        let a = val1 as u128;
                        let b = val2 as u128;
                        ((a.wrapping_mul(b) >> 64) as u64) as u64
                    }
                    (4, 0x00) => val1 ^ val2, // XOR
                    (4, 0x01) => {
                        // DIV (signed)
                        let a = val1 as i64;
                        let b = val2 as i64;
                        let q = if b == 0 {
                            -1i64
                        } else if a == i64::MIN && b == -1 {
                            i64::MIN
                        } else {
                            a / b
                        };
                        q as u64
                    }
                    (5, 0x00) => val1 >> (val2 & 0x3F), // SRL
                    (5, 0x01) => {
                        // DIVU (unsigned)
                        let a = val1;
                        let b = val2;
                        let q = if b == 0 { u64::MAX } else { a / b };
                        q
                    }
                    (5, 0x20) => ((val1 as i64) >> (val2 & 0x3F)) as u64, // SRA
                    (6, 0x00) => val1 | val2,                              // OR
                    (6, 0x01) => {
                        // REM (signed)
                        let a = val1 as i64;
                        let b = val2 as i64;
                        let r = if b == 0 {
                            a
                        } else if a == i64::MIN && b == -1 {
                            0
                        } else {
                            a % b
                        };
                        r as u64
                    }
                    (7, 0x00) => val1 & val2, // AND
                    (7, 0x01) => {
                        // REMU (unsigned)
                        let a = val1;
                        let b = val2;
                        let r = if b == 0 { a } else { a % b };
                        r
                    }
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                self.write_reg(rd, res);
            }
            Op::OpImm32 {
                rd,
                rs1,
                imm,
                funct3,
                funct7,
            } => {
                let val1 = self.read_reg(rs1);
                let res = match funct3 {
                    0 => (val1.wrapping_add(imm as u64) as i32) as i64 as u64, // ADDIW
                    1 => ((val1 as u32) << (imm & 0x1F)) as i32 as i64 as u64, // SLLIW
                    5 => {
                        let shamt = imm & 0x1F;
                        if funct7 & 0x20 != 0 {
                            // SRAIW
                            ((val1 as i32) >> shamt) as i64 as u64
                        } else {
                            // SRLIW
                            ((val1 as u32) >> shamt) as i32 as i64 as u64
                        }
                    }
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                self.write_reg(rd, res);
            }
            Op::Op32 {
                rd,
                rs1,
                rs2,
                funct3,
                funct7,
            } => {
                let val1 = self.read_reg(rs1);
                let val2 = self.read_reg(rs2);
                let res = match (funct3, funct7) {
                    (0, 0x00) => (val1.wrapping_add(val2) as i32) as i64 as u64, // ADDW
                    (0, 0x20) => (val1.wrapping_sub(val2) as i32) as i64 as u64, // SUBW
                    (0, 0x01) => {
                        // MULW: low 32 bits of signed* signed, sign-extended to 64
                        let a = val1 as i32 as i64;
                        let b = val2 as i32 as i64;
                        let prod = (a as i128).wrapping_mul(b as i128);
                        (prod as i32) as i64 as u64
                    }
                    (1, 0x00) => ((val1 as u32) << (val2 & 0x1F)) as i32 as i64 as u64, // SLLW
                    (5, 0x00) => ((val1 as u32) >> (val2 & 0x1F)) as i32 as i64 as u64, // SRLW
                    (4, 0x01) => {
                        // DIVW (signed 32-bit)
                        let a = val1 as i32 as i64;
                        let b = val2 as i32 as i64;
                        let q = if b == 0 {
                            -1i64
                        } else if a == i64::from(i32::MIN) && b == -1 {
                            i64::from(i32::MIN)
                        } else {
                            a / b
                        };
                        (q as i32) as i64 as u64
                    }
                    (5, 0x20) => ((val1 as i32) >> (val2 & 0x1F)) as i64 as u64, // SRAW
                    (5, 0x01) => {
                        // DIVUW (unsigned 32-bit)
                        let a = val1 as u32 as u64;
                        let b = val2 as u32 as u64;
                        let q = if b == 0 { u64::MAX } else { a / b };
                        (q as u32) as i32 as i64 as u64
                    }
                    (6, 0x01) => {
                        // REMW (signed 32-bit)
                        let a = val1 as i32 as i64;
                        let b = val2 as i32 as i64;
                        let r = if b == 0 {
                            a
                        } else if a == i64::from(i32::MIN) && b == -1 {
                            0
                        } else {
                            a % b
                        };
                        (r as i32) as i64 as u64
                    }
                    (7, 0x01) => {
                        // REMUW (unsigned 32-bit)
                        let a = val1 as u32 as u64;
                        let b = val2 as u32 as u64;
                        let r = if b == 0 { a } else { a % b };
                        (r as u32) as i32 as i64 as u64
                    }
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                self.write_reg(rd, res);
            }
            Op::Amo {
                rd,
                rs1,
                rs2,
                funct3,
                funct5,
                ..
            } => {
                let addr = self.read_reg(rs1);

                // Translate once per AMO/LD/ST sequence.
                let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;

                // Only word (funct3=2) and doubleword (funct3=3) widths are valid.
                let is_word = match funct3 {
                    2 => true,
                    3 => false,
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };

                // LR/SC vs AMO op distinguished by funct5
                match funct5 {
                    0b00010 => {
                        // LR.W / LR.D
                        let loaded = if is_word {
                            match bus.read32(pa) {
                                Ok(v) => v as i32 as i64 as u64,
                                Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                            }
                        } else {
                            match bus.read64(pa) {
                                Ok(v) => v,
                                Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                            }
                        };
                        self.write_reg(rd, loaded);
                        self.reservation = Some(Self::reservation_granule(addr));
                    }
                    0b00011 => {
                        // SC.W / SC.D
                        // Alignment checks (must be naturally aligned) on the virtual address.
                        if is_word && addr % 4 != 0 {
                            return self.handle_trap(
                                Trap::StoreAddressMisaligned(addr),
                                pc,
                                Some(insn_raw),
                            );
                        }
                        if !is_word && addr % 8 != 0 {
                            return self.handle_trap(
                                Trap::StoreAddressMisaligned(addr),
                                pc,
                                Some(insn_raw),
                            );
                        }
                        let granule = Self::reservation_granule(addr);
                        if self.reservation == Some(granule) {
                            // Successful store
                            let val = self.read_reg(rs2);
                            let res = if is_word {
                                bus.write32(pa, val as u32)
                            } else {
                                bus.write64(pa, val)
                            };
                            if let Err(e) = res {
                                return self.handle_trap(e, pc, Some(insn_raw));
                            }
                            self.write_reg(rd, 0);
                            self.reservation = None;
                        } else {
                            // Failed store, no memory access
                            self.write_reg(rd, 1);
                        }
                    }
                    // AMO* operations
                    0b00001 | // AMOSWAP
                    0b00000 | // AMOADD
                    0b00100 | // AMOXOR
                    0b01000 | // AMOOR
                    0b01100 | // AMOAND
                    0b10000 | // AMOMIN
                    0b10100 | // AMOMAX
                    0b11000 | // AMOMINU
                    0b11100 // AMOMAXU
                    => {
                        // Any AMO acts like a store to the address, so clear reservation.
                        self.clear_reservation_if_conflict(addr);

                        let old = if is_word {
                            match bus.read32(pa) {
                                Ok(v) => v as i32 as i64 as u64,
                                Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                            }
                        } else {
                            match bus.read64(pa) {
                                Ok(v) => v,
                                Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                            }
                        };
                        let rs2_val = self.read_reg(rs2);

                        let new_val = match funct5 {
                            0b00001 => rs2_val,                        // AMOSWAP
                            0b00000 => old.wrapping_add(rs2_val),      // AMOADD
                            0b00100 => old ^ rs2_val,                  // AMOXOR
                            0b01000 => old | rs2_val,                  // AMOOR
                            0b01100 => old & rs2_val,                  // AMOAND
                            0b10000 => {
                                // AMOMIN (signed)
                                let a = old as i64;
                                let b = rs2_val as i64;
                                if a < b { old } else { rs2_val }
                            }
                            0b10100 => {
                                // AMOMAX (signed)
                                let a = old as i64;
                                let b = rs2_val as i64;
                                if a > b { old } else { rs2_val }
                            }
                            0b11000 => {
                                // AMOMINU (unsigned)
                                if old < rs2_val { old } else { rs2_val }
                            }
                            0b11100 => {
                                // AMOMAXU (unsigned)
                                if old > rs2_val { old } else { rs2_val }
                            }
                            _ => unreachable!(),
                        };

                        let res = if is_word {
                            bus.write32(pa, new_val as u32)
                        } else {
                            bus.write64(pa, new_val)
                        };
                        if let Err(e) = res {
                            return self.handle_trap(e, pc, Some(insn_raw));
                        }

                        // rd receives the original loaded value (sign-extended to XLEN)
                        self.write_reg(rd, old);
                    }
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        );
                    }
                }
            }
            Op::System {
                rd,
                rs1,
                funct3,
                imm,
                ..
            } => {
                match funct3 {
                    0 => {
                        // SYSTEM (ECALL/EBREAK, MRET/SRET, SFENCE.VMA)

                        // Detect SFENCE.VMA via mask/match (funct7=0001001, opcode=0x73, rd=0).
                        const SFENCE_VMA_MASK: u32 = 0b1111111_00000_00000_111_00000_1111111;
                        const SFENCE_VMA_MATCH: u32 = 0b0001001_00000_00000_000_00000_1110011; // 0x12000073

                        if (insn_raw & SFENCE_VMA_MASK) == SFENCE_VMA_MATCH {
                            // Only legal from S or M mode.
                            if matches!(self.mode, Mode::User) {
                                return self.handle_trap(
                                    Trap::IllegalInstruction(insn_raw as u64),
                                    pc,
                                    Some(insn_raw),
                                );
                            }
                            // Simplest implementation: flush entire TLB.
                            self.tlb.flush();
                        } else {
                            match insn_raw {
                                0x0010_0073 => {
                                    // EBREAK
                                    return self.handle_trap(Trap::Breakpoint, pc, Some(insn_raw));
                                }
                                0x1050_0073 => {
                                    // WFI - treat as a hint NOP
                                }
                                0x0000_0073 => {
                                    // ECALL - route based on current privilege mode
                                    let trap = match self.mode {
                                        Mode::User => Trap::EnvironmentCallFromU,
                                        Mode::Supervisor => Trap::EnvironmentCallFromS,
                                        Mode::Machine => Trap::EnvironmentCallFromM,
                                    };
                                    return self.handle_trap(trap, pc, Some(insn_raw));
                                }
                                0x3020_0073 => {
                                    // MRET
                                    if self.mode != Mode::Machine {
                                        return self.handle_trap(
                                            Trap::IllegalInstruction(insn_raw as u64),
                                            pc,
                                            Some(insn_raw),
                                        );
                                    }

                                    let mut mstatus = self.csrs[CSR_MSTATUS as usize];
                                    let mepc = self.csrs[CSR_MEPC as usize];

                                    // Extract MPP and MPIE
                                    let mpp_bits = (mstatus >> 11) & 0b11;
                                    let mpie = (mstatus >> 7) & 1;

                                    // Set new privilege mode from MPP
                                    self.mode = Mode::from_mpp(mpp_bits);

                                    // MIE <= MPIE, MPIE <= 1, MPP <= U (00)
                                    mstatus = (mstatus & !(1 << 3)) | (mpie << 3);
                                    mstatus |= 1 << 7; // MPIE = 1
                                    mstatus &= !(0b11 << 11); // MPP = U (00)

                                    self.csrs[CSR_MSTATUS as usize] = mstatus;
                                    next_pc = mepc;
                                }
                                0x1020_0073 => {
                                    // SRET (only valid from S-mode)
                                    if self.mode != Mode::Supervisor {
                                        return self.handle_trap(
                                            Trap::IllegalInstruction(insn_raw as u64),
                                            pc,
                                            Some(insn_raw),
                                        );
                                    }

                                    // We model only the SPP/SIE/SPIE subset of mstatus.
                                    let mut mstatus = self.csrs[CSR_MSTATUS as usize];
                                    let sepc = self.csrs[CSR_SEPC as usize];

                                    // SPP is bit 8, SPIE is bit 5, SIE is bit 1.
                                    let spp = (mstatus >> 8) & 1;
                                    let spie = (mstatus >> 5) & 1;

                                    self.mode = if spp == 0 {
                                        Mode::User
                                    } else {
                                        Mode::Supervisor
                                    };

                                    // SIE <= SPIE, SPIE <= 1, SPP <= U (0)
                                    mstatus = (mstatus & !(1 << 1)) | (spie << 1);
                                    mstatus |= 1 << 5; // SPIE = 1
                                    mstatus &= !(1 << 8); // SPP = U

                                    self.csrs[CSR_MSTATUS as usize] = mstatus;
                                    next_pc = sepc;
                                }
                                _ => {
                                    return self.handle_trap(
                                        Trap::IllegalInstruction(insn_raw as u64),
                                        pc,
                                        Some(insn_raw),
                                    );
                                }
                            }
                        }
                    }
                    // Zicsr: CSRRW/CSRRS/CSRRC
                    1 | 2 | 3 | 5 | 6 | 7 => {
                        let csr_addr = (imm & 0xFFF) as u16;
                        // Dynamic read for time CSR to reflect CLINT MTIME.
                        let old = if csr_addr == CSR_TIME {
                            bus.read64(CLINT_BASE + MTIME_OFFSET).unwrap_or(0)
                        } else {
                            match self.read_csr(csr_addr) {
                                Ok(v) => v,
                                Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                            }
                        };

                        let mut write_new = None::<u64>;
                        match funct3 {
                            // CSRRW: write rs1, rd = old
                            1 => {
                                let rs1_val = self.read_reg(rs1);
                                write_new = Some(rs1_val);
                            }
                            // CSRRS: set bits in CSR with rs1
                            2 => {
                                let rs1_val = self.read_reg(rs1);
                                if rs1 != Register::X0 {
                                    write_new = Some(old | rs1_val);
                                }
                            }
                            // CSRRC: clear bits in CSR with rs1
                            3 => {
                                let rs1_val = self.read_reg(rs1);
                                if rs1 != Register::X0 {
                                    write_new = Some(old & !rs1_val);
                                }
                            }
                            // CSRRWI: write zero-extended zimm, rd = old
                            5 => {
                                let zimm = rs1.to_usize() as u64;
                                write_new = Some(zimm);
                            }
                            // CSRRSI: set bits using zimm (if non-zero)
                            6 => {
                                let zimm = rs1.to_usize() as u64;
                                if zimm != 0 {
                                    write_new = Some(old | zimm);
                                }
                            }
                            // CSRRCI: clear bits using zimm (if non-zero)
                            7 => {
                                let zimm = rs1.to_usize() as u64;
                                if zimm != 0 {
                                    write_new = Some(old & !zimm);
                                }
                            }
                            _ => {}
                        }

                        if let Some(new_val) = write_new {
                            if let Err(e) = self.write_csr(csr_addr, new_val) {
                                return self.handle_trap(e, pc, Some(insn_raw));
                            }
                        }

                        if rd != Register::X0 {
                            self.write_reg(rd, old);
                        }
                    }
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        );
                    }
                }
            }
            Op::Fence => {
                // NOP
            }
        }

        self.pc = next_pc;
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::bus::SystemBus;

    // --- Test helpers ----------------------------------------------------

    fn encode_i(imm: i32, rs1: u32, funct3: u32, rd: u32, opcode: u32) -> u32 {
        (((imm as u32) & 0xFFF) << 20) | (rs1 << 15) | (funct3 << 12) | (rd << 7) | opcode
    }

    fn encode_r(funct7: u32, rs2: u32, rs1: u32, funct3: u32, rd: u32, opcode: u32) -> u32 {
        (funct7 << 25) | (rs2 << 20) | (rs1 << 15) | (funct3 << 12) | (rd << 7) | opcode
    }

    fn encode_s(imm: i32, rs2: u32, rs1: u32, funct3: u32, opcode: u32) -> u32 {
        let imm = imm as u32;
        let imm11_5 = (imm >> 5) & 0x7F;
        let imm4_0 = imm & 0x1F;
        (imm11_5 << 25)
            | (rs2 << 20)
            | (rs1 << 15)
            | (funct3 << 12)
            | (imm4_0 << 7)
            | opcode
    }

    fn encode_b(imm: i32, rs2: u32, rs1: u32, funct3: u32, opcode: u32) -> u32 {
        // imm is a signed byte offset, must be multiple of 2
        let imm = imm as u32;
        let imm12 = (imm >> 12) & 0x1;
        let imm10_5 = (imm >> 5) & 0x3F;
        let imm4_1 = (imm >> 1) & 0xF;
        let imm11 = (imm >> 11) & 0x1;

        (imm12 << 31)
            | (imm10_5 << 25)
            | (rs2 << 20)
            | (rs1 << 15)
            | (funct3 << 12)
            | (imm4_1 << 8)
            | (imm11 << 7)
            | opcode
    }

    fn make_bus() -> SystemBus {
        SystemBus::new(0x8000_0000, 1024 * 1024) // 1MB
    }

    fn encode_amo(
        funct5: u32,
        aq: bool,
        rl: bool,
        rs2: u32,
        rs1: u32,
        funct3: u32,
        rd: u32,
    ) -> u32 {
        let funct7 = (funct5 << 2) | ((aq as u32) << 1) | (rl as u32);
        encode_r(funct7, rs2, rs1, funct3, rd, 0x2F)
    }

    #[test]
    fn test_addi() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // ADDI x1, x0, -1
        let insn = encode_i(-1, 0, 0, 1, 0x13);
        bus.write32(0x8000_0000, insn).unwrap();

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X1), 0xFFFF_FFFF_FFFF_FFFF);
        assert_eq!(cpu.pc, 0x8000_0004);
    }

    #[test]
    fn test_lui() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // LUI x2, 0x12345
        // imm field is already << 12 in the encoding helper
        let imm = 0x12345 << 12;
        let insn = ((imm as u32) & 0xFFFFF000) | (2 << 7) | 0x37;
        bus.write32(0x8000_0000, insn).unwrap();

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X2), 0x0000_0000_1234_5000);
    }

    #[test]
    fn test_load_store() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // SD x1, 0(x2) -> Store x1 at x2+0
        // x1 = 0xDEADBEEF, x2 = 0x8000_0100
        cpu.write_reg(Register::X1, 0xDEADBEEF);
        cpu.write_reg(Register::X2, 0x8000_0100);

        // SD: Op=0x23, funct3=3, rs1=2, rs2=1, imm=0
        // Using manual encoding here: imm=0 so only rs2/rs1/funct3/opcode matter.
        let sd_insn = (1 << 20) | (2 << 15) | (3 << 12) | 0x23;
        bus.write32(0x8000_0000, sd_insn).unwrap();

        cpu.step(&mut bus).unwrap();
        assert_eq!(bus.read64(0x8000_0100).unwrap(), 0xDEADBEEF);

        // LD x3, 0(x2) -> Load x3 from x2+0
        // LD: Op=0x03, funct3=3, rd=3, rs1=2, imm=0
        let ld_insn = (2 << 15) | (3 << 12) | (3 << 7) | 0x03;
        bus.write32(0x8000_0004, ld_insn).unwrap();

        cpu.step(&mut bus).unwrap(); // Execute SD (pc was incremented in previous step? No wait)
                                     // Previous step PC went 0->4. Now at 4.

        assert_eq!(cpu.read_reg(Register::X3), 0xDEADBEEF);
    }

    #[test]
    fn test_x0_invariant() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // Place a value in memory
        let addr = 0x8000_0100;
        bus.write64(addr, 0xDEAD_BEEF_DEAD_BEEF).unwrap();

        // Set x2 = addr
        cpu.write_reg(Register::X2, addr);

        // 1) ADDI x0, x0, 5
        let addi_x0 = encode_i(5, 0, 0, 0, 0x13);
        // 2) LD x0, 0(x2)
        let ld_x0 = encode_i(0, 2, 3, 0, 0x03);

        bus.write32(0x8000_0000, addi_x0).unwrap();
        bus.write32(0x8000_0004, ld_x0).unwrap();

        cpu.step(&mut bus).unwrap();
        cpu.step(&mut bus).unwrap();

        // x0 must remain hard-wired to zero
        assert_eq!(cpu.read_reg(Register::X0), 0);
    }

    #[test]
    fn test_branch_taken_and_not_taken() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // BEQ x1, x2, +8 (pc + 8 when taken)
        let beq_insn = encode_b(8, 2, 1, 0x0, 0x63);
        bus.write32(0x8000_0000, beq_insn).unwrap();

        // Taken: x1 == x2
        cpu.write_reg(Register::X1, 5);
        cpu.write_reg(Register::X2, 5);
        cpu.pc = 0x8000_0000;
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.pc, 0x8000_0008);

        // Not taken: x1 != x2
        cpu.write_reg(Register::X1, 1);
        cpu.write_reg(Register::X2, 2);
        cpu.pc = 0x8000_0000;
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.pc, 0x8000_0004);
    }

    #[test]
    fn test_w_ops_sign_extension() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // Set x1 = 0x0000_0000_8000_0000 (low 32 bits have sign bit set)
        cpu.write_reg(Register::X1, 0x0000_0000_8000_0000);
        cpu.write_reg(Register::X2, 0); // x2 = 0

        // ADDW x3, x1, x2  (opcode=0x3B, funct3=0, funct7=0)
        let addw = encode_r(0x00, 2, 1, 0x0, 3, 0x3B);
        bus.write32(0x8000_0000, addw).unwrap();

        cpu.step(&mut bus).unwrap();

        // Expect sign-extended 32-bit result: 0xFFFF_FFFF_8000_0000
        assert_eq!(cpu.read_reg(Register::X3), 0xFFFF_FFFF_8000_0000);
    }

    #[test]
    fn test_m_extension_mul_div_rem() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // MUL: 3 * 4 = 12
        cpu.write_reg(Register::X1, 3);
        cpu.write_reg(Register::X2, 4);
        let mul = encode_r(0x01, 2, 1, 0x0, 3, 0x33); // MUL x3, x1, x2
        bus.write32(0x8000_0000, mul).unwrap();
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X3), 12);

        // MULH / MULHSU / MULHU basic sanity using large values
        cpu.pc = 0x8000_0004;
        cpu.write_reg(Register::X1, 0x8000_0000_0000_0000);
        cpu.write_reg(Register::X2, 2);
        let mulh = encode_r(0x01, 2, 1, 0x1, 4, 0x33); // MULH x4, x1, x2
        let mulhsu = encode_r(0x01, 2, 1, 0x2, 5, 0x33); // MULHSU x5, x1, x2
        let mulhu = encode_r(0x01, 2, 1, 0x3, 6, 0x33); // MULHU x6, x1, x2
        bus.write32(0x8000_0004, mulh).unwrap();
        bus.write32(0x8000_0008, mulhsu).unwrap();
        bus.write32(0x8000_000C, mulhu).unwrap();
        cpu.step(&mut bus).unwrap();
        cpu.step(&mut bus).unwrap();
        cpu.step(&mut bus).unwrap();

        // From spec example: low product is 0, high signed part negative
        assert_eq!(cpu.read_reg(Register::X3), 12);
        assert_ne!(cpu.read_reg(Register::X4), 0);
        assert_ne!(cpu.read_reg(Register::X5), 0);
        assert_ne!(cpu.read_reg(Register::X6), 0);

        // DIV / DIVU / REM / REMU corner cases
        cpu.pc = 0x8000_0010;
        cpu.write_reg(Register::X1, u64::MAX); // -1 as signed
        cpu.write_reg(Register::X2, 0);
        let div = encode_r(0x01, 2, 1, 0x4, 7, 0x33); // DIV x7, x1, x2
        let divu = encode_r(0x01, 2, 1, 0x5, 8, 0x33); // DIVU x8, x1, x2
        let rem = encode_r(0x01, 2, 1, 0x6, 9, 0x33); // REM x9, x1, x2
        let remu = encode_r(0x01, 2, 1, 0x7, 10, 0x33); // REMU x10, x1, x2
        bus.write32(0x8000_0010, div).unwrap();
        bus.write32(0x8000_0014, divu).unwrap();
        bus.write32(0x8000_0018, rem).unwrap();
        bus.write32(0x8000_001C, remu).unwrap();

        for _ in 0..4 {
            cpu.step(&mut bus).unwrap();
        }

        assert_eq!(cpu.read_reg(Register::X7), u64::MAX); // DIV by 0 -> -1
        assert_eq!(cpu.read_reg(Register::X8), u64::MAX); // DIVU by 0 -> all ones
        assert_eq!(cpu.read_reg(Register::X9), u64::MAX); // REM by 0 -> rs1
        assert_eq!(cpu.read_reg(Register::X10), u64::MAX); // REMU by 0 -> rs1

        // Overflow case: -(2^63) / -1 -> -(2^63), rem = 0
        cpu.pc = 0x8000_0020;
        cpu.write_reg(Register::X1, i64::MIN as u64);
        cpu.write_reg(Register::X2, (!0u64) as u64); // -1
        let div_over = encode_r(0x01, 2, 1, 0x4, 11, 0x33); // DIV x11, x1, x2
        let rem_over = encode_r(0x01, 2, 1, 0x6, 12, 0x33); // REM x12, x1, x2
        bus.write32(0x8000_0020, div_over).unwrap();
        bus.write32(0x8000_0024, rem_over).unwrap();
        cpu.step(&mut bus).unwrap();
        cpu.step(&mut bus).unwrap();

        assert_eq!(cpu.read_reg(Register::X11), i64::MIN as u64);
        assert_eq!(cpu.read_reg(Register::X12), 0);
    }

    #[test]
    fn test_compressed_addi_and_lwsp_paths() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // Encodings from assembler with rv64imac (see rvc_test.S in dev notes):
        let c_addi_x11_1: u16 = 0x0585; // addi x11,x11,1 (C.ADDI)
        let c_addi16sp_16: u16 = 0x0141; // addi sp,sp,16 (C.ADDI16SP)
        let c_lwsp_a5_12: u16 = 0x47B2; // lw a5,12(sp) (C.LWSP)

        // Initialize registers / memory
        cpu.write_reg(Register::X11, 10);
        let sp_base = 0x8000_0100;
        cpu.write_reg(Register::X2, sp_base); // sp
        // After C.ADDI16SP 16, sp = sp_base + 16. C.LWSP uses offset 12 from new sp.
        bus.write32(sp_base + 16 + 12, 0xDEAD_BEEF).unwrap();

        // Place compressed instructions at 0,2,4
        bus.write16(0x8000_0000, c_addi_x11_1).unwrap();
        bus.write16(0x8000_0002, c_addi16sp_16).unwrap();
        bus.write16(0x8000_0004, c_lwsp_a5_12).unwrap();

        // Execute three steps; PC should advance by 2 for each compressed inst.
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.pc, 0x8000_0002);
        assert_eq!(cpu.read_reg(Register::X11), 11);

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.pc, 0x8000_0004);
        assert_eq!(cpu.read_reg(Register::X2), 0x8000_0110); // sp + 16

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.pc, 0x8000_0006);
        assert_eq!(cpu.read_reg(Register::X15), 0xFFFF_FFFF_DEAD_BEEF); // a5 (sign-extended lw)
    }

    #[test]
    fn test_zicsr_basic_csrs() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);
        let csr_addr: u32 = 0x300; // mstatus

        // CSRRWI x1, mstatus, 5  (mstatus = 5, x1 = old = 0)
        let csrrwi = {
            let zimm = 5u32;
            (csr_addr << 20) | (zimm << 15) | (0x5 << 12) | (1 << 7) | 0x73
        };
        bus.write32(0x8000_0000, csrrwi).unwrap();
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X1), 0);

        // CSRRSI x2, mstatus, 0xA  (mstatus = 5 | 0xA = 0xF, x2 = old = 5)
        let csrrsi = {
            let zimm = 0xAu32;
            (csr_addr << 20) | (zimm << 15) | (0x6 << 12) | (2 << 7) | 0x73
        };
        bus.write32(0x8000_0004, csrrsi).unwrap();
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X2), 5);

        // CSRRCI x3, mstatus, 0x3  (mstatus = 0xF & !0x3 = 0xC, x3 = old = 0xF)
        let csrrci = {
            let zimm = 0x3u32;
            (csr_addr << 20) | (zimm << 15) | (0x7 << 12) | (3 << 7) | 0x73
        };
        bus.write32(0x8000_0008, csrrci).unwrap();
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X3), 0xF);
    }

    #[test]
    fn test_a_extension_lr_sc_basic() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        let addr = 0x8000_0200;
        bus.write64(addr, 0xDEAD_BEEF_DEAD_BEEF).unwrap();

        cpu.write_reg(Register::X1, addr); // base
        cpu.write_reg(Register::X2, 0x0123_4567_89AB_CDEF); // value to store with SC

        // LR.D x3, 0(x1)
        let lr_d = encode_amo(0b00010, false, false, 0, 1, 0x3, 3);
        // SC.D x4, x2, 0(x1)
        let sc_d = encode_amo(0b00011, false, false, 2, 1, 0x3, 4);

        bus.write32(0x8000_0000, lr_d).unwrap();
        bus.write32(0x8000_0004, sc_d).unwrap();

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X3), 0xDEAD_BEEF_DEAD_BEEF);

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X4), 0); // SC success
        assert_eq!(bus.read64(addr).unwrap(), 0x0123_4567_89AB_CDEF);
    }

    #[test]
    fn test_a_extension_reservation_and_misaligned_sc() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        let addr = 0x8000_0300;
        bus.write64(addr, 0xCAFEBABE_F00D_F00D).unwrap();

        cpu.write_reg(Register::X1, addr); // base
        cpu.write_reg(Register::X2, 1); // increment

        // LR.D to establish reservation
        let lr_d = encode_amo(0b00010, false, false, 0, 1, 0x3, 3);
        // AMOADD.D x4, x2, 0(x1) -> increments and clears reservation
        let amoadd_d = encode_amo(0b00000, false, false, 2, 1, 0x3, 4);
        // SC.D x5, x2, 0(x1) -> should fail (x5=1) because reservation cleared
        let sc_d = encode_amo(0b00011, false, false, 2, 1, 0x3, 5);

        bus.write32(0x8000_0000, lr_d).unwrap();
        bus.write32(0x8000_0004, amoadd_d).unwrap();
        bus.write32(0x8000_0008, sc_d).unwrap();

        cpu.step(&mut bus).unwrap(); // LR
        cpu.step(&mut bus).unwrap(); // AMOADD
        cpu.step(&mut bus).unwrap(); // SC (should fail)

        assert_eq!(cpu.read_reg(Register::X5), 1);

        // Misaligned SC.D must trap with StoreAddressMisaligned
        cpu.pc = 0x8000_0010;
        cpu.write_reg(Register::X1, addr + 1); // misaligned
        let sc_misaligned = encode_amo(0b00011, false, false, 2, 1, 0x3, 6);
        bus.write32(0x8000_0010, sc_misaligned).unwrap();

        let res = cpu.step(&mut bus);
        match res {
            Err(Trap::StoreAddressMisaligned(a)) => assert_eq!(a, addr + 1),
            _ => panic!("Expected StoreAddressMisaligned trap"),
        }
    }

    #[test]
    fn test_load_sign_and_zero_extension() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        let addr = 0x8000_0100;
        // 0xFFEE_DDCC_BBAA_9988 laid out little-endian in memory
        bus.write64(addr, 0xFFEE_DDCC_BBAA_9988).unwrap();

        cpu.write_reg(Register::X1, addr); // base pointer

        // LB x2, 0(x1)
        let lb = encode_i(0, 1, 0, 2, 0x03);
        // LBU x3, 0(x1)
        let lbu = encode_i(0, 1, 4, 3, 0x03);
        // LH x4, 0(x1)
        let lh = encode_i(0, 1, 1, 4, 0x03);
        // LHU x5, 0(x1)
        let lhu = encode_i(0, 1, 5, 5, 0x03);
        // LW x6, 0(x1)
        let lw = encode_i(0, 1, 2, 6, 0x03);
        // LWU x7, 0(x1)
        let lwu = encode_i(0, 1, 6, 7, 0x03);
        // LD x8, 0(x1)
        let ld = encode_i(0, 1, 3, 8, 0x03);

        let base_pc = 0x8000_0000;
        for (i, insn) in [lb, lbu, lh, lhu, lw, lwu, ld].into_iter().enumerate() {
            bus.write32(base_pc + (i as u64) * 4, insn).unwrap();
        }

        // Execute all loads
        for _ in 0..7 {
            cpu.step(&mut bus).unwrap();
        }

        assert_eq!(cpu.read_reg(Register::X2), 0xFFFF_FFFF_FFFF_FF88); // LB (sign-extended 0x88)
        assert_eq!(cpu.read_reg(Register::X3), 0x88); // LBU
        assert_eq!(cpu.read_reg(Register::X4), 0xFFFF_FFFF_FFFF_9988); // LH
        assert_eq!(cpu.read_reg(Register::X5), 0x9988); // LHU
        assert_eq!(cpu.read_reg(Register::X6), 0xFFFF_FFFF_BBAA_9988); // LW
        assert_eq!(cpu.read_reg(Register::X7), 0xBBAA_9988); // LWU
        assert_eq!(cpu.read_reg(Register::X8), 0xFFEE_DDCC_BBAA_9988); // LD
    }

    #[test]
    fn test_misaligned_load_and_store_traps() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // x2 = misaligned address
        cpu.write_reg(Register::X2, 0x8000_0001);

        // LW x1, 0(x2)  -> should trap with LoadAddressMisaligned
        let lw = encode_i(0, 2, 2, 1, 0x03);
        bus.write32(0x8000_0000, lw).unwrap();

        let res = cpu.step(&mut bus);
        match res {
            Err(Trap::LoadAddressMisaligned(a)) => assert_eq!(a, 0x8000_0001),
            _ => panic!("Expected LoadAddressMisaligned trap"),
        }

        // SW x1, 0(x2)  -> should trap with StoreAddressMisaligned
        cpu.pc = 0x8000_0000;
        let sw = encode_s(0, 1, 2, 2, 0x23);
        bus.write32(0x8000_0000, sw).unwrap();

        let res = cpu.step(&mut bus);
        match res {
            Err(Trap::StoreAddressMisaligned(a)) => assert_eq!(a, 0x8000_0001),
            _ => panic!("Expected StoreAddressMisaligned trap"),
        }
    }

    #[test]
    fn test_access_fault_outside_dram() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // LW x1, 0(x0) -> effective address 0x0 (outside DRAM, but aligned)
        let lw = encode_i(0, 0, 2, 1, 0x03);
        bus.write32(0x8000_0000, lw).unwrap();

        let res = cpu.step(&mut bus);
        match res {
            Err(Trap::LoadAccessFault(a)) => assert_eq!(a, 0),
            _ => panic!("Expected LoadAccessFault trap"),
        }
    }

    #[test]
    fn test_jal() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // JAL x1, 8
        // Op=0x6F, rd=1, imm=8.
        // J-type: imm[20|10:1|11|19:12]
        // imm=8 (0x8). bit3=1.
        // imm[10:1] = 0100... no wait.
        // 8 = 1000 binary.
        // bit1..10 -> bits 1..4 are 0010 ? No.
        // 8 >> 1 = 4.
        // imm[10:1] = 4.
        // insn: imm[20] | imm[10:1] | imm[11] | imm[19:12] | rd | opcode
        // 0 | 4 | 0 | 0 | 1 | 0x6F
        // (4 << 21) | (1 << 7) | 0x6F
        let jal_insn = (4 << 21) | (1 << 7) | 0x6F;
        bus.write32(0x8000_0000, jal_insn).unwrap();

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X1), 0x8000_0004); // Link address
        assert_eq!(cpu.pc, 0x8000_0008); // Target
    }

    #[test]
    fn test_misaligned_fetch() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0001); // Odd PC

        let res = cpu.step(&mut bus);
        match res {
            Err(Trap::InstructionAddressMisaligned(addr)) => assert_eq!(addr, 0x8000_0001),
            _ => panic!("Expected misaligned trap"),
        }
    }

    #[test]
    fn test_smoke_sum() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // Data at 0x8000_0100
        let data: [u32; 5] = [1, 2, 3, 4, 5];
        for (i, val) in data.iter().enumerate() {
            bus.write32(0x8000_0100 + (i * 4) as u64, *val).unwrap();
        }

        // Program
        // Need to construct 0x80000100 without sign extension issues.
        // 1. ADDI x1, x0, 1
        // 2. SLLI x1, x1, 31 -> 0x80000000
        // 3. ADDI x1, x1, 0x100 -> 0x80000100
        let prog = [
            0x00100093, // addi x1, x0, 1
            0x01F09093, // slli x1, x1, 31
            0x10008093, // addi x1, x1, 0x100 -> Base
            0x00500113, // addi x2, x0, 5 -> Count
            0x00000193, // addi x3, x0, 0 -> Sum
            // loop:
            0x0000A203, // lw x4, 0(x1)
            0x004181B3, // add x3, x3, x4
            0x00408093, // addi x1, x1, 4
            0xFFF10113, // addi x2, x2, -1
            0xFE0118E3, // bne x2, x0, loop (-16)
            0x00100073, // ebreak
        ];

        for (i, val) in prog.iter().enumerate() {
            bus.write32(0x8000_0000 + (i * 4) as u64, *val).unwrap();
        }

        // Run until ebreak
        let mut steps = 0;
        loop {
            steps += 1;
            if steps > 1000 {
                panic!("Infinite loop");
            }
            match cpu.step(&mut bus) {
                Ok(_) => {}
                Err(Trap::Breakpoint) => break,
                Err(e) => panic!("Unexpected trap at pc 0x{:x}: {:?}", cpu.pc, e),
            }
        }

        // Check sum
        assert_eq!(cpu.read_reg(Register::X3), 15);
    }

    #[test]
    fn test_interrupts_clint_plic() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // 1. Setup MTVEC to 0x8000_1000 (Direct)
        let mtvec_val = 0x8000_1000;
        cpu.write_csr(CSR_MTVEC, mtvec_val).unwrap();

        // 2. Enable MIE in mstatus (Global Interrupt Enable)
        // mstatus bit 3 is MIE.
        let mstatus_val = 1 << 3; 
        cpu.write_csr(CSR_MSTATUS, mstatus_val).unwrap();

        // 3. Enable MTIE (Timer) and MEIE (External) and MSIE (Software) in mie
        // MTIE=7, MEIE=11, MSIE=3
        let mie_val = (1 << 7) | (1 << 11) | (1 << 3);
        cpu.write_csr(CSR_MIE, mie_val).unwrap();

        // --- Test CLINT Timer Interrupt ---
        // Set mtimecmp[0] to 100
        bus.clint.mtimecmp[0] = 100;
        // Set mtime to 101 (trigger condition)
        bus.clint.set_mtime(101);

        // We need a valid instruction at PC to attempt fetch, although interrupt checks before fetch.
        bus.write32(0x8000_0000, 0x00000013).unwrap(); // NOP (addi x0, x0, 0)

        let res = cpu.step(&mut bus);
        match res {
             Err(Trap::MachineTimerInterrupt) => {
                 // Success
                 assert_eq!(cpu.pc, 0x8000_1000); // jumped to mtvec
                 // Check mcause: Interrupt=1, Cause=7 -> 0x8000...0007
                 let mcause = cpu.read_csr(CSR_MCAUSE).unwrap();
                 assert_eq!(mcause, 0x8000_0000_0000_0007);
             }
             _ => panic!("Expected MachineTimerInterrupt, got {:?}", res),
        }

        // Clear the interrupt condition
        bus.clint.mtimecmp[0] = 200; 
        // CPU is now at handler. We need to "return" (mret) or just reset state for next test.
        // Reset PC back to start
        cpu.pc = 0x8000_0000;
        // Re-enable MIE (trap disabled it)
        let mut mstatus = cpu.read_csr(CSR_MSTATUS).unwrap();
        mstatus |= 1 << 3;
        cpu.write_csr(CSR_MSTATUS, mstatus).unwrap();

        // --- Test PLIC UART Interrupt ---
        // Configure PLIC
        // 1. Set Priority for Source 10 (UART) to 1
        bus.plic.store(0x000000 + 4 * 10, 4, 1).unwrap();
        // 2. Enable Source 10 for Context 0 (M-mode)
        // Enable addr for ctx 0: 0x002000. Bit 10.
        bus.plic.store(0x002000, 4, 1 << 10).unwrap();
        // 3. Set Threshold for Context 0 to 0
        bus.plic.store(0x200000, 4, 0).unwrap();

        // Trigger UART Interrupt
        // Writing to IER (Enable RDIE=1) and pushing a char to Input
        // UART RBR is at offset 0. IER is at offset 1.
        bus.uart.store(1, 1, 1).unwrap(); // IER = 1 (RX Data Available Interrupt)
        bus.uart.push_input(b'A'); 
        // This should set uart.lsr[0]=1, and because IER[0]=1, uart.interrupting=true.
        
        // Update bus interrupts so PLIC sees UART line high
        bus.check_interrupts();

        // Step CPU
        let res = cpu.step(&mut bus);
        match res {
            Err(Trap::MachineExternalInterrupt) => {
                // Success
                assert_eq!(cpu.pc, 0x8000_1000);
                 let mcause = cpu.read_csr(CSR_MCAUSE).unwrap();
                 assert_eq!(mcause, 0x8000_0000_0000_000B); // Cause 11
            }
            _ => panic!("Expected MachineExternalInterrupt, got {:?}", res),
        }
    }
}
</file>

<file path="vm/src/dram.rs">
use thiserror::Error;

/// Base physical address of DRAM as seen by devices that work directly with
/// physical addresses (VirtIO, etc.).
///
/// This matches the DRAM base used by the `SystemBus` in `bus.rs` and the
/// Phase-0 virt memory map.
pub const DRAM_BASE: u64 = 0x8000_0000;

/// Device-local memory access errors.
///
/// These are mapped into architectural traps (`Trap`) by higher layers
/// (e.g., the system bus) where appropriate.
#[derive(Debug, Error)]
pub enum MemoryError {
    #[error("Out-of-bounds memory access at {0:#x}")]
    OutOfBounds(u64),

    #[error("Invalid or misaligned access at {0:#x}")]
    InvalidAlignment(u64),
}

/// Simple byte-addressable DRAM backing store used by VirtIO-style devices.
///
/// Offsets passed to the load/store helpers are **physical offsets from
/// `DRAM_BASE`**, not full guest physical addresses. Callers typically use
/// `DRAM_BASE` and subtract it via a helper (see `virtio.rs`).
pub struct Dram {
    pub base: u64,
    pub data: Vec<u8>,
}

impl Dram {
    /// Create a new DRAM image of `size` bytes, zero-initialised.
    pub fn new(base: u64, size: usize) -> Self {
        Self { base, data: vec![0; size] }
    }

    pub fn offset(&self, addr: u64) -> Option<usize> {
        if addr >= self.base {
            let off = (addr - self.base) as usize;
            if off < self.data.len() {
                return Some(off);
            }
        }
        None
    }

    pub fn load(&mut self, data: &[u8], offset: u64) -> Result<(), MemoryError> {
        self.write_bytes(offset, data)
    }

    pub fn zero_range(&mut self, offset: usize, len: usize) -> Result<(), MemoryError> {
        if offset + len > self.data.len() {
            return Err(MemoryError::OutOfBounds(offset as u64));
        }
        for i in 0..len {
            self.data[offset + i] = 0;
        }
        Ok(())
    }

    fn check_bounds(&self, offset: u64, size: usize) -> Result<usize, MemoryError> {
        let off = offset as usize;
        let end = off.checked_add(size).ok_or(MemoryError::OutOfBounds(offset))?;
        if end > self.data.len() {
            return Err(MemoryError::OutOfBounds(offset));
        }
        Ok(off)
    }

    pub fn load_8(&self, offset: u64) -> Result<u8, MemoryError> {
        let off = self.check_bounds(offset, 1)?;
        Ok(self.data[off])
    }

    pub fn load_16(&self, offset: u64) -> Result<u16, MemoryError> {
        if offset % 2 != 0 {
            return Err(MemoryError::InvalidAlignment(offset));
        }
        let off = self.check_bounds(offset, 2)?;
        let bytes: [u8; 2] = self.data[off..off + 2].try_into().unwrap();
        Ok(u16::from_le_bytes(bytes))
    }

    pub fn load_32(&self, offset: u64) -> Result<u32, MemoryError> {
        if offset % 4 != 0 {
            return Err(MemoryError::InvalidAlignment(offset));
        }
        let off = self.check_bounds(offset, 4)?;
        let bytes: [u8; 4] = self.data[off..off + 4].try_into().unwrap();
        Ok(u32::from_le_bytes(bytes))
    }

    pub fn load_64(&self, offset: u64) -> Result<u64, MemoryError> {
        if offset % 8 != 0 {
            return Err(MemoryError::InvalidAlignment(offset));
    }
        let off = self.check_bounds(offset, 8)?;
        let bytes: [u8; 8] = self.data[off..off + 8].try_into().unwrap();
        Ok(u64::from_le_bytes(bytes))
    }

    pub fn store_8(&mut self, offset: u64, value: u64) -> Result<(), MemoryError> {
        let off = self.check_bounds(offset, 1)?;
        self.data[off] = (value & 0xff) as u8;
        Ok(())
    }

    pub fn store_16(&mut self, offset: u64, value: u64) -> Result<(), MemoryError> {
        if offset % 2 != 0 {
            return Err(MemoryError::InvalidAlignment(offset));
        }
        let off = self.check_bounds(offset, 2)?;
        let bytes = (value as u16).to_le_bytes();
        self.data[off..off + 2].copy_from_slice(&bytes);
        Ok(())
    }

    pub fn store_32(&mut self, offset: u64, value: u64) -> Result<(), MemoryError> {
        if offset % 4 != 0 {
            return Err(MemoryError::InvalidAlignment(offset));
        }
        let off = self.check_bounds(offset, 4)?;
        let bytes = (value as u32).to_le_bytes();
        self.data[off..off + 4].copy_from_slice(&bytes);
        Ok(())
    }

    pub fn store_64(&mut self, offset: u64, value: u64) -> Result<(), MemoryError> {
        if offset % 8 != 0 {
            return Err(MemoryError::InvalidAlignment(offset));
        }
        let off = self.check_bounds(offset, 8)?;
        let bytes = value.to_le_bytes();
        self.data[off..off + 8].copy_from_slice(&bytes);
        Ok(())
    }

    /// Write an arbitrary slice into DRAM starting at `offset`.
    pub fn write_bytes(&mut self, offset: u64, data: &[u8]) -> Result<(), MemoryError> {
        let off = self.check_bounds(offset, data.len())?;
        self.data[off..off + data.len()].copy_from_slice(data);
        Ok(())
    }
}
</file>

<file path="vm/src/uart.rs">
use crate::dram::MemoryError;
use std::collections::VecDeque;

pub const UART_BASE: u64 = 0x1000_0000;
pub const UART_SIZE: u64 = 0x100;

// Registers (offset)
const RBR: u64 = 0x00; // Receiver Buffer (Read)
const THR: u64 = 0x00; // Transmitter Holding (Write)
const DLL: u64 = 0x00; // Divisor Latch LSB (Read/Write if DLAB=1)
const IER: u64 = 0x01; // Interrupt Enable
const DLM: u64 = 0x01; // Divisor Latch MSB (Read/Write if DLAB=1)
const IIR: u64 = 0x02; // Interrupt Identity (Read)
const FCR: u64 = 0x02; // FIFO Control (Write)
const LCR: u64 = 0x03; // Line Control
const MCR: u64 = 0x04; // Modem Control
const LSR: u64 = 0x05; // Line Status
const MSR: u64 = 0x06; // Modem Status
const SCR: u64 = 0x07; // Scratch

pub struct Uart {
    pub input: VecDeque<u8>,
    pub output: VecDeque<u8>,
    
    // Registers
    pub ier: u8,
    pub iir: u8,
    pub fcr: u8,
    pub lcr: u8,
    pub mcr: u8,
    pub lsr: u8,
    pub msr: u8,
    pub scr: u8,
    
    // Divisor
    pub dll: u8,
    pub dlm: u8,

    pub interrupting: bool,
    
    /// Internal state to track if THRE interrupt is pending (waiting for IIR read or THR write).
    /// This separates the "condition" (THR empty) from the "event" (Interrupt Pending).
    thre_ip: bool,
}

impl Uart {
    pub fn new() -> Self {
        Self {
            input: VecDeque::new(),
            output: VecDeque::new(),
            
            ier: 0x00,
            iir: 0x01, // Default: no interrupt pending
            fcr: 0x00,
            lcr: 0x00,
            mcr: 0x00,
            lsr: 0x60, // Transmitter Empty (bit 5) | Transmitter Holding Register Empty (bit 6)
            msr: 0x00,
            scr: 0x00,
            
            dll: 0x00,
            dlm: 0x00,

            interrupting: false,
            thre_ip: true, // Starts empty, so initial state could be pending if enabled
        }
    }

    pub fn update_interrupts(&mut self) {
        self.interrupting = false;
        self.iir = 0x01; // Default: no interrupt pending

        // Priority 1: Receiver Line Status (not implemented extensively)

        // Priority 2: Received Data Available
        if (self.lsr & 0x01) != 0 && (self.ier & 0x01) != 0 {
            self.interrupting = true;
            self.iir = 0x04; // Recieved Data Available
            return;
        }

        // Priority 3: Transmitter Holding Register Empty
        // Triggered if THR is empty AND IER bit 1 is set AND we haven't acknowledged it yet.
        if self.thre_ip && (self.ier & 0x02) != 0 {
             self.interrupting = true;
             self.iir = 0x02; // THRE
             return;
        }
        
        // Priority 4: Modem Status (not implemented)
    }

    pub fn load(&mut self, offset: u64, size: u64) -> Result<u64, MemoryError> {
        if size != 1 {
            // Some OS might try 4-byte reads, technically not allowed by spec but we can be lenient or strict.
            // Spec says 8-bit width. Let's return 0 for now if not byte access.
            return Ok(0);
        }

        let val = match offset {
            RBR => {
                if (self.lcr & 0x80) != 0 {
                    self.dll
                } else {
                    // RBR: Read from input FIFO
                    let byte = self.input.pop_front().unwrap_or(0);
                    // Update LSR: if more data, set bit 0, else clear it
                    if self.input.is_empty() {
                        self.lsr &= !0x01;
                    } else {
                        self.lsr |= 0x01;
                    }
                    self.update_interrupts();
                    byte
                }
            }
            IER => {
                if (self.lcr & 0x80) != 0 {
                    self.dlm
                } else {
                    self.ier
                }
            }
            IIR => {
                let val = self.iir;
                // Reading IIR clears THRE interrupt if it is the indicated interrupt
                if (val & 0x0F) == 0x02 {
                    self.thre_ip = false;
                    self.update_interrupts();
                    log::trace!("[UART] IIR read cleared THRE ip");
                } else {
                    log::trace!("[UART] IIR read val={:x} (thre_ip={})", val, self.thre_ip);
                }
                val
            }
            LCR => self.lcr,
            MCR => self.mcr,
            LSR => self.lsr,
            MSR => self.msr,
            SCR => self.scr,
            _ => 0,
        };

        Ok(val as u64)
    }

    pub fn store(&mut self, offset: u64, size: u64, value: u64) -> Result<(), MemoryError> {
        if size != 1 {
            return Ok(());
        }

        let val = (value & 0xff) as u8;

        match offset {
            THR => {
                if (self.lcr & 0x80) != 0 {
                    self.dll = val;
                } else {
                    // THR: Write to output
                    log::trace!(
                        "[UART] TX '{}' (0x{:02x})",
                        if val.is_ascii_graphic() {
                            val as char
                        } else {
                            '.'
                        },
                        val
                    );
                    self.output.push_back(val);
                    // We instantly "transmit", so THRE (bit 5) is always set.
                    // Writing to THR clears the THRE interrupt (if pending),
                    // but since it becomes empty immediately, we set thre_ip to true again?
                    // In real HW, it goes Not Empty -> Empty.
                    // So we should clear it, then re-assert it.
                    // For edge-triggered emulation, simply re-asserting is correct because we transitioned.
                    self.lsr |= 0x20; 
                    self.thre_ip = true; 
                    self.update_interrupts();
                }
            }
            IER => {
                if (self.lcr & 0x80) != 0 {
                    self.dlm = val;
                } else {
                    self.ier = val;
                    self.update_interrupts();
                }
            }
            FCR => {
                self.fcr = val;
                if (self.fcr & 0x02) != 0 {
                    self.input.clear();
                    self.lsr &= !0x01;
                }
                if (self.fcr & 0x04) != 0 {
                    self.output.clear();
                    self.lsr |= 0x60; // Empty
                }
                self.update_interrupts();
            }
            LCR => {
                self.lcr = val;
            }
            MCR => {
                self.mcr = val;
            }
            LSR => {
                // Usually read-only, but factory test mode might write. Ignore.
            }
            MSR => {
                // Read-only.
            }
            SCR => {
                self.scr = val;
            }
            _ => {}
        }
        Ok(())
    }

    // Interface for the Host
    pub fn push_input(&mut self, byte: u8) {
        self.input.push_back(byte);
        self.lsr |= 0x01; // Data Ready
        self.update_interrupts();
    }

    pub fn pop_output(&mut self) -> Option<u8> {
        self.output.pop_front()
    }
}
</file>

<file path="vm/src/console.rs">
//! Console handling for terminal I/O (not available in WASM).

#![cfg(not(target_arch = "wasm32"))]

use std::io::{self, Read};
use std::sync::mpsc;
use std::thread;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;

pub struct Console {
    rx: mpsc::Receiver<u8>,
    original_termios: Option<libc::termios>,
    running: Arc<AtomicBool>,
}

impl Console {
    pub fn new() -> Self {
        let (tx, rx) = mpsc::channel();
        let running = Arc::new(AtomicBool::new(true));
        let r_clone = running.clone();

        // Setup raw mode
        let mut original_termios = None;
        if unsafe { libc::isatty(libc::STDIN_FILENO) } == 1 {
            let mut termios = unsafe { std::mem::zeroed() };
            if unsafe { libc::tcgetattr(libc::STDIN_FILENO, &mut termios) } == 0 {
                original_termios = Some(termios);
                let mut raw = termios;
                unsafe {
                    libc::cfmakeraw(&mut raw);
                    libc::tcsetattr(libc::STDIN_FILENO, libc::TCSANOW, &raw);
                }
            }
        }

        thread::spawn(move || {
            let mut buf = [0u8; 1];
            let stdin = io::stdin();
            let mut handle = stdin.lock();
            
            while r_clone.load(Ordering::Relaxed) {
                // This read is blocking. 
                // In a real app we might want non-blocking or select, 
                // but for this simple VM, blocking thread is fine.
                if handle.read_exact(&mut buf).is_ok() {
                    let b = buf[0];
                    // Translate Ctrl-A x to exit? 
                    // Let's leave exit handling to the consumer or special key.
                    // Typically Ctrl-A x is (1, 120).
                    // We just pass raw bytes.
                    if tx.send(b).is_err() {
                        break;
                    }
                } else {
                    break;
                }
            }
        });

        Self {
            rx,
            original_termios,
            running,
        }
    }

    pub fn poll(&self) -> Option<u8> {
        self.rx.try_recv().ok()
    }
}

impl Drop for Console {
    fn drop(&mut self) {
        self.running.store(false, Ordering::Relaxed);
        if let Some(termios) = self.original_termios {
            unsafe {
                libc::tcsetattr(libc::STDIN_FILENO, libc::TCSANOW, &termios);
            }
        }
    }
}
</file>

<file path="vm/src/lib.rs">
pub mod bus;
pub mod cpu;
pub mod decoder;
pub mod csr;
pub mod mmu;
pub mod dram;
pub mod clint;
pub mod plic;
pub mod uart;
pub mod virtio;
pub mod emulator;

#[cfg(not(target_arch = "wasm32"))]
pub mod console;

use serde::{Deserialize, Serialize};

// WASM bindings
#[cfg(target_arch = "wasm32")]
use wasm_bindgen::prelude::*;

#[cfg(target_arch = "wasm32")]
use crate::bus::{SystemBus, DRAM_BASE};

/// WASM-exposed VM wrapper for running RISC-V kernels in the browser.
#[cfg(target_arch = "wasm32")]
#[wasm_bindgen]
pub struct WasmVm {
    bus: SystemBus,
    cpu: cpu::Cpu,
}

#[cfg(target_arch = "wasm32")]
#[wasm_bindgen]
impl WasmVm {
    /// Create a new VM instance and load a kernel (ELF or raw binary).
    #[wasm_bindgen(constructor)]
    pub fn new(kernel: &[u8]) -> Result<WasmVm, JsValue> {
        // Set up panic hook for better error messages in the browser console
        console_error_panic_hook::set_once();

        const DRAM_SIZE: usize = 128 * 1024 * 1024; // 128 MiB
        let mut bus = SystemBus::new(DRAM_BASE, DRAM_SIZE);
        
        // Check if it's an ELF file and load appropriately
        let entry_pc = if kernel.starts_with(b"\x7FELF") {
            // Parse and load ELF
            load_elf_wasm(kernel, &mut bus)
                .map_err(|e| JsValue::from_str(&format!("Failed to load ELF kernel: {}", e)))?
        } else {
            // Load raw binary at DRAM_BASE
            bus.dram
                .load(kernel, 0)
                .map_err(|e| JsValue::from_str(&format!("Failed to load kernel: {}", e)))?;
            DRAM_BASE
        };

        let cpu = cpu::Cpu::new(entry_pc);

        Ok(WasmVm { bus, cpu })
    }

    /// Load a disk image and attach it as a VirtIO block device.
    /// This should be called before starting execution if the kernel needs a filesystem.
    pub fn load_disk(&mut self, disk_image: &[u8]) {
        let vblk = virtio::VirtioBlock::new(disk_image.to_vec());
        self.bus.virtio_devices.push(Box::new(vblk));
    }

    /// Execute a single instruction.
    pub fn step(&mut self) {
        // Ignore traps for now - the kernel handles them
        let _ = self.cpu.step(&mut self.bus);
    }

    /// Get a byte from the UART output buffer, if available.
    pub fn get_output(&mut self) -> Option<u8> {
        self.bus.uart.pop_output()
    }

    /// Push an input byte to the UART.
    pub fn input(&mut self, byte: u8) {
        self.bus.uart.push_input(byte);
    }

    /// Get current memory usage (DRAM size) in bytes.
    pub fn get_memory_usage(&self) -> u64 {
        self.bus.dram.data.len() as u64
    }
}

/// Load an ELF kernel into DRAM (WASM-compatible version).
#[cfg(target_arch = "wasm32")]
fn load_elf_wasm(buffer: &[u8], bus: &mut SystemBus) -> Result<u64, String> {
    use goblin::elf::{program_header::PT_LOAD, Elf};
    
    let elf = Elf::parse(buffer).map_err(|e| format!("ELF parse error: {}", e))?;
    let base = bus.dram_base();
    let dram_end = base + bus.dram_size() as u64;

    for ph in &elf.program_headers {
        if ph.p_type != PT_LOAD || ph.p_memsz == 0 {
            continue;
        }

        let file_size = ph.p_filesz as usize;
        let mem_size = ph.p_memsz as usize;
        let file_offset = ph.p_offset as usize;
        if file_offset + file_size > buffer.len() {
            return Err(format!(
                "ELF segment exceeds file bounds (offset 0x{:x})",
                file_offset
            ));
        }

        let target_addr = if ph.p_paddr != 0 {
            ph.p_paddr
        } else {
            ph.p_vaddr
        };
        if target_addr < base {
            return Err(format!(
                "Segment start 0x{:x} lies below DRAM base 0x{:x}",
                target_addr, base
            ));
        }
        let seg_end = target_addr
            .checked_add(mem_size as u64)
            .ok_or_else(|| "Segment end overflow".to_string())?;
        if seg_end > dram_end {
            return Err(format!(
                "Segment 0x{:x}-0x{:x} exceeds DRAM (end 0x{:x})",
                target_addr, seg_end, dram_end
            ));
        }

        let dram_offset = (target_addr - base) as u64;
        if file_size > 0 {
            let end = file_offset + file_size;
            bus.dram
                .load(&buffer[file_offset..end], dram_offset)
                .map_err(|e| format!("Failed to load segment: {}", e))?;
        }
        if mem_size > file_size {
            let zero_start = dram_offset as usize + file_size;
            bus.dram
                .zero_range(zero_start, mem_size - file_size)
                .map_err(|e| format!("Failed to zero bss: {}", e))?;
        }
    }

    Ok(elf.entry)
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum Trap {
    InstructionAddressMisaligned(u64),
    InstructionAccessFault(u64),
    IllegalInstruction(u64),
    Breakpoint,
    LoadAddressMisaligned(u64),
    LoadAccessFault(u64),
    StoreAddressMisaligned(u64),
    StoreAccessFault(u64),
    EnvironmentCallFromU,
    EnvironmentCallFromS,
    EnvironmentCallFromM,
    InstructionPageFault(u64),
    LoadPageFault(u64),
    StorePageFault(u64),
    
    MachineSoftwareInterrupt,
    MachineTimerInterrupt,
    MachineExternalInterrupt,
    SupervisorSoftwareInterrupt,
    SupervisorTimerInterrupt,
    SupervisorExternalInterrupt,

    // Custom internal errors
    RequestedTrap(u64), // For testing (software interrupts, etc)
    Fatal(String),
}

impl std::fmt::Display for Trap {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{:?}", self)
    }
}

impl std::error::Error for Trap {}
</file>

<file path="vm/src/main.rs">
use clap::Parser;
use goblin::elf::{program_header::PT_LOAD, Elf};
use riscv_vm::bus::{Bus, SystemBus};
use riscv_vm::cpu::Cpu;
use riscv_vm::Trap;
use riscv_vm::csr::{CSR_MCAUSE, CSR_MEPC, CSR_MTVAL, CSR_MTVEC, CSR_SCAUSE, CSR_SEPC, CSR_STVAL, CSR_STVEC};
use std::fs::File;
use std::io::Read;
use std::path::PathBuf;

use riscv_vm::console::Console;

#[derive(Parser, Debug)]
#[command(author, version, about, long_about = None)]
struct Args {
    /// Path to binary to load
    #[arg(short, long)]
    kernel: PathBuf,

    /// Address to load kernel at (default 0x8000_0000)
    #[arg(long, default_value_t = 0x8000_0000)]
    load_addr: u64,

    /// DRAM size in MiB
    #[arg(long, default_value_t = 512)]
    mem_mib: usize,

    /// Optional path to a VirtIO Block disk image (e.g. xv6 fs.img)
    #[arg(long)]
    disk: Option<PathBuf>,
}

// Debug helper: dump VirtIO MMIO identity registers expected by xv6.
fn dump_virtio_id(bus: &mut SystemBus) {
    const VIRTIO0_BASE: u64 = 0x1000_1000;
    fn r32(bus: &mut SystemBus, off: u64) -> u32 {
        bus.read32(VIRTIO0_BASE + off).unwrap_or(0)
    }
    let magic = r32(bus, 0x000);
    let ver = r32(bus, 0x004);
    let devid = r32(bus, 0x008);
    let vendor = r32(bus, 0x00c);
    eprintln!(
        "VirtIO ID: MAGIC=0x{:08x} VERSION={} DEVICE_ID={} VENDOR=0x{:08x}",
        magic, ver, devid, vendor
    );
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    env_logger::init();
    let args = Args::parse();

    let mut file = File::open(&args.kernel)?;
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer)?;

    let dram_size_bytes = args
        .mem_mib
        .checked_mul(1024 * 1024)
        .ok_or("Requested memory size is too large")?;

    // Initialize DRAM at 0x8000_0000
    let dram_base = 0x8000_0000;
    let mut bus = SystemBus::new(dram_base, dram_size_bytes);

    // If a disk image is provided, wire up VirtIO Block at 0x1000_1000
    if let Some(disk_path) = &args.disk {
        let mut disk_file = File::open(disk_path)?;
        let mut disk_buf = Vec::new();
        disk_file.read_to_end(&mut disk_buf)?;
        let vblk = riscv_vm::virtio::VirtioBlock::new(disk_buf);
        bus.virtio_devices.push(Box::new(vblk));
        println!("VirtIO Block device attached at 0x1000_1000 (IRQ 1)");
    }

    let entry_pc = if buffer.starts_with(b"\x7FELF") {
        println!("Detected ELF payload, loading program segments...");
        load_elf_into_dram(&buffer, &mut bus)?
    } else {
        if args.load_addr < dram_base {
            eprintln!("Load address must be >= 0x{:x}", dram_base);
            return Ok(());
        }
        let offset = args.load_addr - dram_base;
        println!(
            "Loading raw binary ({} bytes) at 0x{:x}",
            buffer.len(),
            args.load_addr
        );
        bus.dram
            .load(&buffer, offset)
            .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;
        args.load_addr
    };

    let mut cpu = Cpu::new(entry_pc);

    println!("Starting execution at 0x{:x}", cpu.pc);
    // Early probe dump (harmless if device absent): helps debug xv6 panic on probe.
    dump_virtio_id(&mut bus);

    let mut step_count = 0u64;
    let mut last_report_step = 0u64;
    
    // Initialize console for host input
    let console = Console::new();
    let mut escaped = false;

    loop {
        // Poll console input
        if let Some(b) = console.poll() {
            if escaped {
                if b == b'x' {
                    println!("\nTerminated by user.");
                    break;
                } else if b == 1 {
                    // Ctrl-A twice -> send Ctrl-A to guest
                    bus.uart.push_input(1);
                } else {
                    // Ctrl-A then something else -> send that something else
                    // (Ctrl-A is swallowed)
                    bus.uart.push_input(b);
                }
                escaped = false;
            } else {
                if b == 1 { // Ctrl-A
                    escaped = true;
                } else {
                    bus.uart.push_input(b);
                }
            }
        }

        let step_result = cpu.step(&mut bus);
        step_count += 1;
        
        // Progress report every 10M instructions (not every instruction!)
        if step_count - last_report_step >= 10_000_000 {
            // eprinteln!("[{} M insns] pc=0x{:x} mode={:?}", step_count / 1_000_000, cpu.pc, cpu.mode);
            last_report_step = step_count;
        }
        

        if let Err(trap) = step_result {
            match trap {
                // Test finisher / explicit host stop requested by the guest.
                Trap::RequestedTrap(code) => {
                    println!("Guest requested stop via test finisher: 0x{code:x}");
                    break;
                }
                // Non-recoverable emulator error: dump state and exit.
                Trap::Fatal(msg) => {
                    eprintln!("Fatal emulator error: {msg}");
                    println!("PC: 0x{:x}", cpu.pc);
                    for i in 0..32 {
                        if i % 4 == 0 {
                            println!();
                        }
                        print!("x{:<2}: 0x{:<16x} ", i, cpu.regs[i]);
                    }
                    println!();
                    break;
                }
                // Architectural traps (interrupts, page faults, ecalls, etc.)
                // are fully handled inside Cpu::handle_trap by updating CSRs
                // and redirecting PC to mtvec/stvec. We simply continue
                // stepping so that the guest handler can run.
                _other => {
                    // Traps are handled inside cpu.step() - just continue execution.
                    // Use RUST_LOG=debug to see trap details.
                    if log::log_enabled!(log::Level::Debug) {
                        let mepc  = cpu.read_csr(CSR_MEPC).unwrap_or(0);
                        let mcause = cpu.read_csr(CSR_MCAUSE).unwrap_or(0);
                        let mtval = cpu.read_csr(CSR_MTVAL).unwrap_or(0);
                        let mtvec = cpu.read_csr(CSR_MTVEC).unwrap_or(0);
                        log::debug!(
                            "Trap: {:?} pc=0x{:x} mepc=0x{:x} mcause=0x{:x} mtval=0x{:x} mtvec=0x{:x}",
                            _other, cpu.pc, mepc, mcause, mtval, mtvec
                        );
                    }
                }
            }
        }

        // Check UART output - handle raw mode by converting \n to \r\n
        use std::io::Write;
        let stdout = std::io::stdout();
        let mut stdout_lock = stdout.lock();
        while let Some(byte) = bus.uart.pop_output() {
            // In raw terminal mode, \n alone doesn't return cursor to column 0.
            // We need to emit \r\n for proper line breaks.
            if byte == b'\n' {
                let _ = stdout_lock.write_all(b"\r\n");
            } else if byte == b'\r' {
                // Carriage return - just emit it
                let _ = stdout_lock.write_all(b"\r");
            } else {
                let _ = stdout_lock.write_all(&[byte]);
            }
        }
        let _ = stdout_lock.flush();

        // Stop if PC is 0 in Machine/Supervisor mode (likely trap to unmapped vector).
        // User mode PC=0 is valid (xv6 initcode).
        if cpu.pc == 0 && cpu.mode != riscv_vm::csr::Mode::User {
            let mepc  = cpu.read_csr(CSR_MEPC).unwrap_or(0);
            let mcause = cpu.read_csr(CSR_MCAUSE).unwrap_or(0);
            let mtval = cpu.read_csr(CSR_MTVAL).unwrap_or(0);
            let mtvec = cpu.read_csr(CSR_MTVEC).unwrap_or(0);
            let sepc  = cpu.read_csr(CSR_SEPC).unwrap_or(0);
            let scause = cpu.read_csr(CSR_SCAUSE).unwrap_or(0);
            let stval = cpu.read_csr(CSR_STVAL).unwrap_or(0);
            let stvec = cpu.read_csr(CSR_STVEC).unwrap_or(0);
            println!("PC reached 0, stopping.");
            println!(
                "Final state:\n  pc=0x{:016x} mode={:?}\n  M: mepc=0x{:016x} mcause=0x{:016x} mtval=0x{:016x} mtvec=0x{:016x}\n  S: sepc=0x{:016x} scause=0x{:016x} stval=0x{:016x} stvec=0x{:016x}",
                cpu.pc, cpu.mode, mepc, mcause, mtval, mtvec, sepc, scause, stval, stvec
            );
            break;
        }
    }

    Ok(())
}

fn load_elf_into_dram(
    buffer: &[u8],
    bus: &mut SystemBus,
) -> Result<u64, Box<dyn std::error::Error>> {
    let elf = Elf::parse(buffer)?;
    let base = bus.dram_base();
    let dram_end = base + bus.dram_size() as u64;

    for ph in &elf.program_headers {
        if ph.p_type != PT_LOAD || ph.p_memsz == 0 {
            continue;
        }

        let file_size = ph.p_filesz as usize;
        let mem_size = ph.p_memsz as usize;
        let file_offset = ph.p_offset as usize;
        if file_offset + file_size > buffer.len() {
            return Err(format!(
                "ELF segment exceeds file bounds (offset 0x{:x})",
                file_offset
            )
            .into());
        }

        let target_addr = if ph.p_paddr != 0 {
            ph.p_paddr
        } else {
            ph.p_vaddr
        };
        if target_addr < base {
            return Err(format!(
                "Segment start 0x{:x} lies below DRAM base 0x{:x}",
                target_addr, base
            )
            .into());
        }
        let seg_end = target_addr
            .checked_add(mem_size as u64)
            .ok_or_else(|| "Segment end overflow".to_string())?;
        if seg_end > dram_end {
            return Err(format!(
                "Segment 0x{:x}-0x{:x} exceeds DRAM (end 0x{:x})",
                target_addr, seg_end, dram_end
            )
            .into());
        }

        let dram_offset = (target_addr - base) as u64;
        if file_size > 0 {
            let end = file_offset + file_size;
            bus.dram
                .load(&buffer[file_offset..end], dram_offset)
                .map_err(|e| format!("Failed to load segment: {}", e))?;
        }
        if mem_size > file_size {
            let zero_start = dram_offset as usize + file_size;
            bus.dram
                .zero_range(zero_start, mem_size - file_size)
                .map_err(|e| format!("Failed to zero bss: {}", e))?;
        }
        log::debug!(
            "Loaded segment: addr=0x{:x}, filesz=0x{:x}, memsz=0x{:x}",
            target_addr,
            file_size,
            mem_size
        );
    }

    Ok(elf.entry)
}
</file>

<file path="vm/Cargo.toml">
[package]
name = "riscv-vm"
version = "0.1.0"
edition = "2021"

[lib]
crate-type = ["cdylib", "rlib"]

[dependencies]
log = "0.4"
thiserror = "1.0"
hex = "0.4"
env_logger = "0.10"
clap = { version = "4.4", features = ["derive"] }
libc = "0.2"
goblin = "0.8"
serde = { version = "1.0", features = ["derive"] }
bincode = "1.3"
sha2 = "0.10"
wasm-bindgen = "0.2"

[target.'cfg(target_arch = "wasm32")'.dependencies]
console_error_panic_hook = "0.1"
</file>

<file path="web/public/file.svg">
<svg fill="none" viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg"><path d="M14.5 13.5V5.41a1 1 0 0 0-.3-.7L9.8.29A1 1 0 0 0 9.08 0H1.5v13.5A2.5 2.5 0 0 0 4 16h8a2.5 2.5 0 0 0 2.5-2.5m-1.5 0v-7H8v-5H3v12a1 1 0 0 0 1 1h8a1 1 0 0 0 1-1M9.5 5V2.12L12.38 5zM5.13 5h-.62v1.25h2.12V5zm-.62 3h7.12v1.25H4.5zm.62 3h-.62v1.25h7.12V11z" clip-rule="evenodd" fill="#666" fill-rule="evenodd"/></svg>
</file>

<file path="web/public/globe.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><g clip-path="url(#a)"><path fill-rule="evenodd" clip-rule="evenodd" d="M10.27 14.1a6.5 6.5 0 0 0 3.67-3.45q-1.24.21-2.7.34-.31 1.83-.97 3.1M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16m.48-1.52a7 7 0 0 1-.96 0H7.5a4 4 0 0 1-.84-1.32q-.38-.89-.63-2.08a40 40 0 0 0 3.92 0q-.25 1.2-.63 2.08a4 4 0 0 1-.84 1.31zm2.94-4.76q1.66-.15 2.95-.43a7 7 0 0 0 0-2.58q-1.3-.27-2.95-.43a18 18 0 0 1 0 3.44m-1.27-3.54a17 17 0 0 1 0 3.64 39 39 0 0 1-4.3 0 17 17 0 0 1 0-3.64 39 39 0 0 1 4.3 0m1.1-1.17q1.45.13 2.69.34a6.5 6.5 0 0 0-3.67-3.44q.65 1.26.98 3.1M8.48 1.5l.01.02q.41.37.84 1.31.38.89.63 2.08a40 40 0 0 0-3.92 0q.25-1.2.63-2.08a4 4 0 0 1 .85-1.32 7 7 0 0 1 .96 0m-2.75.4a6.5 6.5 0 0 0-3.67 3.44 29 29 0 0 1 2.7-.34q.31-1.83.97-3.1M4.58 6.28q-1.66.16-2.95.43a7 7 0 0 0 0 2.58q1.3.27 2.95.43a18 18 0 0 1 0-3.44m.17 4.71q-1.45-.12-2.69-.34a6.5 6.5 0 0 0 3.67 3.44q-.65-1.27-.98-3.1" fill="#666"/></g><defs><clipPath id="a"><path fill="#fff" d="M0 0h16v16H0z"/></clipPath></defs></svg>
</file>

<file path="web/public/next.svg">
<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 394 80"><path fill="#000" d="M262 0h68.5v12.7h-27.2v66.6h-13.6V12.7H262V0ZM149 0v12.7H94v20.4h44.3v12.6H94v21h55v12.6H80.5V0h68.7zm34.3 0h-17.8l63.8 79.4h17.9l-32-39.7 32-39.6h-17.9l-23 28.6-23-28.6zm18.3 56.7-9-11-27.1 33.7h17.8l18.3-22.7z"/><path fill="#000" d="M81 79.3 17 0H0v79.3h13.6V17l50.2 62.3H81Zm252.6-.4c-1 0-1.8-.4-2.5-1s-1.1-1.6-1.1-2.6.3-1.8 1-2.5 1.6-1 2.6-1 1.8.3 2.5 1a3.4 3.4 0 0 1 .6 4.3 3.7 3.7 0 0 1-3 1.8zm23.2-33.5h6v23.3c0 2.1-.4 4-1.3 5.5a9.1 9.1 0 0 1-3.8 3.5c-1.6.8-3.5 1.3-5.7 1.3-2 0-3.7-.4-5.3-1s-2.8-1.8-3.7-3.2c-.9-1.3-1.4-3-1.4-5h6c.1.8.3 1.6.7 2.2s1 1.2 1.6 1.5c.7.4 1.5.5 2.4.5 1 0 1.8-.2 2.4-.6a4 4 0 0 0 1.6-1.8c.3-.8.5-1.8.5-3V45.5zm30.9 9.1a4.4 4.4 0 0 0-2-3.3 7.5 7.5 0 0 0-4.3-1.1c-1.3 0-2.4.2-3.3.5-.9.4-1.6 1-2 1.6a3.5 3.5 0 0 0-.3 4c.3.5.7.9 1.3 1.2l1.8 1 2 .5 3.2.8c1.3.3 2.5.7 3.7 1.2a13 13 0 0 1 3.2 1.8 8.1 8.1 0 0 1 3 6.5c0 2-.5 3.7-1.5 5.1a10 10 0 0 1-4.4 3.5c-1.8.8-4.1 1.2-6.8 1.2-2.6 0-4.9-.4-6.8-1.2-2-.8-3.4-2-4.5-3.5a10 10 0 0 1-1.7-5.6h6a5 5 0 0 0 3.5 4.6c1 .4 2.2.6 3.4.6 1.3 0 2.5-.2 3.5-.6 1-.4 1.8-1 2.4-1.7a4 4 0 0 0 .8-2.4c0-.9-.2-1.6-.7-2.2a11 11 0 0 0-2.1-1.4l-3.2-1-3.8-1c-2.8-.7-5-1.7-6.6-3.2a7.2 7.2 0 0 1-2.4-5.7 8 8 0 0 1 1.7-5 10 10 0 0 1 4.3-3.5c2-.8 4-1.2 6.4-1.2 2.3 0 4.4.4 6.2 1.2 1.8.8 3.2 2 4.3 3.4 1 1.4 1.5 3 1.5 5h-5.8z"/></svg>
</file>

<file path="web/public/vercel.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1155 1000"><path d="m577.3 0 577.4 1000H0z" fill="#fff"/></svg>
</file>

<file path="web/public/window.svg">
<svg fill="none" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.5 2.5h13v10a1 1 0 0 1-1 1h-11a1 1 0 0 1-1-1zM0 1h16v11.5a2.5 2.5 0 0 1-2.5 2.5h-11A2.5 2.5 0 0 1 0 12.5zm3.75 4.5a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5M7 4.75a.75.75 0 1 1-1.5 0 .75.75 0 0 1 1.5 0m1.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5" fill="#666"/></svg>
</file>

<file path="web/src/app/globals.css">
@import "tailwindcss";

:root {
  --background: #ffffff;
  --foreground: #171717;
}

@theme inline {
  --color-background: var(--background);
  --color-foreground: var(--foreground);
  --font-sans: var(--font-geist-sans);
  --font-mono: var(--font-geist-mono);
}

@media (prefers-color-scheme: dark) {
  :root {
    --background: #0a0a0a;
    --foreground: #ededed;
  }
}

body {
  background: var(--background);
  color: var(--foreground);
  font-family: Arial, Helvetica, sans-serif;
}
</file>

<file path="web/src/app/layout.tsx">
import type { Metadata } from "next";
import { Geist, Geist_Mono } from "next/font/google";
import "./globals.css";

const geistSans = Geist({
  variable: "--font-geist-sans",
  subsets: ["latin"],
});

const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "Create Next App",
  description: "Generated by create next app",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body
        className={`${geistSans.variable} ${geistMono.variable} antialiased`}
      >
        {children}
      </body>
    </html>
  );
}
</file>

<file path="web/src/app/page.tsx">
"use client";

import {
  useEffect,
  useRef,
} from "react";
import { useVM } from "../hooks/useVM";

export default function Home() {
  const { output, status, sendInput, cpuLoad, memUsage } = useVM();
  const endRef = useRef<HTMLDivElement>(null);

  // Auto scroll
  useEffect(() => {
    endRef.current?.scrollIntoView({ behavior: "smooth" });
  }, [output]);

  // Global key handler so you can still type anywhere on the page
  useEffect(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      if (e.metaKey || e.ctrlKey || e.altKey) return;

      // Don't double-handle keys when an input/textarea/contenteditable has focus
      const target = e.target as HTMLElement | null;
      if (target) {
        const tag = target.tagName;
        if (tag === "INPUT" || tag === "TEXTAREA" || target.isContentEditable) {
          return;
        }
      }

      if (e.key.length === 1 || e.key === "Enter" || e.key === "Backspace") {
        e.preventDefault();
        sendInput(e.key);
      }
    };

    window.addEventListener("keydown", handleKeyDown);
    return () => window.removeEventListener("keydown", handleKeyDown);
  }, [sendInput]);

  return (
    <div className="min-h-screen bg-black text-green-500 p-4 font-mono text-lg flex flex-col">
      <div className="mb-2 border-b border-green-700 pb-2 flex justify-between">
        <h1 className="font-bold">RISC-V VM</h1>
        <div className="flex gap-4 items-center">
          <span className="text-sm text-green-400">
            CPU: {cpuLoad.toFixed(0)}%
          </span>
          <span className="text-sm text-green-400">
            MEM: {(memUsage / (1024 * 1024)).toFixed(1)} MiB
          </span>
          <span
            className={status === "Running" ? "text-green-500" : "text-red-500"}
          >
            [{status}]
          </span>
        </div>
      </div>

      <div className="flex-grow whitespace-pre-wrap break-all focus:outline-none" tabIndex={0}>
        {output}
        <span className="animate-pulse">_</span>
        <div ref={endRef} />
      </div>
      
      <div className="mt-2 text-xs text-gray-500">
          Type anywhere to send input to the VM.
      </div>
    </div>
  );
}
</file>

<file path="web/src/hooks/useVM.ts">
import { useEffect, useRef, useState, useCallback } from 'react';
import init, { WasmVm } from '../pkg/riscv_vm';

export function useVM() {
  const vmRef = useRef<WasmVm | null>(null);
  const [output, setOutput] = useState<string>("");
  const [status, setStatus] = useState<string>("Initializing...");
  const requestRef = useRef<number | null>(null);
  const [cpuLoad, setCpuLoad] = useState<number>(0);
  const [memUsage, setMemUsage] = useState<number>(0);

  const kernelType: 'custom_kernel' | 'kernel' = 'custom_kernel';
  useEffect(() => {
    let active = true;

    async function start() {
      try {
        // Let the bundler resolve the correct wasm asset path.
        await init('/riscv_vm_bg.wasm');

        if (!active) return;

        // Load kernel
        const kernelRes = await fetch(`/${kernelType}`);
        if (!kernelRes.ok) throw new Error(`Failed to load kernel: ${kernelRes.statusText}`);
        const kernelBuf = await kernelRes.arrayBuffer();
        const kernelBytes = new Uint8Array(kernelBuf);

        const vm = new WasmVm(kernelBytes);
        if (kernelType !== 'custom_kernel') {

          // Try to load disk image (optional - some kernels don't need it)
          try {
            const diskRes = await fetch('/fs.img');
            if (diskRes.ok) {
              const diskBuf = await diskRes.arrayBuffer();
              const diskBytes = new Uint8Array(diskBuf);
              vm.load_disk(diskBytes);
            }
          } catch {
            // Disk image not available, continue without it
          }
        }


        vmRef.current = vm;
        setStatus("Running");

        loop();
      } catch (err: any) {
        if (active) setStatus(`Error: ${err.message || err}`);
      }
    }
    start();

    return () => {
      active = false;
      if (requestRef.current !== null) cancelAnimationFrame(requestRef.current);
    };
  }, []);

  const loop = () => {
    const vm = vmRef.current;
    if (!vm) return;

    const INSTRUCTIONS_PER_FRAME = 100000;

    try {
      const t0 = performance.now();
      for (let i = 0; i < INSTRUCTIONS_PER_FRAME; i++) {
        vm.step();
      }
      const t1 = performance.now();
      const duration = t1 - t0;
      const load = Math.min(100, (duration / 16.67) * 100);
      setCpuLoad(load);

      // Query memory usage if the wasm exposes it
      const anyVm = vm as any;
      if (typeof anyVm.get_memory_usage === 'function') {
        const usage = Number(anyVm.get_memory_usage());
        setMemUsage(usage);
      }

      // Drain output buffer (sanitize control chars)
      const codes: number[] = [];
      let ch = (vm as any).get_output?.();
      let limit = 2000;
      while (ch !== undefined && limit > 0) {
        codes.push(Number(ch));
        ch = (vm as any).get_output?.();
        limit--;
      }

      if (codes.length) {
        setOutput(prev => {
          let current = prev;
          for (const code of codes) {
            if (code === 8) {
              // Backspace
              current = current.slice(0, -1);
            } else if (code === 10 || code === 13 || (code >= 32 && code <= 126)) {
              current += String.fromCharCode(code);
            } else {
              // Drop other control bytes
            }
          }
          return current;
        });
      }

      requestRef.current = requestAnimationFrame(loop);
    } catch (e: any) {
      setStatus(`Crashed: ${e}`);
      console.error(e);
    }
  };

  const sendInput = useCallback((key: string) => {
    const vm = vmRef.current;
    if (!vm) return;

    // Map Enter to \n
    if (key === 'Enter') {
      vm.input(10); // \n
      return;
    }

    // Map Backspace to 8
    if (key === 'Backspace') {
      vm.input(8);
      return;
    }

    if (key.length === 1) {
      vm.input(key.charCodeAt(0));
    }
  }, []);

  return { output, status, sendInput, cpuLoad, memUsage };
}
</file>

<file path="web/.gitignore">
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
/node_modules
/.pnp
.pnp.*
.yarn/*
!.yarn/patches
!.yarn/plugins
!.yarn/releases
!.yarn/versions

# testing
/coverage

# next.js
/.next/
/out/

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.pnpm-debug.log*

# env files (can opt-in for committing if needed)
.env*

# vercel
.vercel

# typescript
*.tsbuildinfo
next-env.d.ts
</file>

<file path="web/eslint.config.mjs">
import { defineConfig, globalIgnores } from "eslint/config";
import nextVitals from "eslint-config-next/core-web-vitals";
import nextTs from "eslint-config-next/typescript";

const eslintConfig = defineConfig([
  ...nextVitals,
  ...nextTs,
  // Override default ignores of eslint-config-next.
  globalIgnores([
    // Default ignores of eslint-config-next:
    ".next/**",
    "out/**",
    "build/**",
    "next-env.d.ts",
  ]),
]);

export default eslintConfig;
</file>

<file path="web/next.config.ts">
import type { NextConfig } from "next";

const nextConfig: NextConfig = {
  /* config options here */
};

export default nextConfig;
</file>

<file path="web/package.json">
{
  "name": "web",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "eslint"
  },
  "dependencies": {
    "next": "16.0.3",
    "react": "19.2.0",
    "react-dom": "19.2.0"
  },
  "devDependencies": {
    "@tailwindcss/postcss": "^4",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "eslint": "^9",
    "eslint-config-next": "16.0.3",
    "tailwindcss": "^4",
    "typescript": "^5"
  },
  "packageManager": "yarn@4.11.0+sha512.4e54aeace9141df2f0177c266b05ec50dc044638157dae128c471ba65994ac802122d7ab35bcd9e81641228b7dcf24867d28e750e0bcae8a05277d600008ad54"
}
</file>

<file path="web/postcss.config.mjs">
const config = {
  plugins: {
    "@tailwindcss/postcss": {},
  },
};

export default config;
</file>

<file path="web/README.md">
This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.
</file>

<file path="web/tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "react-jsx",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": [
    "next-env.d.ts",
    "**/*.ts",
    "**/*.tsx",
    ".next/types/**/*.ts",
    ".next/dev/types/**/*.ts",
    "**/*.mts"
  ],
  "exclude": ["node_modules"]
}
</file>

</files>
