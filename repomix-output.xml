This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: relay/**/*, riscv-vm/**/*
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
relay/
  src/
    main.rs
  .dockerignore
  app.json
  Cargo.toml
  Dockerfile
riscv-vm/
  src/
    bus.rs
    clint.rs
    console.rs
    cpu.rs
    csr.rs
    decoder.rs
    dram.rs
    emulator.rs
    lib.rs
    main.rs
    mmu.rs
    net_libp2p.rs
    net_tap.rs
    net_ws.rs
    net.rs
    plic.rs
    uart.rs
    virtio.rs
  Cargo.toml
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="riscv-vm/src/bus.rs">
use crate::clint::{Clint, CLINT_BASE, CLINT_SIZE};
use crate::plic::{Plic, PLIC_BASE, PLIC_SIZE};
use crate::uart::{Uart, UART_BASE, UART_SIZE};
use crate::virtio::VirtioDevice;
use crate::Trap;
use crate::dram::Dram;

/// Default DRAM base for the virt platform.
pub const DRAM_BASE: u64 = 0x8000_0000;

/// Base address of the RISC-V test finisher MMIO region.
pub const TEST_FINISHER_BASE: u64 = 0x0010_0000;
pub const TEST_FINISHER_SIZE: u64 = 0x1000;

/// VirtIO MMIO base address (for the first device).
pub const VIRTIO_BASE: u64 = 0x1000_1000;
/// Size of each VirtIO MMIO region.
pub const VIRTIO_STRIDE: u64 = 0x1000;

pub trait Bus {
    fn read8(&mut self, addr: u64) -> Result<u8, Trap>;
    fn read16(&mut self, addr: u64) -> Result<u16, Trap>;
    fn read32(&mut self, addr: u64) -> Result<u32, Trap>;
    fn read64(&mut self, addr: u64) -> Result<u64, Trap>;

    fn write8(&mut self, addr: u64, val: u8) -> Result<(), Trap>;
    fn write16(&mut self, addr: u64, val: u16) -> Result<(), Trap>;
    fn write32(&mut self, addr: u64, val: u32) -> Result<(), Trap>;
    fn write64(&mut self, addr: u64, val: u64) -> Result<(), Trap>;

    /// Generic load helper used by the MMU for page-table walks.
    fn load(&mut self, addr: u64, size: u64) -> Result<u64, Trap> {
        match size {
            1 => self.read8(addr).map(|v| v as u64),
            2 => self.read16(addr).map(|v| v as u64),
            4 => self.read32(addr).map(|v| v as u64),
            8 => self.read64(addr),
            _ => Err(Trap::Fatal(format!("Unsupported bus load size: {}", size))),
        }
    }

    /// Generic store helper used by the MMU for page-table A/D updates.
    fn store(&mut self, addr: u64, size: u64, value: u64) -> Result<(), Trap> {
        match size {
            1 => self.write8(addr, value as u8),
            2 => self.write16(addr, value as u16),
            4 => self.write32(addr, value as u32),
            8 => self.write64(addr, value),
            _ => Err(Trap::Fatal(format!("Unsupported bus store size: {}", size))),
        }
    }

    fn fetch_u32(&mut self, addr: u64) -> Result<u32, Trap> {
        if addr % 4 != 0 {
            return Err(Trap::InstructionAddressMisaligned(addr));
        }
        // Map LoadAccessFault to InstructionAccessFault for fetch
        self.read32(addr).map_err(|e| match e {
            Trap::LoadAccessFault(a) => Trap::InstructionAccessFault(a),
            Trap::LoadAddressMisaligned(a) => Trap::InstructionAddressMisaligned(a),
            _ => e,
        })
    }

    fn poll_interrupts(&mut self) -> u64 {
        0
    }
}

// A simple system bus that just wraps DRAM for now (Phase 1)
pub struct SystemBus {
    pub dram: Dram,
    pub clint: Clint,
    pub plic: Plic,
    pub uart: Uart,
    pub virtio_devices: Vec<Box<dyn VirtioDevice>>,
}

impl SystemBus {
    pub fn new(dram_base: u64, dram_size: usize) -> Self {
        Self {
            dram: Dram::new(dram_base, dram_size),
            clint: Clint::new(),
            plic: Plic::new(),
            uart: Uart::new(),
            virtio_devices: Vec::new(),
        }
    }

    pub fn dram_base(&self) -> u64 {
        self.dram.base
    }

    pub fn dram_size(&self) -> usize {
        self.dram.data.len()
    }

    pub fn check_interrupts(&mut self) -> u64 {
        // 0. Advance CLINT timer each step
        self.clint.tick();
        
        // 1. Update PLIC with UART status
        let uart_irq = self.uart.interrupting;
        self.plic.set_source_level(crate::plic::UART_IRQ, uart_irq);

        // 1b. Update PLIC with VirtIO interrupts
        // We map VirtIO devices to IRQs starting at VIRTIO0_IRQ (1).
        // Device 0 -> IRQ 1
        // Device 1 -> IRQ 2
        // ...
        // Device 7 -> IRQ 8
        // Note: xv6 expects VIRTIO0 at IRQ 1.
        for (i, dev) in self.virtio_devices.iter().enumerate() {
            let irq = crate::plic::VIRTIO0_IRQ + i as u32;
            if irq < 32 { // PLIC limit
                let intr = dev.is_interrupting();
                if intr && log::log_enabled!(log::Level::Trace) {
                     log::trace!("[Bus] VirtIO dev {} interrupting (irq {})", i, irq);
                }
                self.plic.set_source_level(irq, intr);
            }
        }

        // 2. Calculate MIP bits
        let mut mip = 0;

        // MSIP (Machine Software Interrupt) - Bit 3
        if self.clint.msip[0] & 1 != 0 {
            mip |= 1 << 3;
        }

        // MTIP (Machine Timer Interrupt) - Bit 7
        if self.clint.mtime >= self.clint.mtimecmp[0] {
            mip |= 1 << 7;
        }

        // SEIP (Supervisor External Interrupt) - Bit 9
        if self.plic.is_interrupt_pending_for(1) {
            mip |= 1 << 9;
        }

        // MEIP (Machine External Interrupt) - Bit 11
        if self.plic.is_interrupt_pending_for(0) {
            mip |= 1 << 11;
        }

        mip
    }

    fn get_virtio_device(&mut self, addr: u64) -> Option<(usize, u64)> {
        if addr >= VIRTIO_BASE {
            let offset = addr - VIRTIO_BASE;
            let idx = (offset / VIRTIO_STRIDE) as usize;
            if idx < self.virtio_devices.len() {
                return Some((idx, offset % VIRTIO_STRIDE));
            }
        }
        None
    }
    
    /// Check if an address is in the VirtIO MMIO region (even if no device present).
    /// Returns the offset within the device region if in range.
    fn is_virtio_region(&self, addr: u64) -> Option<u64> {
        if addr >= VIRTIO_BASE && addr < VIRTIO_BASE + VIRTIO_STRIDE * 8 {
            Some((addr - VIRTIO_BASE) % VIRTIO_STRIDE)
        } else {
            None
        }
    }
    
    /// Poll all VirtIO devices for pending work (e.g., incoming network packets).
    /// Should be called periodically from the main emulation loop.
    pub fn poll_virtio(&mut self) {
        for device in &mut self.virtio_devices {
            if let Err(e) = device.poll(&mut self.dram) {
                log::warn!("[Bus] VirtIO poll error: {:?}", e);
            }
        }
    }
}

impl Bus for SystemBus {
    fn poll_interrupts(&mut self) -> u64 {
        self.check_interrupts()
    }

    fn read8(&mut self, addr: u64) -> Result<u8, Trap> {
        // Test finisher region: reads are harmless and return zero.
        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Ok(0);
        }

        if let Some(off) = self.dram.offset(addr) {
            return Ok(self.dram.data[off]);
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            let val = self.clint.load(offset, 1);
            return Ok(val as u8);
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            let val = self.plic.load(offset, 1).map_err(|_| Trap::LoadAccessFault(addr))?;
            return Ok(val as u8);
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             let val = self.uart.load(offset, 1).map_err(|_| Trap::LoadAccessFault(addr))?;
             return Ok(val as u8);
        }

        if let Some((idx, offset)) = self.get_virtio_device(addr) {
            // Emulate narrow MMIO reads by extracting from the 32-bit register value
            let aligned = offset & !3;
            let word = self.virtio_devices[idx].read(aligned).map_err(|_| Trap::LoadAccessFault(addr))?;
            let shift = ((offset & 3) * 8) as u64;
            return Ok(((word >> shift) & 0xff) as u8);
        }
        
        // Unmapped VirtIO slots return 0 (allows safe probing)
        if self.is_virtio_region(addr).is_some() {
            return Ok(0);
        }

        Err(Trap::LoadAccessFault(addr))
    }

    fn read16(&mut self, addr: u64) -> Result<u16, Trap> {
        if addr % 2 != 0 {
            return Err(Trap::LoadAddressMisaligned(addr));
        }

        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Ok(0);
        }

        if let Some(off) = self.dram.offset(addr) {
            if off + 2 > self.dram.data.len() {
                return Err(Trap::LoadAccessFault(addr));
            }
            let bytes = &self.dram.data[off..off + 2];
            return Ok(u16::from_le_bytes(bytes.try_into().unwrap()));
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            let val = self.clint.load(offset, 2);
            return Ok(val as u16);
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            let val = self.plic.load(offset, 2).map_err(|_| Trap::LoadAccessFault(addr))?;
            return Ok(val as u16);
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             let val = self.uart.load(offset, 2).map_err(|_| Trap::LoadAccessFault(addr))?;
             return Ok(val as u16);
        }

        if let Some((idx, offset)) = self.get_virtio_device(addr) {
            let aligned = offset & !3;
            let word = self.virtio_devices[idx].read(aligned).map_err(|_| Trap::LoadAccessFault(addr))?;
            let shift = ((offset & 3) * 8) as u64;
            return Ok(((word >> shift) & 0xffff) as u16);
        }
        
        // Unmapped VirtIO slots return 0 (allows safe probing)
        if self.is_virtio_region(addr).is_some() {
            return Ok(0);
        }

        Err(Trap::LoadAccessFault(addr))
    }

    fn read32(&mut self, addr: u64) -> Result<u32, Trap> {
        if addr % 4 != 0 {
            return Err(Trap::LoadAddressMisaligned(addr));
        }

        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Ok(0);
        }

        if let Some(off) = self.dram.offset(addr) {
            if off + 4 > self.dram.data.len() {
                return Err(Trap::LoadAccessFault(addr));
            }
            let bytes = &self.dram.data[off..off + 4];
            return Ok(u32::from_le_bytes(bytes.try_into().unwrap()));
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            let val = self.clint.load(offset, 4);
            return Ok(val as u32);
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            let val = self.plic.load(offset, 4).map_err(|_| Trap::LoadAccessFault(addr))?;
            return Ok(val as u32);
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             let val = self.uart.load(offset, 4).map_err(|_| Trap::LoadAccessFault(addr))?;
             return Ok(val as u32);
        }

        if let Some((idx, offset)) = self.get_virtio_device(addr) {
            let val = self.virtio_devices[idx].read(offset).map_err(|_| Trap::LoadAccessFault(addr))?;
            return Ok(val as u32);
        }
        
        // Unmapped VirtIO slots return 0 (allows safe probing)
        if self.is_virtio_region(addr).is_some() {
            return Ok(0);
        }

        Err(Trap::LoadAccessFault(addr))
    }

    fn read64(&mut self, addr: u64) -> Result<u64, Trap> {
        if addr % 8 != 0 {
            return Err(Trap::LoadAddressMisaligned(addr));
        }

        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Ok(0);
        }

        if let Some(off) = self.dram.offset(addr) {
            if off + 8 > self.dram.data.len() {
                return Err(Trap::LoadAccessFault(addr));
            }
            let bytes = &self.dram.data[off..off + 8];
            return Ok(u64::from_le_bytes(bytes.try_into().unwrap()));
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            let val = self.clint.load(offset, 8);
            return Ok(val);
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            let val = self.plic.load(offset, 8).map_err(|_| Trap::LoadAccessFault(addr))?;
            return Ok(val);
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             let val = self.uart.load(offset, 8).map_err(|_| Trap::LoadAccessFault(addr))?;
             return Ok(val);
        }

        if let Some((idx, offset)) = self.get_virtio_device(addr) {
            let low = self.virtio_devices[idx].read(offset).map_err(|_| Trap::LoadAccessFault(addr))?;
            let high = self.virtio_devices[idx].read(offset + 4).map_err(|_| Trap::LoadAccessFault(addr + 4))?;
            return Ok((low as u64) | ((high as u64) << 32));
        }
        
        // Unmapped VirtIO slots return 0 (allows safe probing)
        if self.is_virtio_region(addr).is_some() {
            return Ok(0);
        }

        Err(Trap::LoadAccessFault(addr))
    }

    fn write8(&mut self, addr: u64, val: u8) -> Result<(), Trap> {
        // Any write in the test finisher region signals a requested trap to the host.
        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Err(Trap::RequestedTrap(val as u64));
        }

        if let Some(off) = self.dram.offset(addr) {
            self.dram.data[off] = val;
            return Ok(());
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            self.clint.store(offset, 1, val as u64);
            return Ok(());
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            self.plic.store(offset, 1, val as u64).map_err(|_| Trap::StoreAccessFault(addr))?;
            return Ok(());
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             self.uart.store(offset, 1, val as u64).map_err(|_| Trap::StoreAccessFault(addr))?;
             return Ok(());
        }

        if let Some((_idx, _offset)) = self.get_virtio_device(addr) {
            // VirtIO registers are 32-bit. Byte writes are not strictly supported by the spec for all registers.
            // We ignore them for now to be safe.
            return Ok(());
        }

        Err(Trap::StoreAccessFault(addr))
    }

    fn write16(&mut self, addr: u64, val: u16) -> Result<(), Trap> {
        if addr % 2 != 0 {
            return Err(Trap::StoreAddressMisaligned(addr));
        }

        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Err(Trap::RequestedTrap(val as u64));
        }

        if let Some(off) = self.dram.offset(addr) {
            if off + 2 > self.dram.data.len() {
                return Err(Trap::StoreAccessFault(addr));
            }
            let bytes = val.to_le_bytes();
            self.dram.data[off..off + 2].copy_from_slice(&bytes);
            return Ok(());
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            self.clint.store(offset, 2, val as u64);
            return Ok(());
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            self.plic.store(offset, 2, val as u64).map_err(|_| Trap::StoreAccessFault(addr))?;
            return Ok(());
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             self.uart.store(offset, 2, val as u64).map_err(|_| Trap::StoreAccessFault(addr))?;
             return Ok(());
        }

        if let Some((_idx, _offset)) = self.get_virtio_device(addr) {
            return Ok(());
        }

        Err(Trap::StoreAccessFault(addr))
    }

    fn write32(&mut self, addr: u64, val: u32) -> Result<(), Trap> {
        if addr % 4 != 0 {
            return Err(Trap::StoreAddressMisaligned(addr));
        }

        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Err(Trap::RequestedTrap(val as u64));
        }

        if let Some(off) = self.dram.offset(addr) {
            if off + 4 > self.dram.data.len() {
                return Err(Trap::StoreAccessFault(addr));
            }
            let bytes = val.to_le_bytes();
            self.dram.data[off..off + 4].copy_from_slice(&bytes);
            return Ok(());
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            self.clint.store(offset, 4, val as u64);
            return Ok(());
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            self.plic.store(offset, 4, val as u64).map_err(|_| Trap::StoreAccessFault(addr))?;
            return Ok(());
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             self.uart.store(offset, 4, val as u64).map_err(|_| Trap::StoreAccessFault(addr))?;
             return Ok(());
        }

        if let Some((idx, offset)) = self.get_virtio_device(addr) {
            self.virtio_devices[idx].write(offset, val as u64, &mut self.dram)
                .map_err(|_| Trap::StoreAccessFault(addr))?;
            return Ok(());
        }
        
        // Writes to unmapped VirtIO slots are silently ignored (allows safe probing)
        if self.is_virtio_region(addr).is_some() {
            return Ok(());
        }

        Err(Trap::StoreAccessFault(addr))
    }

    fn write64(&mut self, addr: u64, val: u64) -> Result<(), Trap> {
        if addr % 8 != 0 {
            return Err(Trap::StoreAddressMisaligned(addr));
        }

        if addr >= TEST_FINISHER_BASE && addr < TEST_FINISHER_BASE + TEST_FINISHER_SIZE {
            return Err(Trap::RequestedTrap(val));
        }

        if let Some(off) = self.dram.offset(addr) {
            if off + 8 > self.dram.data.len() {
                return Err(Trap::StoreAccessFault(addr));
            }
            let bytes = val.to_le_bytes();
            self.dram.data[off..off + 8].copy_from_slice(&bytes);
            return Ok(());
        }

        if addr >= CLINT_BASE && addr < CLINT_BASE + CLINT_SIZE {
            let offset = addr - CLINT_BASE;
            self.clint.store(offset, 8, val);
            return Ok(());
        }

        if addr >= PLIC_BASE && addr < PLIC_BASE + PLIC_SIZE {
            let offset = addr - PLIC_BASE;
            self.plic.store(offset, 8, val).map_err(|_| Trap::StoreAccessFault(addr))?;
            return Ok(());
        }

        if addr >= UART_BASE && addr < UART_BASE + UART_SIZE {
             let offset = addr - UART_BASE;
             self.uart.store(offset, 8, val).map_err(|_| Trap::StoreAccessFault(addr))?;
             return Ok(());
        }

        if let Some((_idx, _offset)) = self.get_virtio_device(addr) {
            // VirtIO registers are 32-bit. 64-bit writes are not typically supported directly via MMIO
            // except for legacy queue PFN which is 32-bit anyway.
            return Ok(());
        }
        
        // Writes to unmapped VirtIO slots are silently ignored (allows safe probing)
        if self.is_virtio_region(addr).is_some() {
            return Ok(());
        }

        Err(Trap::StoreAccessFault(addr))
    }
}
</file>

<file path="riscv-vm/src/clint.rs">
pub const CLINT_BASE: u64 = 0x0200_0000;
pub const CLINT_SIZE: u64 = 0x10000;

pub const MSIP_OFFSET: u64 = 0x0000;
pub const MTIME_OFFSET: u64 = 0xbff8;
pub const MTIMECMP_OFFSET: u64 = 0x4000;

pub const MAX_HARTS: usize = 8;

/// Time increment per CPU step (in timer ticks).
/// At 10MHz and ~1 instruction per cycle at ~10MHz CPU, this gives roughly real-time.
/// Adjust for desired timer granularity.
const MTIME_INCREMENT: u64 = 1;

pub struct Clint {
    pub msip: [u32; MAX_HARTS],
    pub mtimecmp: [u64; MAX_HARTS],
    /// Machine timer counter. Incremented by `tick()` each CPU step.
    pub mtime: u64,
    pub debug: bool,
}

impl Clint {
    pub fn new() -> Self {
        Self {
            msip: [0; MAX_HARTS],
            mtimecmp: [u64::MAX; MAX_HARTS], 
            mtime: 0,
            debug: false,
        }
    }

    /// Returns the current mtime value.
    pub fn mtime(&self) -> u64 {
        self.mtime
    }

    /// Sets mtime to a specific value (used for snapshot restore).
    pub fn set_mtime(&mut self, val: u64) {
        self.mtime = val;
    }

    /// Advance mtime by one tick. Called once per CPU step.
    pub fn tick(&mut self) {
        self.mtime = self.mtime.wrapping_add(MTIME_INCREMENT);
    }

    /// Backward compatibility: increment is now tick()
    pub fn increment(&mut self) {
        self.tick();
    }

    pub fn sync_time_micros(&mut self, _micros: u64) {
        // No-op for deterministic timer
    }

    /// Load from the CLINT register space.
    ///
    /// Offsets are relative to `CLINT_BASE`. Only naturally aligned 4- and
    /// 8-byte accesses are architecturally meaningful; other sizes return 0.
    pub fn load(&self, offset: u64, size: u64) -> u64 {
        match (offset, size) {
            // MSIP[hart], 32-bit
            (o, 4) if o >= MSIP_OFFSET && o < MSIP_OFFSET + (MAX_HARTS as u64 * 4) => {
                let hart_idx = ((o - MSIP_OFFSET) / 4) as usize;
                self.msip[hart_idx] as u64
            }

            // MTIME, 64-bit
            (MTIME_OFFSET, 8) => self.mtime(),
            // MTIME, low/high 32-bit words
            (MTIME_OFFSET, 4) => self.mtime() & 0xffff_ffff,
            (o, 4) if o == MTIME_OFFSET + 4 => self.mtime() >> 32,

            // MTIMECMP[hart], 64-bit and split 32-bit accesses
            (o, 8) if o >= MTIMECMP_OFFSET && o < MTIMECMP_OFFSET + (MAX_HARTS as u64 * 8) => {
                let hart_idx = ((o - MTIMECMP_OFFSET) / 8) as usize;
                self.mtimecmp[hart_idx]
            }
            (o, 4) if o >= MTIMECMP_OFFSET && o < MTIMECMP_OFFSET + (MAX_HARTS as u64 * 8) => {
                let hart_idx = ((o - MTIMECMP_OFFSET) / 8) as usize;
                let sub = (o - MTIMECMP_OFFSET) % 8;
                let val = self.mtimecmp[hart_idx];
                match sub {
                    0 => val & 0xffff_ffff,
                    4 => val >> 32,
                    _ => 0,
                }
            }

            // Other offsets/sizes are reserved -> read as zero.
            _ => 0,
        }
    }

    /// Store into the CLINT register space.
    ///
    /// Offsets are relative to `CLINT_BASE`. Mis-sized or strange offsets are
    /// ignored to keep the device side-effect free for unsupported accesses.
    pub fn store(&mut self, offset: u64, size: u64, value: u64) {
        match (offset, size) {
            // MSIP[hart], 32-bit
            (o, 4) if o >= MSIP_OFFSET && o < MSIP_OFFSET + (MAX_HARTS as u64 * 4) => {
                let hart_idx = ((o - MSIP_OFFSET) / 4) as usize;
                // Only the LSB matters for MSIP
                self.msip[hart_idx] = (value & 1) as u32;
            }

            // MTIME is read-only in this implementation (driven by wall clock)
            (MTIME_OFFSET, _) => {}
            (o, 4) if o == MTIME_OFFSET + 4 => {}

            // MTIMECMP[hart], 64-bit and split 32-bit writes
            (o, 8) if o >= MTIMECMP_OFFSET && o < MTIMECMP_OFFSET + (MAX_HARTS as u64 * 8) => {
                let hart_idx = ((o - MTIMECMP_OFFSET) / 8) as usize;
                self.mtimecmp[hart_idx] = value;
            }
            (o, 4) if o >= MTIMECMP_OFFSET && o < MTIMECMP_OFFSET + (MAX_HARTS as u64 * 8) => {
                let hart_idx = ((o - MTIMECMP_OFFSET) / 8) as usize;
                let sub = (o - MTIMECMP_OFFSET) % 8;
                let current = self.mtimecmp[hart_idx];
                self.mtimecmp[hart_idx] = match sub {
                    0 => (current & 0xffff_ffff_0000_0000) | (value & 0xffff_ffff),
                    4 => (current & 0x0000_0000_ffff_ffff) | (value << 32),
                    _ => current,
                };
            }

            _ => {}
        }
    }
}
</file>

<file path="riscv-vm/src/console.rs">
//! Console handling for terminal I/O (not available in WASM).

#![cfg(not(target_arch = "wasm32"))]

use std::io::{self, Read};
use std::sync::mpsc;
use std::thread;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;

pub struct Console {
    rx: mpsc::Receiver<u8>,
    original_termios: Option<libc::termios>,
    running: Arc<AtomicBool>,
}

impl Console {
    pub fn new() -> Self {
        let (tx, rx) = mpsc::channel();
        let running = Arc::new(AtomicBool::new(true));
        let r_clone = running.clone();

        // Setup raw mode
        let mut original_termios = None;
        if unsafe { libc::isatty(libc::STDIN_FILENO) } == 1 {
            let mut termios = unsafe { std::mem::zeroed() };
            if unsafe { libc::tcgetattr(libc::STDIN_FILENO, &mut termios) } == 0 {
                original_termios = Some(termios);
                let mut raw = termios;
                unsafe {
                    libc::cfmakeraw(&mut raw);
                    libc::tcsetattr(libc::STDIN_FILENO, libc::TCSANOW, &raw);
                }
            }
        }

        thread::spawn(move || {
            let mut buf = [0u8; 1];
            let stdin = io::stdin();
            let mut handle = stdin.lock();
            
            while r_clone.load(Ordering::Relaxed) {
                // This read is blocking. 
                // In a real app we might want non-blocking or select, 
                // but for this simple VM, blocking thread is fine.
                if handle.read_exact(&mut buf).is_ok() {
                    let b = buf[0];
                    // Translate Ctrl-A x to exit? 
                    // Let's leave exit handling to the consumer or special key.
                    // Typically Ctrl-A x is (1, 120).
                    // We just pass raw bytes.
                    if tx.send(b).is_err() {
                        break;
                    }
                } else {
                    break;
                }
            }
        });

        Self {
            rx,
            original_termios,
            running,
        }
    }

    pub fn poll(&self) -> Option<u8> {
        self.rx.try_recv().ok()
    }
}

impl Drop for Console {
    fn drop(&mut self) {
        self.running.store(false, Ordering::Relaxed);
        if let Some(termios) = self.original_termios {
            unsafe {
                libc::tcsetattr(libc::STDIN_FILENO, libc::TCSANOW, &termios);
            }
        }
    }
}
</file>

<file path="riscv-vm/src/cpu.rs">
use crate::bus::Bus;
use crate::clint::{CLINT_BASE, MTIME_OFFSET};
use crate::csr::{
    Mode, CSR_MCAUSE, CSR_MEPC, CSR_MISA, CSR_MSTATUS, CSR_MTVEC, CSR_MTVAL, CSR_MIDELEG,
    CSR_MIE, CSR_MIP, CSR_SATP, CSR_MEDELEG, CSR_STVEC, CSR_SEPC, CSR_SCAUSE, CSR_STVAL, CSR_SIE,
    CSR_SSTATUS, CSR_SIP, CSR_TIME, CSR_MENVCFG, CSR_STIMECMP,
};
use crate::decoder::{self, Op, Register};
use crate::mmu::{self, AccessType as MmuAccessType, Tlb};
use crate::Trap;
use std::collections::HashMap;

pub struct Cpu {
    pub regs: [u64; 32],
    pub pc: u64,
    /// Reservation set address for LR/SC (granule-aligned), or None if no reservation.
    reservation: Option<u64>,
    /// Simple CSR storage for Zicsr (12-bit CSR address space).
    csrs: [u64; 4096],
    /// Current privilege mode (Machine/Supervisor/User).
    pub mode: Mode,
    /// Per-hart TLB for Sv39/Sv48 translation.
    pub tlb: Tlb,
}

impl Cpu {
    pub fn new(pc: u64) -> Self {
        let mut csrs = [0u64; 4096];
        // misa: rv64imac_zicsr_zifencei (value from phase-0.md)
        const MISA_RV64IMAC_ZICSR_ZIFENCEI: u64 = 0x4000_0000_0018_1125;
        csrs[CSR_MISA as usize] = MISA_RV64IMAC_ZICSR_ZIFENCEI;

        // mstatus initial value: all zeros except UXL/SXL can be left as 0 (WARL).
        csrs[CSR_MSTATUS as usize] = 0;

        Self {
            regs: [0; 32],
            pc,
            reservation: None,
            csrs,
            mode: Mode::Machine,
            tlb: Tlb::new(),
        }
    }

    /// Export the current CSR image into a compact map suitable for
    /// serialization in snapshots.
    pub fn export_csrs(&self) -> HashMap<u16, u64> {
        let mut map = HashMap::new();
        for (idx, &val) in self.csrs.iter().enumerate() {
            if val != 0 {
                map.insert(idx as u16, val);
            }
        }
        map
    }

    /// Restore CSRs from a previously exported map.
    ///
    /// Any CSR not present in the map is reset to 0. This is intentionally
    /// low-level and bypasses architectural WARL checks; it is only used for
    /// snapshot/restore.
    pub fn import_csrs(&mut self, map: &HashMap<u16, u64>) {
        self.csrs = [0u64; 4096];
        for (&addr, &val) in map.iter() {
            let idx = addr as usize;
            if idx < self.csrs.len() {
                self.csrs[idx] = val;
            }
        }
    }

    pub fn read_reg(&self, reg: Register) -> u64 {
        if reg == Register::X0 {
            0
        } else {
            self.regs[reg.to_usize()]
        }
    }

    pub fn write_reg(&mut self, reg: Register, val: u64) {
        if reg != Register::X0 {
            self.regs[reg.to_usize()] = val;
        }
    }

    fn reservation_granule(addr: u64) -> u64 {
        const GRANULE: u64 = 64;
        addr & !(GRANULE - 1)
    }

    fn clear_reservation_if_conflict(&mut self, addr: u64) {
        if let Some(res) = self.reservation {
            if Self::reservation_granule(res) == Self::reservation_granule(addr) {
                self.reservation = None;
            }
        }
    }

    pub fn read_csr(&self, addr: u16) -> Result<u64, Trap> {
        // Privilege checks per RISC-V privileged spec:
        // CSR address bits [9:8] encode the lowest privilege level that can access:
        //   00 = User, 01 = Supervisor, 10 = Hypervisor (reserved), 11 = Machine
        let required_priv = (addr >> 8) & 0x3;
        let current_priv = match self.mode {
            Mode::User => 0,
            Mode::Supervisor => 1,
            Mode::Machine => 3,
        };
        if current_priv < required_priv {
            return Err(Trap::IllegalInstruction(addr as u64));
        }

        match addr {
            CSR_SSTATUS => {
                let mstatus = self.csrs[CSR_MSTATUS as usize];
                // Mask for sstatus view: SIE(1), SPIE(5), SPP(8), FS(13:14), XS(15:16), SUM(18), MXR(19), UXL(32:33), SD(63)
                // Simplified mask for this emulator:
                let mask = (1 << 1) | (1 << 5) | (1 << 8) | (3 << 13) | (1 << 18) | (1 << 19);
                Ok(mstatus & mask)
            }
            CSR_SIE => {
                let mie = self.csrs[CSR_MIE as usize];
                // Mask delegated interrupts: SSIP(1), STIP(5), SEIP(9)
                let mask = (1 << 1) | (1 << 5) | (1 << 9);
                Ok(mie & mask)
            }
            CSR_SIP => {
                let mip = self.csrs[CSR_MIP as usize];
                let mask = (1 << 1) | (1 << 5) | (1 << 9);
                Ok(mip & mask)
            }
            _ => Ok(self.csrs[addr as usize]),
        }
    }

    pub fn write_csr(&mut self, addr: u16, val: u64) -> Result<(), Trap> {
        // Read-only CSRs have bits [11:10] == 0b11
        let read_only = (addr >> 10) & 0x3 == 0x3;
        if read_only {
            // Writes to read-only CSRs are ignored (WARL behavior for some, illegal for others)
            // For simplicity, we just ignore the write
            return Ok(());
        }
        
        // Privilege checks per RISC-V privileged spec:
        // CSR address bits [9:8] encode the lowest privilege level that can access
        let required_priv = (addr >> 8) & 0x3;
        let current_priv = match self.mode {
            Mode::User => 0,
            Mode::Supervisor => 1,
            Mode::Machine => 3,
        };
        if current_priv < required_priv {
            return Err(Trap::IllegalInstruction(addr as u64));
        }

        match addr {
            CSR_SSTATUS => {
                let mut mstatus = self.csrs[CSR_MSTATUS as usize];
                let mask = (1 << 1) | (1 << 5) | (1 << 8) | (3 << 13) | (1 << 18) | (1 << 19);
                mstatus = (mstatus & !mask) | (val & mask);
                self.csrs[CSR_MSTATUS as usize] = mstatus;
                Ok(())
            }
            CSR_SIE => {
                let mut mie = self.csrs[CSR_MIE as usize];
                let mask = (1 << 1) | (1 << 5) | (1 << 9);
                mie = (mie & !mask) | (val & mask);
                self.csrs[CSR_MIE as usize] = mie;
                Ok(())
            }
            CSR_SIP => {
                let mut mip = self.csrs[CSR_MIP as usize];
                // Only SSIP is writable in SIP
                let mask = 1 << 1;
                mip = (mip & !mask) | (val & mask);
                self.csrs[CSR_MIP as usize] = mip;
                Ok(())
            }
            _ => {
                self.csrs[addr as usize] = val;
                Ok(())
            }
        }
    }

    /// Map a `Trap` into (is_interrupt, cause, tval) per privileged spec, or `None` if it's a host-only error.
    fn trap_to_cause_tval(trap: &Trap) -> Option<(bool, u64, u64)> {
        match *trap {
            Trap::InstructionAddressMisaligned(addr) => Some((false, 0, addr)),
            Trap::InstructionAccessFault(addr) => Some((false, 1, addr)),
            Trap::IllegalInstruction(bits) => Some((false, 2, bits)),
            Trap::Breakpoint => Some((false, 3, 0)),
            Trap::LoadAddressMisaligned(addr) => Some((false, 4, addr)),
            Trap::LoadAccessFault(addr) => Some((false, 5, addr)),
            Trap::StoreAddressMisaligned(addr) => Some((false, 6, addr)),
            Trap::StoreAccessFault(addr) => Some((false, 7, addr)),
            Trap::EnvironmentCallFromU => Some((false, 8, 0)),
            Trap::EnvironmentCallFromS => Some((false, 9, 0)),
            Trap::EnvironmentCallFromM => Some((false, 11, 0)),
            Trap::InstructionPageFault(addr) => Some((false, 12, addr)),
            Trap::LoadPageFault(addr) => Some((false, 13, addr)),
            Trap::StorePageFault(addr) => Some((false, 15, addr)),
            
            Trap::SupervisorSoftwareInterrupt => Some((true, 1, 0)),
            Trap::MachineSoftwareInterrupt => Some((true, 3, 0)),
            Trap::SupervisorTimerInterrupt => Some((true, 5, 0)),
            Trap::MachineTimerInterrupt => Some((true, 7, 0)),
            Trap::SupervisorExternalInterrupt => Some((true, 9, 0)),
            Trap::MachineExternalInterrupt => Some((true, 11, 0)),

            Trap::RequestedTrap(_) | Trap::Fatal(_) => None,
        }
    }

    fn handle_trap<T>(&mut self, trap: Trap, pc: u64, _insn_raw: Option<u32>) -> Result<T, Trap> {
        // Fatal/host-only traps bypass architectural trap entry.
        if let Some((is_interrupt, cause, tval)) = Self::trap_to_cause_tval(&trap) {
            // Determine delegation target per medeleg/mideleg
            let medeleg = self.csrs[CSR_MEDELEG as usize];
            let mideleg = self.csrs[CSR_MIDELEG as usize];
            let deleg_bit = 1u64 << (cause as u64);

            let deleg_to_s = match self.mode {
                // Delegation to a lower privilege is only meaningful when not in Machine mode
                Mode::Machine => false,
                _ => {
                    if is_interrupt {
                        (mideleg & deleg_bit) != 0
                    } else {
                        (medeleg & deleg_bit) != 0
                    }
                }
            };

            if deleg_to_s {
                // Supervisor trap entry (do not modify M-mode CSRs)
                // Save faulting PC and tval to supervisor CSRs
                self.csrs[CSR_SEPC as usize] = pc;
                self.csrs[CSR_STVAL as usize] = tval;
                let scause_val = ((is_interrupt as u64) << 63) | (cause & 0x7FFF_FFFF_FFFF_FFFF);
                self.csrs[CSR_SCAUSE as usize] = scause_val;

                // Update mstatus: SPP, SPIE, clear SIE
                let mut mstatus = self.csrs[CSR_MSTATUS as usize];
                if log::log_enabled!(log::Level::Trace) {
                    log::trace!("Trap to S-mode: mstatus_before={:x}", mstatus);
                }
                
                let sie = (mstatus >> 1) & 1;
                // SPIE <= SIE
                mstatus = (mstatus & !(1 << 5)) | (sie << 5);
                // SIE <= 0
                mstatus &= !(1 << 1);
                // SPP <= current privilege (1 if S, 0 if U)
                let spp = match self.mode {
                    Mode::Supervisor => 1,
                    _ => 0,
                };
                mstatus = (mstatus & !(1 << 8)) | (spp << 8);
                self.csrs[CSR_MSTATUS as usize] = mstatus;
                
                if log::log_enabled!(log::Level::Trace) {
                    log::trace!("Trap to S-mode: mstatus_after={:x}", mstatus);
                }

                self.mode = Mode::Supervisor;

                // Set PC to stvec (vectored if interrupt and mode==1)
                let stvec = self.csrs[CSR_STVEC as usize];
                let base = stvec & !0b11;
                let mode = stvec & 0b11;
                let vectored = mode == 1;
                let target_pc = if is_interrupt && vectored {
                    base.wrapping_add(4 * cause)
                } else {
                    base
                };
                self.pc = target_pc;
            } else {
                // Machine trap entry (default)
                // Save faulting PC and tval.
                self.csrs[CSR_MEPC as usize] = pc;
                self.csrs[CSR_MTVAL as usize] = tval;

                let mcause_val = ((is_interrupt as u64) << 63) | (cause & 0x7FFF_FFFF_FFFF_FFFF);
                self.csrs[CSR_MCAUSE as usize] = mcause_val;

                // Update mstatus: MPP, MPIE, clear MIE
                let mut mstatus = self.csrs[CSR_MSTATUS as usize];
                let mie = (mstatus >> 3) & 1;
                // MPIE <= MIE, MIE <= 0
                mstatus = (mstatus & !(1 << 7)) | (mie << 7);
                mstatus &= !(1 << 3);
                // MPP <= current mode.
                let mpp = self.mode.to_mpp();
                mstatus = (mstatus & !(0b11 << 11)) | (mpp << 11);
                self.csrs[CSR_MSTATUS as usize] = mstatus;
                self.mode = Mode::Machine;

                // Set PC to mtvec (vectored if interrupt and mode==1)
                let mtvec = self.csrs[CSR_MTVEC as usize];
                let base = mtvec & !0b11;
                let mode = mtvec & 0b11;
                let vectored = mode == 1;
                let target_pc = if is_interrupt && vectored {
                    base.wrapping_add(4 * cause)
                } else {
                    base
                };
                self.pc = target_pc;
            }
        }

        Err(trap)
    }

    /// Translate a virtual address to a physical address using the MMU.
    ///
    /// On translation failure, this enters the trap handler and returns the
    /// trap via `Err`.
    fn translate_addr(
        &mut self,
        bus: &mut dyn Bus,
        vaddr: u64,
        access: MmuAccessType,
        pc: u64,
        insn_raw: Option<u32>,
    ) -> Result<u64, Trap> {
        let satp = self.csrs[CSR_SATP as usize];
        let mstatus = self.csrs[CSR_MSTATUS as usize];
        match mmu::translate(bus, &mut self.tlb, self.mode, satp, mstatus, vaddr, access) {
            Ok(pa) => Ok(pa),
            Err(trap) => self.handle_trap(trap, pc, insn_raw),
        }
    }

    fn fetch_and_expand(&mut self, bus: &mut dyn Bus) -> Result<(u32, u8), Trap> {
        let pc = self.pc;
        if pc % 2 != 0 {
            return self.handle_trap(Trap::InstructionAddressMisaligned(pc), pc, None);
        }

        // Fetch first halfword via MMU (instruction access).
        let pa_low = self.translate_addr(bus, pc, MmuAccessType::Instruction, pc, None)?;
        let half = match bus.read16(pa_low) {
            Ok(v) => v,
            Err(e) => {
                // Map load faults from the bus into instruction faults.
                let mapped = match e {
                    Trap::LoadAccessFault(_) => Trap::InstructionAccessFault(pc),
                    Trap::LoadAddressMisaligned(_) => Trap::InstructionAddressMisaligned(pc),
                    other => other,
                };
                return self.handle_trap(mapped, pc, None);
            }
        };

        if half & 0x3 != 0x3 {
            // Compressed 16-bit instruction
            let insn32 = match decoder::expand_compressed(half) {
                Ok(v) => v,
                Err(trap) => return self.handle_trap(trap, pc, None),
            };
            Ok((insn32, 2))
        } else {
            // 32-bit instruction; fetch high half via MMU as well.
            let pc_hi = pc.wrapping_add(2);
            let pa_hi = self.translate_addr(bus, pc_hi, MmuAccessType::Instruction, pc, None)?;
            let hi = match bus.read16(pa_hi) {
                Ok(v) => v,
                Err(e) => {
                    let mapped = match e {
                        Trap::LoadAccessFault(_) => Trap::InstructionAccessFault(pc),
                        Trap::LoadAddressMisaligned(_) => Trap::InstructionAddressMisaligned(pc),
                        other => other,
                    };
                    return self.handle_trap(mapped, pc, None);
                }
            };
            let insn32 = (half as u32) | ((hi as u32) << 16);
            Ok((insn32, 4))
        }
    }

    fn check_pending_interrupt(&self) -> Option<Trap> {
        let mstatus = self.csrs[CSR_MSTATUS as usize];
        let mip = self.csrs[CSR_MIP as usize];
        let mie = self.csrs[CSR_MIE as usize];
        let mideleg = self.csrs[CSR_MIDELEG as usize];

        // SIE is a shadow of MIE for supervisor interrupt bits (SSIP=1, STIP=5, SEIP=9)
        let sie_mask: u64 = (1 << 1) | (1 << 5) | (1 << 9);
        let sie = mie & sie_mask;

        // Mask delegated interrupts out of machine set, and into supervisor set.
        let m_pending = (mip & mie) & !mideleg;
        let s_pending = (mip & sie) & mideleg;

        // Machine mode global enable:
        // Enabled if (currently in Machine and MIE==1) OR (currently below Machine).
        let m_enabled = match self.mode {
            Mode::Machine => ((mstatus >> 3) & 1) == 1, // MIE
            _ => true,
        };
        if m_enabled {
            if (m_pending & (1 << 11)) != 0 { return Some(Trap::MachineExternalInterrupt); } // MEIP
            if (m_pending & (1 << 3)) != 0 { return Some(Trap::MachineSoftwareInterrupt); }   // MSIP
            if (m_pending & (1 << 7)) != 0 { return Some(Trap::MachineTimerInterrupt); }      // MTIP
        }

        // Supervisor mode global enable:
        // Enabled if (currently in Supervisor and SIE==1) OR (currently in User).
        let s_enabled = match self.mode {
            Mode::Machine => false,
            Mode::Supervisor => ((mstatus >> 1) & 1) == 1, // SIE
            Mode::User => true,
        };
        
        // DEBUG: Check if we are about to trap for interrupt when we shouldn't
        if s_enabled && s_pending != 0 {
             if log::log_enabled!(log::Level::Trace) {
                 log::trace!("Interrupt pending: s_pending={:x} mstatus={:x} mode={:?}", s_pending, mstatus, self.mode);
             }
        }

        if s_enabled {
            if (s_pending & (1 << 9)) != 0 { return Some(Trap::SupervisorExternalInterrupt); } // SEIP
            if (s_pending & (1 << 1)) != 0 { return Some(Trap::SupervisorSoftwareInterrupt); } // SSIP
            if (s_pending & (1 << 5)) != 0 { return Some(Trap::SupervisorTimerInterrupt); }    // STIP
        }

        None
    }

    pub fn step(&mut self, bus: &mut dyn Bus) -> Result<(), Trap> {
        // Poll device-driven interrupts into MIP mask.
        let mut hw_mip = bus.poll_interrupts();

        // Sstc support: raise STIP (bit 5) when time >= stimecmp and Sstc enabled.
        // menvcfg[63] gate is optional; xv6 enables it.
        let menvcfg = self.csrs[CSR_MENVCFG as usize];
        let sstc_enabled = ((menvcfg >> 63) & 1) == 1;
        let stimecmp = self.csrs[CSR_STIMECMP as usize];
        if sstc_enabled && stimecmp != 0 {
            // Read CLINT MTIME directly (physical address).
            if let Ok(now) = bus.read64(CLINT_BASE + MTIME_OFFSET) {
                if now >= stimecmp {
                    hw_mip |= 1 << 5; // STIP
                }
            }
        }

        // Update MIP: preserve software-writable bits (SSIP=bit1, STIP=bit5 if not Sstc),
        // but always update hardware-driven bits (MSIP=3, MTIP=7, SEIP=9, MEIP=11).
        // SSIP (bit 1) is software-writable and should be preserved.
        // STIP (bit 5) is normally read-only but Sstc makes it hardware-driven.
        let hw_bits: u64 = (1 << 3) | (1 << 7) | (1 << 9) | (1 << 11); // MSIP, MTIP, SEIP, MEIP
        let hw_bits_with_stip: u64 = hw_bits | (1 << 5); // Include STIP when Sstc enabled
        
        let mask = if sstc_enabled { hw_bits_with_stip } else { hw_bits };
        let old_mip = self.csrs[CSR_MIP as usize];
        self.csrs[CSR_MIP as usize] = (old_mip & !mask) | (hw_mip & mask);
        
        if let Some(trap) = self.check_pending_interrupt() {
            return self.handle_trap(trap, self.pc, None);
        }

        let pc = self.pc;
        // Fetch (supports compressed 16-bit and regular 32-bit instructions)
        let (insn_raw, insn_len) = self.fetch_and_expand(bus)?;
        // Decode
        let op = match decoder::decode(insn_raw) {
            Ok(v) => v,
            Err(trap) => return self.handle_trap(trap, pc, Some(insn_raw)),
        };

        let mut next_pc = pc.wrapping_add(insn_len as u64);

        match op {
            Op::Lui { rd, imm } => {
                self.write_reg(rd, imm as u64);
            }
            Op::Auipc { rd, imm } => {
                self.write_reg(rd, pc.wrapping_add(imm as u64));
            }
            Op::Jal { rd, imm } => {
                self.write_reg(rd, pc.wrapping_add(insn_len as u64));
                next_pc = pc.wrapping_add(imm as u64);
                if next_pc % 2 != 0 {
                    return self.handle_trap(
                        Trap::InstructionAddressMisaligned(next_pc),
                        pc,
                        Some(insn_raw),
                    );
                }
            }
            Op::Jalr { rd, rs1, imm } => {
                let target = self.read_reg(rs1).wrapping_add(imm as u64) & !1;
                self.write_reg(rd, pc.wrapping_add(insn_len as u64));
                next_pc = target;
                if next_pc % 2 != 0 {
                    return self.handle_trap(
                        Trap::InstructionAddressMisaligned(next_pc),
                        pc,
                        Some(insn_raw),
                    );
                }
            }
            Op::Branch {
                rs1,
                rs2,
                imm,
                funct3,
            } => {
                let val1 = self.read_reg(rs1);
                let val2 = self.read_reg(rs2);
                let taken = match funct3 {
                    0 => val1 == val2,                   // BEQ
                    1 => val1 != val2,                   // BNE
                    4 => (val1 as i64) < (val2 as i64),  // BLT
                    5 => (val1 as i64) >= (val2 as i64), // BGE
                    6 => val1 < val2,                    // BLTU
                    7 => val1 >= val2,                   // BGEU
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                if taken {
                    next_pc = pc.wrapping_add(imm as u64);
                    if next_pc % 2 != 0 {
                        return self.handle_trap(
                            Trap::InstructionAddressMisaligned(next_pc),
                            pc,
                            Some(insn_raw),
                        );
                    }
                }
            }
            Op::Load {
                rd,
                rs1,
                imm,
                funct3,
            } => {
                let addr = self.read_reg(rs1).wrapping_add(imm as u64);
                let val = match funct3 {
                    0 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read8(pa) {
                        Ok(v) => (v as i8) as i64 as u64, // LB
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    1 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read16(pa) {
                        Ok(v) => (v as i16) as i64 as u64, // LH
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    2 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read32(pa) {
                        Ok(v) => (v as i32) as i64 as u64, // LW
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    3 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read64(pa) {
                        Ok(v) => v, // LD
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    4 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read8(pa) {
                        Ok(v) => v as u64, // LBU
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    5 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read16(pa) {
                        Ok(v) => v as u64, // LHU
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    6 => {
                        let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;
                        match bus.read32(pa) {
                        Ok(v) => v as u64, // LWU
                        Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                    }}
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                self.write_reg(rd, val);
            }
            Op::Store {
                rs1,
                rs2,
                imm,
                funct3,
            } => {
                let addr = self.read_reg(rs1).wrapping_add(imm as u64);
                let pa = self.translate_addr(bus, addr, MmuAccessType::Store, pc, Some(insn_raw))?;
                // Any store to the reservation granule clears LR/SC reservation.
                self.clear_reservation_if_conflict(addr);
                let val = self.read_reg(rs2);
                let res = match funct3 {
                    0 => bus.write8(pa, val as u8),   // SB
                    1 => bus.write16(pa, val as u16), // SH
                    2 => bus.write32(pa, val as u32), // SW
                    3 => bus.write64(pa, val),        // SD
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                if let Err(e) = res {
                    return self.handle_trap(e, pc, Some(insn_raw));
                }
            }
            Op::OpImm {
                rd,
                rs1,
                imm,
                funct3,
                funct7,
            } => {
                let val1 = self.read_reg(rs1);
                let res = match funct3 {
                    0 => val1.wrapping_add(imm as u64), // ADDI
                    2 => {
                        if (val1 as i64) < imm {
                            1
                        } else {
                            0
                        }
                    } // SLTI
                    3 => {
                        if val1 < (imm as u64) {
                            1
                        } else {
                            0
                        }
                    } // SLTIU
                    4 => val1 ^ (imm as u64),           // XORI
                    6 => val1 | (imm as u64),           // ORI
                    7 => val1 & (imm as u64),           // ANDI
                    1 => {
                        // SLLI
                        let shamt = imm & 0x3F;
                        val1 << shamt
                    }
                    5 => {
                        // SRLI / SRAI
                        let shamt = imm & 0x3F;
                        if funct7 & 0x20 != 0 {
                            // SRAI
                            ((val1 as i64) >> shamt) as u64
                        } else {
                            // SRLI
                            val1 >> shamt
                        }
                    }
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                self.write_reg(rd, res);
            }
            Op::Op {
                rd,
                rs1,
                rs2,
                funct3,
                funct7,
            } => {
                let val1 = self.read_reg(rs1);
                let val2 = self.read_reg(rs2);
                let res = match (funct3, funct7) {
                    (0, 0x00) => val1.wrapping_add(val2), // ADD
                    (0, 0x20) => val1.wrapping_sub(val2), // SUB
                    // M-extension (RV64M) - MUL/DIV/REM on XLEN=64
                    (0, 0x01) => {
                        // MUL: low 64 bits of signed(rs1) * signed(rs2)
                        let a = val1 as i64 as i128;
                        let b = val2 as i64 as i128;
                        (a.wrapping_mul(b) as i64) as u64
                    }
                    (1, 0x00) => val1 << (val2 & 0x3F), // SLL
                    (1, 0x01) => {
                        // MULH: high 64 bits of signed * signed
                        let a = val1 as i64 as i128;
                        let b = val2 as i64 as i128;
                        ((a.wrapping_mul(b) >> 64) as i64) as u64
                    }
                    (2, 0x00) => {
                        if (val1 as i64) < (val2 as i64) {
                            1
                        } else {
                            0
                        }
                    } // SLT
                    (2, 0x01) => {
                        // MULHSU: high 64 bits of signed * unsigned
                        let a = val1 as i64 as i128;
                        let b = val2 as u64 as i128;
                        ((a.wrapping_mul(b) >> 64) as i64) as u64
                    }
                    (3, 0x00) => {
                        if val1 < val2 {
                            1
                        } else {
                            0
                        }
                    } // SLTU
                    (3, 0x01) => {
                        // MULHU: high 64 bits of unsigned * unsigned
                        let a = val1 as u128;
                        let b = val2 as u128;
                        ((a.wrapping_mul(b) >> 64) as u64) as u64
                    }
                    (4, 0x00) => val1 ^ val2, // XOR
                    (4, 0x01) => {
                        // DIV (signed)
                        let a = val1 as i64;
                        let b = val2 as i64;
                        let q = if b == 0 {
                            -1i64
                        } else if a == i64::MIN && b == -1 {
                            i64::MIN
                        } else {
                            a / b
                        };
                        q as u64
                    }
                    (5, 0x00) => val1 >> (val2 & 0x3F), // SRL
                    (5, 0x01) => {
                        // DIVU (unsigned)
                        let a = val1;
                        let b = val2;
                        let q = if b == 0 { u64::MAX } else { a / b };
                        q
                    }
                    (5, 0x20) => ((val1 as i64) >> (val2 & 0x3F)) as u64, // SRA
                    (6, 0x00) => val1 | val2,                              // OR
                    (6, 0x01) => {
                        // REM (signed)
                        let a = val1 as i64;
                        let b = val2 as i64;
                        let r = if b == 0 {
                            a
                        } else if a == i64::MIN && b == -1 {
                            0
                        } else {
                            a % b
                        };
                        r as u64
                    }
                    (7, 0x00) => val1 & val2, // AND
                    (7, 0x01) => {
                        // REMU (unsigned)
                        let a = val1;
                        let b = val2;
                        let r = if b == 0 { a } else { a % b };
                        r
                    }
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                self.write_reg(rd, res);
            }
            Op::OpImm32 {
                rd,
                rs1,
                imm,
                funct3,
                funct7,
            } => {
                let val1 = self.read_reg(rs1);
                let res = match funct3 {
                    0 => (val1.wrapping_add(imm as u64) as i32) as i64 as u64, // ADDIW
                    1 => ((val1 as u32) << (imm & 0x1F)) as i32 as i64 as u64, // SLLIW
                    5 => {
                        let shamt = imm & 0x1F;
                        if funct7 & 0x20 != 0 {
                            // SRAIW
                            ((val1 as i32) >> shamt) as i64 as u64
                        } else {
                            // SRLIW
                            ((val1 as u32) >> shamt) as i32 as i64 as u64
                        }
                    }
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                self.write_reg(rd, res);
            }
            Op::Op32 {
                rd,
                rs1,
                rs2,
                funct3,
                funct7,
            } => {
                let val1 = self.read_reg(rs1);
                let val2 = self.read_reg(rs2);
                let res = match (funct3, funct7) {
                    (0, 0x00) => (val1.wrapping_add(val2) as i32) as i64 as u64, // ADDW
                    (0, 0x20) => (val1.wrapping_sub(val2) as i32) as i64 as u64, // SUBW
                    (0, 0x01) => {
                        // MULW: low 32 bits of signed* signed, sign-extended to 64
                        let a = val1 as i32 as i64;
                        let b = val2 as i32 as i64;
                        let prod = (a as i128).wrapping_mul(b as i128);
                        (prod as i32) as i64 as u64
                    }
                    (1, 0x00) => ((val1 as u32) << (val2 & 0x1F)) as i32 as i64 as u64, // SLLW
                    (5, 0x00) => ((val1 as u32) >> (val2 & 0x1F)) as i32 as i64 as u64, // SRLW
                    (4, 0x01) => {
                        // DIVW (signed 32-bit)
                        let a = val1 as i32 as i64;
                        let b = val2 as i32 as i64;
                        let q = if b == 0 {
                            -1i64
                        } else if a == i64::from(i32::MIN) && b == -1 {
                            i64::from(i32::MIN)
                        } else {
                            a / b
                        };
                        (q as i32) as i64 as u64
                    }
                    (5, 0x20) => ((val1 as i32) >> (val2 & 0x1F)) as i64 as u64, // SRAW
                    (5, 0x01) => {
                        // DIVUW (unsigned 32-bit)
                        let a = val1 as u32 as u64;
                        let b = val2 as u32 as u64;
                        let q = if b == 0 { u64::MAX } else { a / b };
                        (q as u32) as i32 as i64 as u64
                    }
                    (6, 0x01) => {
                        // REMW (signed 32-bit)
                        let a = val1 as i32 as i64;
                        let b = val2 as i32 as i64;
                        let r = if b == 0 {
                            a
                        } else if a == i64::from(i32::MIN) && b == -1 {
                            0
                        } else {
                            a % b
                        };
                        (r as i32) as i64 as u64
                    }
                    (7, 0x01) => {
                        // REMUW (unsigned 32-bit)
                        let a = val1 as u32 as u64;
                        let b = val2 as u32 as u64;
                        let r = if b == 0 { a } else { a % b };
                        (r as u32) as i32 as i64 as u64
                    }
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };
                self.write_reg(rd, res);
            }
            Op::Amo {
                rd,
                rs1,
                rs2,
                funct3,
                funct5,
                ..
            } => {
                let addr = self.read_reg(rs1);

                // Translate once per AMO/LD/ST sequence.
                let pa = self.translate_addr(bus, addr, MmuAccessType::Load, pc, Some(insn_raw))?;

                // Only word (funct3=2) and doubleword (funct3=3) widths are valid.
                let is_word = match funct3 {
                    2 => true,
                    3 => false,
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        )
                    }
                };

                // LR/SC vs AMO op distinguished by funct5
                match funct5 {
                    0b00010 => {
                        // LR.W / LR.D
                        let loaded = if is_word {
                            match bus.read32(pa) {
                                Ok(v) => v as i32 as i64 as u64,
                                Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                            }
                        } else {
                            match bus.read64(pa) {
                                Ok(v) => v,
                                Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                            }
                        };
                        self.write_reg(rd, loaded);
                        self.reservation = Some(Self::reservation_granule(addr));
                    }
                    0b00011 => {
                        // SC.W / SC.D
                        // Alignment checks (must be naturally aligned) on the virtual address.
                        if is_word && addr % 4 != 0 {
                            return self.handle_trap(
                                Trap::StoreAddressMisaligned(addr),
                                pc,
                                Some(insn_raw),
                            );
                        }
                        if !is_word && addr % 8 != 0 {
                            return self.handle_trap(
                                Trap::StoreAddressMisaligned(addr),
                                pc,
                                Some(insn_raw),
                            );
                        }
                        let granule = Self::reservation_granule(addr);
                        if self.reservation == Some(granule) {
                            // Successful store
                            let val = self.read_reg(rs2);
                            let res = if is_word {
                                bus.write32(pa, val as u32)
                            } else {
                                bus.write64(pa, val)
                            };
                            if let Err(e) = res {
                                return self.handle_trap(e, pc, Some(insn_raw));
                            }
                            self.write_reg(rd, 0);
                            self.reservation = None;
                        } else {
                            // Failed store, no memory access
                            self.write_reg(rd, 1);
                        }
                    }
                    // AMO* operations
                    0b00001 | // AMOSWAP
                    0b00000 | // AMOADD
                    0b00100 | // AMOXOR
                    0b01000 | // AMOOR
                    0b01100 | // AMOAND
                    0b10000 | // AMOMIN
                    0b10100 | // AMOMAX
                    0b11000 | // AMOMINU
                    0b11100 // AMOMAXU
                    => {
                        // Any AMO acts like a store to the address, so clear reservation.
                        self.clear_reservation_if_conflict(addr);

                        let old = if is_word {
                            match bus.read32(pa) {
                                Ok(v) => v as i32 as i64 as u64,
                                Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                            }
                        } else {
                            match bus.read64(pa) {
                                Ok(v) => v,
                                Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                            }
                        };
                        let rs2_val = self.read_reg(rs2);

                        let new_val = match funct5 {
                            0b00001 => rs2_val,                        // AMOSWAP
                            0b00000 => old.wrapping_add(rs2_val),      // AMOADD
                            0b00100 => old ^ rs2_val,                  // AMOXOR
                            0b01000 => old | rs2_val,                  // AMOOR
                            0b01100 => old & rs2_val,                  // AMOAND
                            0b10000 => {
                                // AMOMIN (signed)
                                let a = old as i64;
                                let b = rs2_val as i64;
                                if a < b { old } else { rs2_val }
                            }
                            0b10100 => {
                                // AMOMAX (signed)
                                let a = old as i64;
                                let b = rs2_val as i64;
                                if a > b { old } else { rs2_val }
                            }
                            0b11000 => {
                                // AMOMINU (unsigned)
                                if old < rs2_val { old } else { rs2_val }
                            }
                            0b11100 => {
                                // AMOMAXU (unsigned)
                                if old > rs2_val { old } else { rs2_val }
                            }
                            _ => unreachable!(),
                        };

                        let res = if is_word {
                            bus.write32(pa, new_val as u32)
                        } else {
                            bus.write64(pa, new_val)
                        };
                        if let Err(e) = res {
                            return self.handle_trap(e, pc, Some(insn_raw));
                        }

                        // rd receives the original loaded value (sign-extended to XLEN)
                        self.write_reg(rd, old);
                    }
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        );
                    }
                }
            }
            Op::System {
                rd,
                rs1,
                funct3,
                imm,
                ..
            } => {
                match funct3 {
                    0 => {
                        // SYSTEM (ECALL/EBREAK, MRET/SRET, SFENCE.VMA)

                        // Detect SFENCE.VMA via mask/match (funct7=0001001, opcode=0x73, rd=0).
                        const SFENCE_VMA_MASK: u32 = 0b1111111_00000_00000_111_00000_1111111;
                        const SFENCE_VMA_MATCH: u32 = 0b0001001_00000_00000_000_00000_1110011; // 0x12000073

                        if (insn_raw & SFENCE_VMA_MASK) == SFENCE_VMA_MATCH {
                            // Only legal from S or M mode.
                            if matches!(self.mode, Mode::User) {
                                return self.handle_trap(
                                    Trap::IllegalInstruction(insn_raw as u64),
                                    pc,
                                    Some(insn_raw),
                                );
                            }
                            // Simplest implementation: flush entire TLB.
                            self.tlb.flush();
                        } else {
                            match insn_raw {
                                0x0010_0073 => {
                                    // EBREAK
                                    return self.handle_trap(Trap::Breakpoint, pc, Some(insn_raw));
                                }
                                0x1050_0073 => {
                                    // WFI - treat as a hint NOP
                                }
                                0x0000_0073 => {
                                    // ECALL - route based on current privilege mode
                                    let trap = match self.mode {
                                        Mode::User => Trap::EnvironmentCallFromU,
                                        Mode::Supervisor => Trap::EnvironmentCallFromS,
                                        Mode::Machine => Trap::EnvironmentCallFromM,
                                    };
                                    return self.handle_trap(trap, pc, Some(insn_raw));
                                }
                                0x3020_0073 => {
                                    // MRET
                                    if self.mode != Mode::Machine {
                                        return self.handle_trap(
                                            Trap::IllegalInstruction(insn_raw as u64),
                                            pc,
                                            Some(insn_raw),
                                        );
                                    }

                                    let mut mstatus = self.csrs[CSR_MSTATUS as usize];
                                    let mepc = self.csrs[CSR_MEPC as usize];

                                    // Extract MPP and MPIE
                                    let mpp_bits = (mstatus >> 11) & 0b11;
                                    let mpie = (mstatus >> 7) & 1;

                                    // Set new privilege mode from MPP
                                    self.mode = Mode::from_mpp(mpp_bits);

                                    // MIE <= MPIE, MPIE <= 1, MPP <= U (00)
                                    mstatus = (mstatus & !(1 << 3)) | (mpie << 3);
                                    mstatus |= 1 << 7; // MPIE = 1
                                    mstatus &= !(0b11 << 11); // MPP = U (00)

                                    self.csrs[CSR_MSTATUS as usize] = mstatus;
                                    next_pc = mepc;
                                }
                                0x1020_0073 => {
                                    // SRET (only valid from S-mode)
                                    if self.mode != Mode::Supervisor {
                                        return self.handle_trap(
                                            Trap::IllegalInstruction(insn_raw as u64),
                                            pc,
                                            Some(insn_raw),
                                        );
                                    }

                                    // We model only the SPP/SIE/SPIE subset of mstatus.
                                    let mut mstatus = self.csrs[CSR_MSTATUS as usize];
                                    let sepc = self.csrs[CSR_SEPC as usize];

                                    // SPP is bit 8, SPIE is bit 5, SIE is bit 1.
                                    let spp = (mstatus >> 8) & 1;
                                    let spie = (mstatus >> 5) & 1;

                                    self.mode = if spp == 0 {
                                        Mode::User
                                    } else {
                                        Mode::Supervisor
                                    };

                                    // SIE <= SPIE, SPIE <= 1, SPP <= U (0)
                                    mstatus = (mstatus & !(1 << 1)) | (spie << 1);
                                    mstatus |= 1 << 5; // SPIE = 1
                                    mstatus &= !(1 << 8); // SPP = U

                                    self.csrs[CSR_MSTATUS as usize] = mstatus;
                                    next_pc = sepc;
                                }
                                _ => {
                                    return self.handle_trap(
                                        Trap::IllegalInstruction(insn_raw as u64),
                                        pc,
                                        Some(insn_raw),
                                    );
                                }
                            }
                        }
                    }
                    // Zicsr: CSRRW/CSRRS/CSRRC
                    1 | 2 | 3 | 5 | 6 | 7 => {
                        let csr_addr = (imm & 0xFFF) as u16;
                        // Dynamic read for time CSR to reflect CLINT MTIME.
                        let old = if csr_addr == CSR_TIME {
                            bus.read64(CLINT_BASE + MTIME_OFFSET).unwrap_or(0)
                        } else {
                            match self.read_csr(csr_addr) {
                                Ok(v) => v,
                                Err(e) => return self.handle_trap(e, pc, Some(insn_raw)),
                            }
                        };

                        let mut write_new = None::<u64>;
                        match funct3 {
                            // CSRRW: write rs1, rd = old
                            1 => {
                                let rs1_val = self.read_reg(rs1);
                                write_new = Some(rs1_val);
                            }
                            // CSRRS: set bits in CSR with rs1
                            2 => {
                                let rs1_val = self.read_reg(rs1);
                                if rs1 != Register::X0 {
                                    write_new = Some(old | rs1_val);
                                }
                            }
                            // CSRRC: clear bits in CSR with rs1
                            3 => {
                                let rs1_val = self.read_reg(rs1);
                                if rs1 != Register::X0 {
                                    write_new = Some(old & !rs1_val);
                                }
                            }
                            // CSRRWI: write zero-extended zimm, rd = old
                            5 => {
                                let zimm = rs1.to_usize() as u64;
                                write_new = Some(zimm);
                            }
                            // CSRRSI: set bits using zimm (if non-zero)
                            6 => {
                                let zimm = rs1.to_usize() as u64;
                                if zimm != 0 {
                                    write_new = Some(old | zimm);
                                }
                            }
                            // CSRRCI: clear bits using zimm (if non-zero)
                            7 => {
                                let zimm = rs1.to_usize() as u64;
                                if zimm != 0 {
                                    write_new = Some(old & !zimm);
                                }
                            }
                            _ => {}
                        }

                        if let Some(new_val) = write_new {
                            if let Err(e) = self.write_csr(csr_addr, new_val) {
                                return self.handle_trap(e, pc, Some(insn_raw));
                            }
                        }

                        if rd != Register::X0 {
                            self.write_reg(rd, old);
                        }
                    }
                    _ => {
                        return self.handle_trap(
                            Trap::IllegalInstruction(insn_raw as u64),
                            pc,
                            Some(insn_raw),
                        );
                    }
                }
            }
            Op::Fence => {
                // NOP
            }
        }

        self.pc = next_pc;
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::bus::SystemBus;

    // --- Test helpers ----------------------------------------------------

    fn encode_i(imm: i32, rs1: u32, funct3: u32, rd: u32, opcode: u32) -> u32 {
        (((imm as u32) & 0xFFF) << 20) | (rs1 << 15) | (funct3 << 12) | (rd << 7) | opcode
    }

    fn encode_r(funct7: u32, rs2: u32, rs1: u32, funct3: u32, rd: u32, opcode: u32) -> u32 {
        (funct7 << 25) | (rs2 << 20) | (rs1 << 15) | (funct3 << 12) | (rd << 7) | opcode
    }

    fn encode_s(imm: i32, rs2: u32, rs1: u32, funct3: u32, opcode: u32) -> u32 {
        let imm = imm as u32;
        let imm11_5 = (imm >> 5) & 0x7F;
        let imm4_0 = imm & 0x1F;
        (imm11_5 << 25)
            | (rs2 << 20)
            | (rs1 << 15)
            | (funct3 << 12)
            | (imm4_0 << 7)
            | opcode
    }

    fn encode_b(imm: i32, rs2: u32, rs1: u32, funct3: u32, opcode: u32) -> u32 {
        // imm is a signed byte offset, must be multiple of 2
        let imm = imm as u32;
        let imm12 = (imm >> 12) & 0x1;
        let imm10_5 = (imm >> 5) & 0x3F;
        let imm4_1 = (imm >> 1) & 0xF;
        let imm11 = (imm >> 11) & 0x1;

        (imm12 << 31)
            | (imm10_5 << 25)
            | (rs2 << 20)
            | (rs1 << 15)
            | (funct3 << 12)
            | (imm4_1 << 8)
            | (imm11 << 7)
            | opcode
    }

    fn make_bus() -> SystemBus {
        SystemBus::new(0x8000_0000, 1024 * 1024) // 1MB
    }

    fn encode_amo(
        funct5: u32,
        aq: bool,
        rl: bool,
        rs2: u32,
        rs1: u32,
        funct3: u32,
        rd: u32,
    ) -> u32 {
        let funct7 = (funct5 << 2) | ((aq as u32) << 1) | (rl as u32);
        encode_r(funct7, rs2, rs1, funct3, rd, 0x2F)
    }

    #[test]
    fn test_addi() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // ADDI x1, x0, -1
        let insn = encode_i(-1, 0, 0, 1, 0x13);
        bus.write32(0x8000_0000, insn).unwrap();

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X1), 0xFFFF_FFFF_FFFF_FFFF);
        assert_eq!(cpu.pc, 0x8000_0004);
    }

    #[test]
    fn test_lui() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // LUI x2, 0x12345
        // imm field is already << 12 in the encoding helper
        let imm = 0x12345 << 12;
        let insn = ((imm as u32) & 0xFFFFF000) | (2 << 7) | 0x37;
        bus.write32(0x8000_0000, insn).unwrap();

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X2), 0x0000_0000_1234_5000);
    }

    #[test]
    fn test_load_store() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // SD x1, 0(x2) -> Store x1 at x2+0
        // x1 = 0xDEADBEEF, x2 = 0x8000_0100
        cpu.write_reg(Register::X1, 0xDEADBEEF);
        cpu.write_reg(Register::X2, 0x8000_0100);

        // SD: Op=0x23, funct3=3, rs1=2, rs2=1, imm=0
        // Using manual encoding here: imm=0 so only rs2/rs1/funct3/opcode matter.
        let sd_insn = (1 << 20) | (2 << 15) | (3 << 12) | 0x23;
        bus.write32(0x8000_0000, sd_insn).unwrap();

        cpu.step(&mut bus).unwrap();
        assert_eq!(bus.read64(0x8000_0100).unwrap(), 0xDEADBEEF);

        // LD x3, 0(x2) -> Load x3 from x2+0
        // LD: Op=0x03, funct3=3, rd=3, rs1=2, imm=0
        let ld_insn = (2 << 15) | (3 << 12) | (3 << 7) | 0x03;
        bus.write32(0x8000_0004, ld_insn).unwrap();

        cpu.step(&mut bus).unwrap(); // Execute SD (pc was incremented in previous step? No wait)
                                     // Previous step PC went 0->4. Now at 4.

        assert_eq!(cpu.read_reg(Register::X3), 0xDEADBEEF);
    }

    #[test]
    fn test_x0_invariant() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // Place a value in memory
        let addr = 0x8000_0100;
        bus.write64(addr, 0xDEAD_BEEF_DEAD_BEEF).unwrap();

        // Set x2 = addr
        cpu.write_reg(Register::X2, addr);

        // 1) ADDI x0, x0, 5
        let addi_x0 = encode_i(5, 0, 0, 0, 0x13);
        // 2) LD x0, 0(x2)
        let ld_x0 = encode_i(0, 2, 3, 0, 0x03);

        bus.write32(0x8000_0000, addi_x0).unwrap();
        bus.write32(0x8000_0004, ld_x0).unwrap();

        cpu.step(&mut bus).unwrap();
        cpu.step(&mut bus).unwrap();

        // x0 must remain hard-wired to zero
        assert_eq!(cpu.read_reg(Register::X0), 0);
    }

    #[test]
    fn test_branch_taken_and_not_taken() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // BEQ x1, x2, +8 (pc + 8 when taken)
        let beq_insn = encode_b(8, 2, 1, 0x0, 0x63);
        bus.write32(0x8000_0000, beq_insn).unwrap();

        // Taken: x1 == x2
        cpu.write_reg(Register::X1, 5);
        cpu.write_reg(Register::X2, 5);
        cpu.pc = 0x8000_0000;
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.pc, 0x8000_0008);

        // Not taken: x1 != x2
        cpu.write_reg(Register::X1, 1);
        cpu.write_reg(Register::X2, 2);
        cpu.pc = 0x8000_0000;
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.pc, 0x8000_0004);
    }

    #[test]
    fn test_w_ops_sign_extension() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // Set x1 = 0x0000_0000_8000_0000 (low 32 bits have sign bit set)
        cpu.write_reg(Register::X1, 0x0000_0000_8000_0000);
        cpu.write_reg(Register::X2, 0); // x2 = 0

        // ADDW x3, x1, x2  (opcode=0x3B, funct3=0, funct7=0)
        let addw = encode_r(0x00, 2, 1, 0x0, 3, 0x3B);
        bus.write32(0x8000_0000, addw).unwrap();

        cpu.step(&mut bus).unwrap();

        // Expect sign-extended 32-bit result: 0xFFFF_FFFF_8000_0000
        assert_eq!(cpu.read_reg(Register::X3), 0xFFFF_FFFF_8000_0000);
    }

    #[test]
    fn test_m_extension_mul_div_rem() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // MUL: 3 * 4 = 12
        cpu.write_reg(Register::X1, 3);
        cpu.write_reg(Register::X2, 4);
        let mul = encode_r(0x01, 2, 1, 0x0, 3, 0x33); // MUL x3, x1, x2
        bus.write32(0x8000_0000, mul).unwrap();
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X3), 12);

        // MULH / MULHSU / MULHU basic sanity using large values
        cpu.pc = 0x8000_0004;
        cpu.write_reg(Register::X1, 0x8000_0000_0000_0000);
        cpu.write_reg(Register::X2, 2);
        let mulh = encode_r(0x01, 2, 1, 0x1, 4, 0x33); // MULH x4, x1, x2
        let mulhsu = encode_r(0x01, 2, 1, 0x2, 5, 0x33); // MULHSU x5, x1, x2
        let mulhu = encode_r(0x01, 2, 1, 0x3, 6, 0x33); // MULHU x6, x1, x2
        bus.write32(0x8000_0004, mulh).unwrap();
        bus.write32(0x8000_0008, mulhsu).unwrap();
        bus.write32(0x8000_000C, mulhu).unwrap();
        cpu.step(&mut bus).unwrap();
        cpu.step(&mut bus).unwrap();
        cpu.step(&mut bus).unwrap();

        // From spec example: low product is 0, high signed part negative
        assert_eq!(cpu.read_reg(Register::X3), 12);
        assert_ne!(cpu.read_reg(Register::X4), 0);
        assert_ne!(cpu.read_reg(Register::X5), 0);
        assert_ne!(cpu.read_reg(Register::X6), 0);

        // DIV / DIVU / REM / REMU corner cases
        cpu.pc = 0x8000_0010;
        cpu.write_reg(Register::X1, u64::MAX); // -1 as signed
        cpu.write_reg(Register::X2, 0);
        let div = encode_r(0x01, 2, 1, 0x4, 7, 0x33); // DIV x7, x1, x2
        let divu = encode_r(0x01, 2, 1, 0x5, 8, 0x33); // DIVU x8, x1, x2
        let rem = encode_r(0x01, 2, 1, 0x6, 9, 0x33); // REM x9, x1, x2
        let remu = encode_r(0x01, 2, 1, 0x7, 10, 0x33); // REMU x10, x1, x2
        bus.write32(0x8000_0010, div).unwrap();
        bus.write32(0x8000_0014, divu).unwrap();
        bus.write32(0x8000_0018, rem).unwrap();
        bus.write32(0x8000_001C, remu).unwrap();

        for _ in 0..4 {
            cpu.step(&mut bus).unwrap();
        }

        assert_eq!(cpu.read_reg(Register::X7), u64::MAX); // DIV by 0 -> -1
        assert_eq!(cpu.read_reg(Register::X8), u64::MAX); // DIVU by 0 -> all ones
        assert_eq!(cpu.read_reg(Register::X9), u64::MAX); // REM by 0 -> rs1
        assert_eq!(cpu.read_reg(Register::X10), u64::MAX); // REMU by 0 -> rs1

        // Overflow case: -(2^63) / -1 -> -(2^63), rem = 0
        cpu.pc = 0x8000_0020;
        cpu.write_reg(Register::X1, i64::MIN as u64);
        cpu.write_reg(Register::X2, (!0u64) as u64); // -1
        let div_over = encode_r(0x01, 2, 1, 0x4, 11, 0x33); // DIV x11, x1, x2
        let rem_over = encode_r(0x01, 2, 1, 0x6, 12, 0x33); // REM x12, x1, x2
        bus.write32(0x8000_0020, div_over).unwrap();
        bus.write32(0x8000_0024, rem_over).unwrap();
        cpu.step(&mut bus).unwrap();
        cpu.step(&mut bus).unwrap();

        assert_eq!(cpu.read_reg(Register::X11), i64::MIN as u64);
        assert_eq!(cpu.read_reg(Register::X12), 0);
    }

    #[test]
    fn test_compressed_addi_and_lwsp_paths() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // Encodings from assembler with rv64imac (see rvc_test.S in dev notes):
        let c_addi_x11_1: u16 = 0x0585; // addi x11,x11,1 (C.ADDI)
        let c_addi16sp_16: u16 = 0x0141; // addi sp,sp,16 (C.ADDI16SP)
        let c_lwsp_a5_12: u16 = 0x47B2; // lw a5,12(sp) (C.LWSP)

        // Initialize registers / memory
        cpu.write_reg(Register::X11, 10);
        let sp_base = 0x8000_0100;
        cpu.write_reg(Register::X2, sp_base); // sp
        // After C.ADDI16SP 16, sp = sp_base + 16. C.LWSP uses offset 12 from new sp.
        bus.write32(sp_base + 16 + 12, 0xDEAD_BEEF).unwrap();

        // Place compressed instructions at 0,2,4
        bus.write16(0x8000_0000, c_addi_x11_1).unwrap();
        bus.write16(0x8000_0002, c_addi16sp_16).unwrap();
        bus.write16(0x8000_0004, c_lwsp_a5_12).unwrap();

        // Execute three steps; PC should advance by 2 for each compressed inst.
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.pc, 0x8000_0002);
        assert_eq!(cpu.read_reg(Register::X11), 11);

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.pc, 0x8000_0004);
        assert_eq!(cpu.read_reg(Register::X2), 0x8000_0110); // sp + 16

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.pc, 0x8000_0006);
        assert_eq!(cpu.read_reg(Register::X15), 0xFFFF_FFFF_DEAD_BEEF); // a5 (sign-extended lw)
    }

    #[test]
    fn test_zicsr_basic_csrs() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);
        let csr_addr: u32 = 0x300; // mstatus

        // CSRRWI x1, mstatus, 5  (mstatus = 5, x1 = old = 0)
        let csrrwi = {
            let zimm = 5u32;
            (csr_addr << 20) | (zimm << 15) | (0x5 << 12) | (1 << 7) | 0x73
        };
        bus.write32(0x8000_0000, csrrwi).unwrap();
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X1), 0);

        // CSRRSI x2, mstatus, 0xA  (mstatus = 5 | 0xA = 0xF, x2 = old = 5)
        let csrrsi = {
            let zimm = 0xAu32;
            (csr_addr << 20) | (zimm << 15) | (0x6 << 12) | (2 << 7) | 0x73
        };
        bus.write32(0x8000_0004, csrrsi).unwrap();
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X2), 5);

        // CSRRCI x3, mstatus, 0x3  (mstatus = 0xF & !0x3 = 0xC, x3 = old = 0xF)
        let csrrci = {
            let zimm = 0x3u32;
            (csr_addr << 20) | (zimm << 15) | (0x7 << 12) | (3 << 7) | 0x73
        };
        bus.write32(0x8000_0008, csrrci).unwrap();
        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X3), 0xF);
    }

    #[test]
    fn test_a_extension_lr_sc_basic() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        let addr = 0x8000_0200;
        bus.write64(addr, 0xDEAD_BEEF_DEAD_BEEF).unwrap();

        cpu.write_reg(Register::X1, addr); // base
        cpu.write_reg(Register::X2, 0x0123_4567_89AB_CDEF); // value to store with SC

        // LR.D x3, 0(x1)
        let lr_d = encode_amo(0b00010, false, false, 0, 1, 0x3, 3);
        // SC.D x4, x2, 0(x1)
        let sc_d = encode_amo(0b00011, false, false, 2, 1, 0x3, 4);

        bus.write32(0x8000_0000, lr_d).unwrap();
        bus.write32(0x8000_0004, sc_d).unwrap();

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X3), 0xDEAD_BEEF_DEAD_BEEF);

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X4), 0); // SC success
        assert_eq!(bus.read64(addr).unwrap(), 0x0123_4567_89AB_CDEF);
    }

    #[test]
    fn test_a_extension_reservation_and_misaligned_sc() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        let addr = 0x8000_0300;
        bus.write64(addr, 0xCAFEBABE_F00D_F00D).unwrap();

        cpu.write_reg(Register::X1, addr); // base
        cpu.write_reg(Register::X2, 1); // increment

        // LR.D to establish reservation
        let lr_d = encode_amo(0b00010, false, false, 0, 1, 0x3, 3);
        // AMOADD.D x4, x2, 0(x1) -> increments and clears reservation
        let amoadd_d = encode_amo(0b00000, false, false, 2, 1, 0x3, 4);
        // SC.D x5, x2, 0(x1) -> should fail (x5=1) because reservation cleared
        let sc_d = encode_amo(0b00011, false, false, 2, 1, 0x3, 5);

        bus.write32(0x8000_0000, lr_d).unwrap();
        bus.write32(0x8000_0004, amoadd_d).unwrap();
        bus.write32(0x8000_0008, sc_d).unwrap();

        cpu.step(&mut bus).unwrap(); // LR
        cpu.step(&mut bus).unwrap(); // AMOADD
        cpu.step(&mut bus).unwrap(); // SC (should fail)

        assert_eq!(cpu.read_reg(Register::X5), 1);

        // Misaligned SC.D must trap with StoreAddressMisaligned
        cpu.pc = 0x8000_0010;
        cpu.write_reg(Register::X1, addr + 1); // misaligned
        let sc_misaligned = encode_amo(0b00011, false, false, 2, 1, 0x3, 6);
        bus.write32(0x8000_0010, sc_misaligned).unwrap();

        let res = cpu.step(&mut bus);
        match res {
            Err(Trap::StoreAddressMisaligned(a)) => assert_eq!(a, addr + 1),
            _ => panic!("Expected StoreAddressMisaligned trap"),
        }
    }

    #[test]
    fn test_load_sign_and_zero_extension() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        let addr = 0x8000_0100;
        // 0xFFEE_DDCC_BBAA_9988 laid out little-endian in memory
        bus.write64(addr, 0xFFEE_DDCC_BBAA_9988).unwrap();

        cpu.write_reg(Register::X1, addr); // base pointer

        // LB x2, 0(x1)
        let lb = encode_i(0, 1, 0, 2, 0x03);
        // LBU x3, 0(x1)
        let lbu = encode_i(0, 1, 4, 3, 0x03);
        // LH x4, 0(x1)
        let lh = encode_i(0, 1, 1, 4, 0x03);
        // LHU x5, 0(x1)
        let lhu = encode_i(0, 1, 5, 5, 0x03);
        // LW x6, 0(x1)
        let lw = encode_i(0, 1, 2, 6, 0x03);
        // LWU x7, 0(x1)
        let lwu = encode_i(0, 1, 6, 7, 0x03);
        // LD x8, 0(x1)
        let ld = encode_i(0, 1, 3, 8, 0x03);

        let base_pc = 0x8000_0000;
        for (i, insn) in [lb, lbu, lh, lhu, lw, lwu, ld].into_iter().enumerate() {
            bus.write32(base_pc + (i as u64) * 4, insn).unwrap();
        }

        // Execute all loads
        for _ in 0..7 {
            cpu.step(&mut bus).unwrap();
        }

        assert_eq!(cpu.read_reg(Register::X2), 0xFFFF_FFFF_FFFF_FF88); // LB (sign-extended 0x88)
        assert_eq!(cpu.read_reg(Register::X3), 0x88); // LBU
        assert_eq!(cpu.read_reg(Register::X4), 0xFFFF_FFFF_FFFF_9988); // LH
        assert_eq!(cpu.read_reg(Register::X5), 0x9988); // LHU
        assert_eq!(cpu.read_reg(Register::X6), 0xFFFF_FFFF_BBAA_9988); // LW
        assert_eq!(cpu.read_reg(Register::X7), 0xBBAA_9988); // LWU
        assert_eq!(cpu.read_reg(Register::X8), 0xFFEE_DDCC_BBAA_9988); // LD
    }

    #[test]
    fn test_misaligned_load_and_store_traps() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // x2 = misaligned address
        cpu.write_reg(Register::X2, 0x8000_0001);

        // LW x1, 0(x2)  -> should trap with LoadAddressMisaligned
        let lw = encode_i(0, 2, 2, 1, 0x03);
        bus.write32(0x8000_0000, lw).unwrap();

        let res = cpu.step(&mut bus);
        match res {
            Err(Trap::LoadAddressMisaligned(a)) => assert_eq!(a, 0x8000_0001),
            _ => panic!("Expected LoadAddressMisaligned trap"),
        }

        // SW x1, 0(x2)  -> should trap with StoreAddressMisaligned
        cpu.pc = 0x8000_0000;
        let sw = encode_s(0, 1, 2, 2, 0x23);
        bus.write32(0x8000_0000, sw).unwrap();

        let res = cpu.step(&mut bus);
        match res {
            Err(Trap::StoreAddressMisaligned(a)) => assert_eq!(a, 0x8000_0001),
            _ => panic!("Expected StoreAddressMisaligned trap"),
        }
    }

    #[test]
    fn test_access_fault_outside_dram() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // LW x1, 0(x0) -> effective address 0x0 (outside DRAM, but aligned)
        let lw = encode_i(0, 0, 2, 1, 0x03);
        bus.write32(0x8000_0000, lw).unwrap();

        let res = cpu.step(&mut bus);
        match res {
            Err(Trap::LoadAccessFault(a)) => assert_eq!(a, 0),
            _ => panic!("Expected LoadAccessFault trap"),
        }
    }

    #[test]
    fn test_jal() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // JAL x1, 8
        // Op=0x6F, rd=1, imm=8.
        // J-type: imm[20|10:1|11|19:12]
        // imm=8 (0x8). bit3=1.
        // imm[10:1] = 0100... no wait.
        // 8 = 1000 binary.
        // bit1..10 -> bits 1..4 are 0010 ? No.
        // 8 >> 1 = 4.
        // imm[10:1] = 4.
        // insn: imm[20] | imm[10:1] | imm[11] | imm[19:12] | rd | opcode
        // 0 | 4 | 0 | 0 | 1 | 0x6F
        // (4 << 21) | (1 << 7) | 0x6F
        let jal_insn = (4 << 21) | (1 << 7) | 0x6F;
        bus.write32(0x8000_0000, jal_insn).unwrap();

        cpu.step(&mut bus).unwrap();
        assert_eq!(cpu.read_reg(Register::X1), 0x8000_0004); // Link address
        assert_eq!(cpu.pc, 0x8000_0008); // Target
    }

    #[test]
    fn test_misaligned_fetch() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0001); // Odd PC

        let res = cpu.step(&mut bus);
        match res {
            Err(Trap::InstructionAddressMisaligned(addr)) => assert_eq!(addr, 0x8000_0001),
            _ => panic!("Expected misaligned trap"),
        }
    }

    #[test]
    fn test_smoke_sum() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // Data at 0x8000_0100
        let data: [u32; 5] = [1, 2, 3, 4, 5];
        for (i, val) in data.iter().enumerate() {
            bus.write32(0x8000_0100 + (i * 4) as u64, *val).unwrap();
        }

        // Program
        // Need to construct 0x80000100 without sign extension issues.
        // 1. ADDI x1, x0, 1
        // 2. SLLI x1, x1, 31 -> 0x80000000
        // 3. ADDI x1, x1, 0x100 -> 0x80000100
        let prog = [
            0x00100093, // addi x1, x0, 1
            0x01F09093, // slli x1, x1, 31
            0x10008093, // addi x1, x1, 0x100 -> Base
            0x00500113, // addi x2, x0, 5 -> Count
            0x00000193, // addi x3, x0, 0 -> Sum
            // loop:
            0x0000A203, // lw x4, 0(x1)
            0x004181B3, // add x3, x3, x4
            0x00408093, // addi x1, x1, 4
            0xFFF10113, // addi x2, x2, -1
            0xFE0118E3, // bne x2, x0, loop (-16)
            0x00100073, // ebreak
        ];

        for (i, val) in prog.iter().enumerate() {
            bus.write32(0x8000_0000 + (i * 4) as u64, *val).unwrap();
        }

        // Run until ebreak
        let mut steps = 0;
        loop {
            steps += 1;
            if steps > 1000 {
                panic!("Infinite loop");
            }
            match cpu.step(&mut bus) {
                Ok(_) => {}
                Err(Trap::Breakpoint) => break,
                Err(e) => panic!("Unexpected trap at pc 0x{:x}: {:?}", cpu.pc, e),
            }
        }

        // Check sum
        assert_eq!(cpu.read_reg(Register::X3), 15);
    }

    #[test]
    fn test_interrupts_clint_plic() {
        let mut bus = make_bus();
        let mut cpu = Cpu::new(0x8000_0000);

        // 1. Setup MTVEC to 0x8000_1000 (Direct)
        let mtvec_val = 0x8000_1000;
        cpu.write_csr(CSR_MTVEC, mtvec_val).unwrap();

        // 2. Enable MIE in mstatus (Global Interrupt Enable)
        // mstatus bit 3 is MIE.
        let mstatus_val = 1 << 3; 
        cpu.write_csr(CSR_MSTATUS, mstatus_val).unwrap();

        // 3. Enable MTIE (Timer) and MEIE (External) and MSIE (Software) in mie
        // MTIE=7, MEIE=11, MSIE=3
        let mie_val = (1 << 7) | (1 << 11) | (1 << 3);
        cpu.write_csr(CSR_MIE, mie_val).unwrap();

        // --- Test CLINT Timer Interrupt ---
        // Set mtimecmp[0] to 100
        bus.clint.mtimecmp[0] = 100;
        // Set mtime to 101 (trigger condition)
        bus.clint.set_mtime(101);

        // We need a valid instruction at PC to attempt fetch, although interrupt checks before fetch.
        bus.write32(0x8000_0000, 0x00000013).unwrap(); // NOP (addi x0, x0, 0)

        let res = cpu.step(&mut bus);
        match res {
             Err(Trap::MachineTimerInterrupt) => {
                 // Success
                 assert_eq!(cpu.pc, 0x8000_1000); // jumped to mtvec
                 // Check mcause: Interrupt=1, Cause=7 -> 0x8000...0007
                 let mcause = cpu.read_csr(CSR_MCAUSE).unwrap();
                 assert_eq!(mcause, 0x8000_0000_0000_0007);
             }
             _ => panic!("Expected MachineTimerInterrupt, got {:?}", res),
        }

        // Clear the interrupt condition
        bus.clint.mtimecmp[0] = 200; 
        // CPU is now at handler. We need to "return" (mret) or just reset state for next test.
        // Reset PC back to start
        cpu.pc = 0x8000_0000;
        // Re-enable MIE (trap disabled it)
        let mut mstatus = cpu.read_csr(CSR_MSTATUS).unwrap();
        mstatus |= 1 << 3;
        cpu.write_csr(CSR_MSTATUS, mstatus).unwrap();

        // --- Test PLIC UART Interrupt ---
        // Configure PLIC
        // 1. Set Priority for Source 10 (UART) to 1
        bus.plic.store(0x000000 + 4 * 10, 4, 1).unwrap();
        // 2. Enable Source 10 for Context 0 (M-mode)
        // Enable addr for ctx 0: 0x002000. Bit 10.
        bus.plic.store(0x002000, 4, 1 << 10).unwrap();
        // 3. Set Threshold for Context 0 to 0
        bus.plic.store(0x200000, 4, 0).unwrap();

        // Trigger UART Interrupt
        // Writing to IER (Enable RDIE=1) and pushing a char to Input
        // UART RBR is at offset 0. IER is at offset 1.
        bus.uart.store(1, 1, 1).unwrap(); // IER = 1 (RX Data Available Interrupt)
        bus.uart.push_input(b'A'); 
        // This should set uart.lsr[0]=1, and because IER[0]=1, uart.interrupting=true.
        
        // Update bus interrupts so PLIC sees UART line high
        bus.check_interrupts();

        // Step CPU
        let res = cpu.step(&mut bus);
        match res {
            Err(Trap::MachineExternalInterrupt) => {
                // Success
                assert_eq!(cpu.pc, 0x8000_1000);
                 let mcause = cpu.read_csr(CSR_MCAUSE).unwrap();
                 assert_eq!(mcause, 0x8000_0000_0000_000B); // Cause 11
            }
            _ => panic!("Expected MachineExternalInterrupt, got {:?}", res),
        }
    }
}
</file>

<file path="riscv-vm/src/csr.rs">
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum Mode {
    User,
    Supervisor,
    Machine,
}

impl Mode {
    /// Encode privilege mode into the MPP/SPP field encoding.
    pub fn to_mpp(self) -> u64 {
        match self {
            Mode::User => 0b00,
            Mode::Supervisor => 0b01,
            Mode::Machine => 0b11,
        }
    }

    /// Decode MPP/SPP field into a privilege mode.
    pub fn from_mpp(bits: u64) -> Mode {
        match bits & 0b11 {
            0b00 => Mode::User,
            0b01 => Mode::Supervisor,
            // 0b10 is reserved; treat as Machine for WARL coercion.
            _ => Mode::Machine,
        }
    }
}

// Common CSR addresses used by the privileged architecture.
pub const CSR_SATP: u16 = 0x180;

pub const CSR_MSTATUS: u16 = 0x300;
pub const CSR_MISA: u16 = 0x301;
pub const CSR_MEDELEG: u16 = 0x302;
pub const CSR_MIDELEG: u16 = 0x303;
pub const CSR_MIE: u16 = 0x304;
pub const CSR_MTVEC: u16 = 0x305;

pub const CSR_MEPC: u16 = 0x341;
pub const CSR_MCAUSE: u16 = 0x342;
pub const CSR_MTVAL: u16 = 0x343;
pub const CSR_MIP: u16 = 0x344;

// Supervisor CSRs
pub const CSR_SSTATUS: u16 = 0x100;
pub const CSR_SIE: u16 = 0x104;
pub const CSR_STVEC: u16 = 0x105;
pub const CSR_SSCRATCH: u16 = 0x140;
pub const CSR_SEPC: u16 = 0x141;
pub const CSR_SCAUSE: u16 = 0x142;
pub const CSR_STVAL: u16 = 0x143;
pub const CSR_SIP: u16 = 0x144;

// Additional CSRs used by xv6 and Sstc
pub const CSR_TIME: u16 = 0xC01;      // time (read-only)
pub const CSR_MENVCFG: u16 = 0x30A;   // menvcfg (for Sstc enable bit 63)
pub const CSR_STIMECMP: u16 = 0x14D;  // stimecmp (Sstc)
pub const CSR_MCOUNTEREN: u16 = 0x306;

// Machine Information Registers (read-only)
pub const CSR_MVENDORID: u16 = 0xF11;  // Vendor ID
pub const CSR_MARCHID: u16 = 0xF12;    // Architecture ID
pub const CSR_MIMPID: u16 = 0xF13;     // Implementation ID
pub const CSR_MHARTID: u16 = 0xF14;    // Hardware thread ID
</file>

<file path="riscv-vm/src/decoder.rs">
use crate::Trap;

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum Register {
    X0,
    X1,
    X2,
    X3,
    X4,
    X5,
    X6,
    X7,
    X8,
    X9,
    X10,
    X11,
    X12,
    X13,
    X14,
    X15,
    X16,
    X17,
    X18,
    X19,
    X20,
    X21,
    X22,
    X23,
    X24,
    X25,
    X26,
    X27,
    X28,
    X29,
    X30,
    X31,
}

impl Register {
    pub fn from_u32(v: u32) -> Self {
        match v & 0x1F {
            0 => Register::X0,
            1 => Register::X1,
            2 => Register::X2,
            3 => Register::X3,
            4 => Register::X4,
            5 => Register::X5,
            6 => Register::X6,
            7 => Register::X7,
            8 => Register::X8,
            9 => Register::X9,
            10 => Register::X10,
            11 => Register::X11,
            12 => Register::X12,
            13 => Register::X13,
            14 => Register::X14,
            15 => Register::X15,
            16 => Register::X16,
            17 => Register::X17,
            18 => Register::X18,
            19 => Register::X19,
            20 => Register::X20,
            21 => Register::X21,
            22 => Register::X22,
            23 => Register::X23,
            24 => Register::X24,
            25 => Register::X25,
            26 => Register::X26,
            27 => Register::X27,
            28 => Register::X28,
            29 => Register::X29,
            30 => Register::X30,
            31 => Register::X31,
            _ => unreachable!(),
        }
    }

    pub fn to_usize(&self) -> usize {
        *self as usize
    }
}

#[derive(Debug, Clone, PartialEq)]
pub enum Op {
    Lui {
        rd: Register,
        imm: i64,
    },
    Auipc {
        rd: Register,
        imm: i64,
    },
    Jal {
        rd: Register,
        imm: i64,
    },
    Jalr {
        rd: Register,
        rs1: Register,
        imm: i64,
    },
    Branch {
        rs1: Register,
        rs2: Register,
        imm: i64,
        funct3: u32,
    },
    Load {
        rd: Register,
        rs1: Register,
        imm: i64,
        funct3: u32,
    },
    Store {
        rs1: Register,
        rs2: Register,
        imm: i64,
        funct3: u32,
    },
    OpImm {
        rd: Register,
        rs1: Register,
        imm: i64,
        funct3: u32,
        funct7: u32,
    }, // I-type ALU (ADDI etc)
    Op {
        rd: Register,
        rs1: Register,
        rs2: Register,
        funct3: u32,
        funct7: u32,
    }, // R-type ALU
    OpImm32 {
        rd: Register,
        rs1: Register,
        imm: i64,
        funct3: u32,
        funct7: u32,
    }, // ADDIW etc
    Op32 {
        rd: Register,
        rs1: Register,
        rs2: Register,
        funct3: u32,
        funct7: u32,
    }, // ADDW etc
    System {
        rd: Register,
        rs1: Register,
        funct3: u32,
        imm: u32,
    }, // CSRs / Ecall (imm used for csr addr usually)
    Amo {
        rd: Register,
        rs1: Register,
        rs2: Register,
        funct3: u32,
        funct5: u32,
        aq: bool,
        rl: bool,
    }, // RV64A atomics (LR/SC/AMO*)
    Fence, // FENCE / FENCE.I
}

pub fn decode(insn: u32) -> Result<Op, Trap> {
    let opcode = insn & 0x7F;
    let rd = Register::from_u32((insn >> 7) & 0x1F);
    let funct3 = (insn >> 12) & 0x7;
    let rs1 = Register::from_u32((insn >> 15) & 0x1F);
    let rs2 = Register::from_u32((insn >> 20) & 0x1F);
    let funct7 = (insn >> 25) & 0x7F;

    // Sign extension helpers
    let imm_i = ((insn as i32) >> 20) as i64;
    let imm_s = (((insn as i32) >> 25) << 5) as i64 | (((insn >> 7) & 0x1F) as i64);
    // B-type: imm[12|10:5|4:1|11]
    let imm_b = {
        let bit31 = (insn >> 31) & 1;
        let bit30_25 = (insn >> 25) & 0x3F;
        let bit11_8 = (insn >> 8) & 0xF;
        let bit7 = (insn >> 7) & 1;
        let val = (bit31 << 12) | (bit7 << 11) | (bit30_25 << 5) | (bit11_8 << 1);
        // Sign extend from bit 12
        ((val as i32) << 19 >> 19) as i64
    };
    // U-type: imm[31:12]
    let imm_u = ((insn as i32) & 0xFFFFF000u32 as i32) as i64;
    // J-type: imm[20|10:1|11|19:12]
    let imm_j = {
        let bit31 = (insn >> 31) & 1;
        let bit30_21 = (insn >> 21) & 0x3FF;
        let bit20 = (insn >> 20) & 1;
        let bit19_12 = (insn >> 12) & 0xFF;
        let val = (bit31 << 20) | (bit19_12 << 12) | (bit20 << 11) | (bit30_21 << 1);
        ((val as i32) << 11 >> 11) as i64
    };

    match opcode {
        0x37 => Ok(Op::Lui { rd, imm: imm_u }),
        0x17 => Ok(Op::Auipc { rd, imm: imm_u }),
        0x6F => Ok(Op::Jal { rd, imm: imm_j }),
        0x67 => Ok(Op::Jalr {
            rd,
            rs1,
            imm: imm_i,
        }),
        0x63 => Ok(Op::Branch {
            rs1,
            rs2,
            imm: imm_b,
            funct3,
        }),
        0x03 => Ok(Op::Load {
            rd,
            rs1,
            imm: imm_i,
            funct3,
        }),
        0x23 => Ok(Op::Store {
            rs1,
            rs2,
            imm: imm_s,
            funct3,
        }),
        0x13 => Ok(Op::OpImm {
            rd,
            rs1,
            imm: imm_i,
            funct3,
            funct7,
        }),
        0x33 => Ok(Op::Op {
            rd,
            rs1,
            rs2,
            funct3,
            funct7,
        }),
        0x1B => Ok(Op::OpImm32 {
            rd,
            rs1,
            imm: imm_i,
            funct3,
            funct7,
        }),
        0x3B => Ok(Op::Op32 {
            rd,
            rs1,
            rs2,
            funct3,
            funct7,
        }),
        0x2F => {
            // A-extension (atomics)
            let funct5 = (insn >> 27) & 0x1F;
            let aq = ((insn >> 26) & 1) != 0;
            let rl = ((insn >> 25) & 1) != 0;
            Ok(Op::Amo {
                rd,
                rs1,
                rs2,
                funct3,
                funct5,
                aq,
                rl,
            })
        }
        0x73 => {
            let i_imm = (insn >> 20) & 0xFFF;
            Ok(Op::System {
                rd,
                rs1,
                funct3,
                imm: i_imm,
            })
        }
        0x0F => Ok(Op::Fence),

        _ => Err(Trap::IllegalInstruction(insn as u64)),
    }
}

// -------- Compressed (C) extension expansion ---------------------------------
//
// These helpers expand 16-bit compressed instructions into canonical 32-bit
// encodings, which are then fed through the normal `decode()` function.

fn encode_i(imm: i32, rs1: u32, funct3: u32, rd: u32, opcode: u32) -> u32 {
    let imm12 = (imm as u32) & 0xFFF;
    (imm12 << 20) | (rs1 << 15) | (funct3 << 12) | (rd << 7) | opcode
}

fn encode_u(imm: i32, rd: u32, opcode: u32) -> u32 {
    // U-type: imm[31:12] in bits[31:12], low 12 bits zero.
    let imm20 = ((imm as u32) >> 12) & 0xFFFFF;
    (imm20 << 12) | (rd << 7) | opcode
}

fn encode_r(funct7: u32, rs2: u32, rs1: u32, funct3: u32, rd: u32, opcode: u32) -> u32 {
    (funct7 << 25) | (rs2 << 20) | (rs1 << 15) | (funct3 << 12) | (rd << 7) | opcode
}

fn encode_s(imm: i32, rs2: u32, rs1: u32, funct3: u32, opcode: u32) -> u32 {
    let imm12 = (imm as u32) & 0xFFF;
    let imm11_5 = (imm12 >> 5) & 0x7F;
    let imm4_0 = imm12 & 0x1F;
    (imm11_5 << 25)
        | (rs2 << 20)
        | (rs1 << 15)
        | (funct3 << 12)
        | (imm4_0 << 7)
        | opcode
}

fn encode_j(imm: i32, rd: u32) -> u32 {
    // J-type immediate, imm is already the signed byte offset.
    let imm20 = ((imm >> 20) & 0x1) as u32;
    let imm10_1 = ((imm >> 1) & 0x3FF) as u32;
    let imm11 = ((imm >> 11) & 0x1) as u32;
    let imm19_12 = ((imm >> 12) & 0xFF) as u32;
    (imm20 << 31) | (imm19_12 << 12) | (imm11 << 20) | (imm10_1 << 21) | (rd << 7) | 0x6F
}

fn encode_b(imm: i32, rs2: u32, rs1: u32, funct3: u32, opcode: u32) -> u32 {
    // B-type immediate, imm is signed byte offset (multiple of 2).
    let imm13 = (imm as u32) & 0x1FFF;
    let imm12 = (imm13 >> 12) & 0x1;
    let imm10_5 = (imm13 >> 5) & 0x3F;
    let imm4_1 = (imm13 >> 1) & 0xF;
    let imm11 = (imm13 >> 11) & 0x1;
    (imm12 << 31)
        | (imm10_5 << 25)
        | (rs2 << 20)
        | (rs1 << 15)
        | (funct3 << 12)
        | (imm4_1 << 8)
        | (imm11 << 7)
        | opcode
}

fn sext(value: u32, bits: u8) -> i32 {
    let shift = 32 - bits as i32;
    ((value << shift) as i32) >> shift
}

pub fn expand_compressed(insn: u16) -> Result<u32, Trap> {
    let opcode = insn & 0x3;
    let funct3 = (insn >> 13) & 0x7;

    match opcode {
        0b00 => expand_q0(insn, funct3),
        0b01 => expand_q1(insn, funct3),
        0b10 => expand_q2(insn, funct3),
        _ => Err(Trap::IllegalInstruction(insn as u64)),
    }
}

fn expand_q0(insn: u16, funct3: u16) -> Result<u32, Trap> {
    let insn_u = insn as u32;
    match funct3 {
        // C.ADDI4SPN -> ADDI rd', x2, nzuimm
        0b000 => {
            let nzuimm = (((insn_u >> 6) & 0x1) << 2)
                | (((insn_u >> 5) & 0x1) << 3)
                | (((insn_u >> 11) & 0x3) << 4)
                | (((insn_u >> 7) & 0xF) << 6);
            if nzuimm == 0 {
                return Err(Trap::IllegalInstruction(insn as u64));
            }
            let rd_prime = 8 + ((insn_u >> 2) & 0x7);
            Ok(encode_i(nzuimm as i32, 2, 0x0, rd_prime, 0x13))
        }
        // C.LW -> LW rd', uimm(rs1')
        0b010 => {
            let uimm =
                (((insn_u >> 6) & 0x1) << 2) | (((insn_u >> 10) & 0x7) << 3) | (((insn_u >> 5) & 0x1) << 6);
            let rd_prime = 8 + ((insn_u >> 2) & 0x7);
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            Ok(encode_i(uimm as i32, rs1_prime, 0x2, rd_prime, 0x03))
        }
        // C.LD -> LD rd', uimm(rs1')
        0b011 => {
            let uimm = (((insn_u >> 10) & 0x7) << 3) | (((insn_u >> 5) & 0x3) << 6);
            let rd_prime = 8 + ((insn_u >> 2) & 0x7);
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            Ok(encode_i(uimm as i32, rs1_prime, 0x3, rd_prime, 0x03))
        }
        // C.SW -> SW rs2', uimm(rs1')
        0b110 => {
            let uimm =
                (((insn_u >> 6) & 0x1) << 2) | (((insn_u >> 10) & 0x7) << 3) | (((insn_u >> 5) & 0x1) << 6);
            let rs2_prime = 8 + ((insn_u >> 2) & 0x7);
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            Ok(encode_s(uimm as i32, rs2_prime, rs1_prime, 0x2, 0x23))
        }
        // C.SD -> SD rs2', uimm(rs1')
        0b111 => {
            let uimm = (((insn_u >> 10) & 0x7) << 3) | (((insn_u >> 5) & 0x3) << 6);
            let rs2_prime = 8 + ((insn_u >> 2) & 0x7);
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            Ok(encode_s(uimm as i32, rs2_prime, rs1_prime, 0x3, 0x23))
        }
        _ => Err(Trap::IllegalInstruction(insn as u64)),
    }
}

fn expand_q1(insn: u16, funct3: u16) -> Result<u32, Trap> {
    let insn_u = insn as u32;
    match funct3 {
        // C.NOP / C.ADDI
        0b000 => {
            let rd = (insn_u >> 7) & 0x1F;
            let imm_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
            let imm = sext(imm_bits, 6);
            if rd == 0 {
                if imm == 0 {
                    // C.NOP
                    return Ok(encode_i(0, 0, 0x0, 0, 0x13));
                } else {
                    return Err(Trap::IllegalInstruction(insn as u64));
                }
            }
            Ok(encode_i(imm, rd, 0x0, rd, 0x13)) // ADDI rd, rd, imm
        }
        // RV64: C.ADDIW
        0b001 => {
            let rd = (insn_u >> 7) & 0x1F;
            let imm_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
            let imm = sext(imm_bits, 6);
            if rd == 0 {
                return Err(Trap::IllegalInstruction(insn as u64));
            }
            Ok(encode_i(imm, rd, 0x0, rd, 0x1B)) // ADDIW rd, rd, imm
        }
        // C.LI -> ADDI rd, x0, imm
        0b010 => {
            let rd = (insn_u >> 7) & 0x1F;
            let imm_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
            let imm = sext(imm_bits, 6);
            if rd == 0 {
                return Err(Trap::IllegalInstruction(insn as u64));
            }
            Ok(encode_i(imm, 0, 0x0, rd, 0x13))
        }
        // C.ADDI16SP / C.LUI
        0b011 => {
            let rd = (insn_u >> 7) & 0x1F;
            if rd == 2 {
                // C.ADDI16SP
                let mut nz = 0u32;
                nz |= ((insn_u >> 12) & 0x1) << 9;
                nz |= ((insn_u >> 3) & 0x3) << 7;
                nz |= ((insn_u >> 5) & 0x1) << 6;
                nz |= ((insn_u >> 2) & 0x1) << 5;
                nz |= ((insn_u >> 6) & 0x1) << 4;
                if nz == 0 {
                    return Err(Trap::IllegalInstruction(insn as u64));
                }
                let imm = sext(nz, 10);
                Ok(encode_i(imm, 2, 0x0, 2, 0x13)) // ADDI x2,x2,imm
            } else {
                // C.LUI -> LUI rd, imm
                let imm_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
                if rd == 0 || imm_bits == 0 {
                    return Err(Trap::IllegalInstruction(insn as u64));
                }
                let imm = sext(imm_bits, 6);
                Ok(encode_u(imm << 12, rd, 0x37))
            }
        }
        // C.SRLI / C.SRAI / C.ANDI / C.SUB/XOR/OR/AND
        0b100 => {
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            let rs2_prime = 8 + ((insn_u >> 2) & 0x7);
            let op = (insn_u >> 10) & 0x3;
            match op {
                // C.SRLI
                0b00 => {
                    let shamt_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
                    let shamt = shamt_bits & 0x3F; // RV64: 6-bit shamt
                    Ok(encode_i(shamt as i32, rs1_prime, 0x5, rs1_prime, 0x13)) // SRLI
                }
                // C.SRAI
                0b01 => {
                    let shamt_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
                    let shamt = shamt_bits & 0x3F;
                    // SRAI encoding: funct7=0b0100000, funct3=101
                    Ok(encode_i((0x20 << 6) | (shamt as i32), rs1_prime, 0x5, rs1_prime, 0x13))
                }
                // C.ANDI
                0b10 => {
                    let imm_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
                    let imm = sext(imm_bits, 6);
                    Ok(encode_i(imm, rs1_prime, 0x7, rs1_prime, 0x13))
                }
                // C.SUB / C.XOR / C.OR / C.AND (bit12=0) or C.SUBW / C.ADDW (bit12=1, RV64)
                0b11 => {
                    let bit12 = (insn_u >> 12) & 0x1;
                    let funct2 = (insn_u >> 5) & 0x3;
                    
                    if bit12 == 0 {
                        // C.SUB / C.XOR / C.OR / C.AND -> R-type with opcode 0x33
                        let (funct3, funct7) = match funct2 {
                            0b00 => (0x0, 0x20), // SUB
                            0b01 => (0x4, 0x00), // XOR
                            0b10 => (0x6, 0x00), // OR
                            0b11 => (0x7, 0x00), // AND
                            _ => unreachable!(),
                        };
                        Ok(
                            (funct7 << 25)
                                | (rs2_prime << 20)
                                | (rs1_prime << 15)
                                | (funct3 << 12)
                                | (rs1_prime << 7)
                                | 0x33,
                        )
                    } else {
                        // RV64C: C.SUBW / C.ADDW -> R-type with opcode 0x3B (Op32)
                        match funct2 {
                            0b00 => {
                                // C.SUBW -> SUBW rd', rd', rs2'
                                Ok(encode_r(0x20, rs2_prime, rs1_prime, 0x0, rs1_prime, 0x3B))
                            }
                            0b01 => {
                                // C.ADDW -> ADDW rd', rd', rs2'
                                Ok(encode_r(0x00, rs2_prime, rs1_prime, 0x0, rs1_prime, 0x3B))
                            }
                            // funct2 = 0b10, 0b11 are reserved in RV64C
                            _ => Err(Trap::IllegalInstruction(insn as u64)),
                        }
                    }
                }
                _ => Err(Trap::IllegalInstruction(insn as u64)),
            }
        }
        // C.J (unconditional jump)
        0b101 => {
            // C.J immediate: imm[11|4|9:8|10|6|7|3:1|5] with bit 0 implicitly 0
            let mut off = 0u32;
            off |= ((insn_u >> 12) & 0x1) << 11;
            off |= ((insn_u >> 11) & 0x1) << 4;
            off |= ((insn_u >> 9) & 0x3) << 8;
            off |= ((insn_u >> 8) & 0x1) << 10;
            off |= ((insn_u >> 7) & 0x1) << 6;
            off |= ((insn_u >> 6) & 0x1) << 7;
            off |= ((insn_u >> 3) & 0x7) << 1;
            off |= ((insn_u >> 2) & 0x1) << 5;
            // off already has bit 0 = 0 implicitly; sign-extend from bit 11
            let imm = sext(off, 12);
            Ok(encode_j(imm, 0)) // JAL x0, imm
        }
        // C.BEQZ
        0b110 => {
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            // C.BEQZ immediate: imm[8|4:3|7:6|2:1|5] with bit 0 implicitly 0
            let mut off = 0u32;
            off |= ((insn_u >> 12) & 0x1) << 8;
            off |= ((insn_u >> 10) & 0x3) << 3;
            off |= ((insn_u >> 5) & 0x3) << 6;
            off |= ((insn_u >> 3) & 0x3) << 1;
            off |= ((insn_u >> 2) & 0x1) << 5;
            // off already has bit 0 = 0 implicitly; sign-extend from bit 8
            let imm = sext(off, 9);
            Ok(encode_b(imm, 0, rs1_prime, 0x0, 0x63)) // BEQ rs1', x0, imm
        }
        // C.BNEZ
        0b111 => {
            let rs1_prime = 8 + ((insn_u >> 7) & 0x7);
            // C.BNEZ immediate: imm[8|4:3|7:6|2:1|5] with bit 0 implicitly 0
            let mut off = 0u32;
            off |= ((insn_u >> 12) & 0x1) << 8;
            off |= ((insn_u >> 10) & 0x3) << 3;
            off |= ((insn_u >> 5) & 0x3) << 6;
            off |= ((insn_u >> 3) & 0x3) << 1;
            off |= ((insn_u >> 2) & 0x1) << 5;
            // off already has bit 0 = 0 implicitly; sign-extend from bit 8
            let imm = sext(off, 9);
            Ok(encode_b(imm, 0, rs1_prime, 0x1, 0x63)) // BNE rs1', x0, imm
        }
        _ => Err(Trap::IllegalInstruction(insn as u64)),
    }
}

fn expand_q2(insn: u16, funct3: u16) -> Result<u32, Trap> {
    let insn_u = insn as u32;
    match funct3 {
        // C.SLLI
        0b000 => {
            let rd = (insn_u >> 7) & 0x1F;
            let imm_bits = ((insn_u >> 2) & 0x1F) | (((insn_u >> 12) & 0x1) << 5);
            let imm = imm_bits & 0x3F; // RV64: 6-bit shamt
            if rd == 0 {
                return Err(Trap::IllegalInstruction(insn as u64));
            }
            Ok(encode_i(imm as i32, rd, 0x1, rd, 0x13))
        }
        // C.LWSP
        0b010 => {
            let rd = (insn_u >> 7) & 0x1F;
            if rd == 0 {
                return Err(Trap::IllegalInstruction(insn as u64));
            }
            let uimm = (((insn_u >> 4) & 0x7) << 2)
                | (((insn_u >> 12) & 0x1) << 5)
                | (((insn_u >> 2) & 0x3) << 6);
            Ok(encode_i(uimm as i32, 2, 0x2, rd, 0x03))
        }
        // C.LDSP: LD rd, uimm(sp) - uimm[5|4:3|8:6] scaled by 8
        0b011 => {
            let rd = (insn_u >> 7) & 0x1F;
            if rd == 0 {
                return Err(Trap::IllegalInstruction(insn as u64));
            }
            // bit 12 -> uimm[5], bits [6:5] -> uimm[4:3], bits [4:2] -> uimm[8:6]
            let uimm = (((insn_u >> 12) & 0x1) << 5)
                | (((insn_u >> 5) & 0x3) << 3)
                | (((insn_u >> 2) & 0x7) << 6);
            Ok(encode_i(uimm as i32, 2, 0x3, rd, 0x03))
        }
        // C.JR / C.MV / C.EBREAK / C.JALR / C.ADD
        0b100 => {
            let rd = (insn_u >> 7) & 0x1F;
            let rs2 = (insn_u >> 2) & 0x1F;
            let bit12 = (insn_u >> 12) & 0x1;
            match (bit12, rs2, rd) {
                // C.JR: rs2=0, bit12=0, rd!=0
                (0, 0, rd) if rd != 0 => {
                    Ok(encode_i(0, rd, 0x0, 0, 0x67)) // JALR x0, rd, 0
                }
                // C.MV: bit12=0, rs2!=0, rd!=0
                (0, rs2, rd) if rs2 != 0 && rd != 0 => {
                    Ok(encode_r(0x00, rs2, 0, 0x0, rd, 0x33)) // ADD rd, x0, rs2
                }
                // C.EBREAK: bit12=1, rd=0, rs2=0
                (1, 0, 0) => Ok(0x0010_0073),
                // C.JALR: bit12=1, rs2=0, rd!=0
                (1, 0, rd) if rd != 0 => {
                    Ok(encode_i(0, rd, 0x0, 1, 0x67)) // JALR x1, rd, 0
                }
                // C.ADD: bit12=1, rs2!=0, rd!=0
                (1, rs2, rd) if rs2 != 0 && rd != 0 => {
                    Ok(encode_r(0x00, rs2, rd, 0x0, rd, 0x33)) // ADD rd, rd, rs2
                }
                _ => Err(Trap::IllegalInstruction(insn as u64)),
            }
        }
        // C.SWSP: SW rs2, uimm(sp) - uimm[5:2|7:6] scaled by 4
        0b110 => {
            let rs2 = (insn_u >> 2) & 0x1F;
            // bits [12:9] -> uimm[5:2], bits [8:7] -> uimm[7:6]
            let uimm = (((insn_u >> 9) & 0xF) << 2) | (((insn_u >> 7) & 0x3) << 6);
            Ok(encode_s(uimm as i32, rs2, 2, 0x2, 0x23))
        }
        // C.SDSP: SD rs2, uimm(sp) - uimm[5:3|8:6] scaled by 8
        0b111 => {
            let rs2 = (insn_u >> 2) & 0x1F;
            // bits [12:10] -> uimm[5:3], bits [9:7] -> uimm[8:6]
            let uimm = (((insn_u >> 10) & 0x7) << 3) | (((insn_u >> 7) & 0x7) << 6);
            Ok(encode_s(uimm as i32, rs2, 2, 0x3, 0x23))
        }
        _ => Err(Trap::IllegalInstruction(insn as u64)),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn decode_lui_and_jal() {
        // LUI x2, 0x12345
        let lui_insn: u32 = 0x12345137;
        let op = decode(lui_insn).unwrap();
        match op {
            Op::Lui { rd, imm } => {
                assert_eq!(rd, Register::X2);
                assert_eq!(imm, 0x0000_0000_1234_5000);
            }
            _ => panic!("Expected LUI op"),
        }

        // JAL x1, 8 (matches cpu::tests::test_jal)
        let jal_insn: u32 = (4 << 21) | (1 << 7) | 0x6F;
        let op = decode(jal_insn).unwrap();
        match op {
            Op::Jal { rd, imm } => {
                assert_eq!(rd, Register::X1);
                assert_eq!(imm, 8);
            }
            _ => panic!("Expected JAL op"),
        }
    }

    #[test]
    fn decode_illegal_opcode() {
        // Opcode with bits[6:0] not matching any valid RV64I opcode we implement.
        let bad: u32 = 0x0000_0000;
        let res = decode(bad);
        match res {
            Err(Trap::IllegalInstruction(bits)) => assert_eq!(bits, bad as u64),
            _ => panic!("Expected IllegalInstruction trap"),
        }
    }

    #[test]
    fn expand_compressed_basic_integer_ops() {
        // These 16-bit encodings come from assembling with rv64imac:
        //   addi x8, x2, 16          # C.ADDI4SPN
        //   addi x11,x11,1           # C.ADDI
        //   addiw x12,x12,1          # C.ADDIW
        //   addi x13,x0,-1           # C.LI
        //   addi x2, x2, 16          # C.ADDI16SP
        //   lui  x14,1               # C.LUI
        let c_addi4spn: u16 = 0x0800;
        let c_addi: u16 = 0x0585;
        let c_addiw: u16 = 0x2605;
        let c_li: u16 = 0x56FD;
        let c_addi16sp: u16 = 0x0141;
        let c_lui: u16 = 0x6705;

        // C.ADDI4SPN -> ADDI x8, x2, 16
        let op = decode(expand_compressed(c_addi4spn).unwrap()).unwrap();
        match op {
            Op::OpImm { rd, rs1, imm, funct3, .. } => {
                assert_eq!(rd, Register::X8);
                assert_eq!(rs1, Register::X2);
                assert_eq!(imm, 16);
                assert_eq!(funct3, 0);
            }
            _ => panic!("Expected OpImm from C.ADDI4SPN"),
        }

        // C.ADDI -> ADDI x11, x11, 1
        let op = decode(expand_compressed(c_addi).unwrap()).unwrap();
        match op {
            Op::OpImm { rd, rs1, imm, .. } => {
                assert_eq!(rd, Register::X11);
                assert_eq!(rs1, Register::X11);
                assert_eq!(imm, 1);
            }
            _ => panic!("Expected OpImm from C.ADDI"),
        }

        // C.ADDIW -> ADDIW x12, x12, 1
        let op = decode(expand_compressed(c_addiw).unwrap()).unwrap();
        match op {
            Op::OpImm32 { rd, rs1, imm, .. } => {
                assert_eq!(rd, Register::X12);
                assert_eq!(rs1, Register::X12);
                assert_eq!(imm, 1);
            }
            _ => panic!("Expected OpImm32 from C.ADDIW"),
        }

        // C.LI -> ADDI x13, x0, -1
        let op = decode(expand_compressed(c_li).unwrap()).unwrap();
        match op {
            Op::OpImm { rd, rs1, imm, .. } => {
                assert_eq!(rd, Register::X13);
                assert_eq!(rs1, Register::X0);
                assert_eq!(imm, -1);
            }
            _ => panic!("Expected OpImm from C.LI"),
        }

        // C.ADDI16SP -> ADDI x2, x2, 16
        let op = decode(expand_compressed(c_addi16sp).unwrap()).unwrap();
        match op {
            Op::OpImm { rd, rs1, imm, .. } => {
                assert_eq!(rd, Register::X2);
                assert_eq!(rs1, Register::X2);
                assert_eq!(imm, 16);
            }
            _ => panic!("Expected OpImm from C.ADDI16SP"),
        }

        // C.LUI -> LUI x14, 1
        let op = decode(expand_compressed(c_lui).unwrap()).unwrap();
        match op {
            Op::Lui { rd, imm } => {
                assert_eq!(rd, Register::X14);
                assert_eq!(imm, 0x0000_0000_0000_1000);
            }
            _ => panic!("Expected Lui from C.LUI"),
        }
    }
}
</file>

<file path="riscv-vm/src/dram.rs">
use thiserror::Error;

/// Base physical address of DRAM as seen by devices that work directly with
/// physical addresses (VirtIO, etc.).
///
/// This matches the DRAM base used by the `SystemBus` in `bus.rs` and the
/// Phase-0 virt memory map.
pub const DRAM_BASE: u64 = 0x8000_0000;

/// Device-local memory access errors.
///
/// These are mapped into architectural traps (`Trap`) by higher layers
/// (e.g., the system bus) where appropriate.
#[derive(Debug, Error)]
pub enum MemoryError {
    #[error("Out-of-bounds memory access at {0:#x}")]
    OutOfBounds(u64),

    #[error("Invalid or misaligned access at {0:#x}")]
    InvalidAlignment(u64),
}

/// Simple byte-addressable DRAM backing store used by VirtIO-style devices.
///
/// Offsets passed to the load/store helpers are **physical offsets from
/// `DRAM_BASE`**, not full guest physical addresses. Callers typically use
/// `DRAM_BASE` and subtract it via a helper (see `virtio.rs`).
pub struct Dram {
    pub base: u64,
    pub data: Vec<u8>,
}

impl Dram {
    /// Create a new DRAM image of `size` bytes, zero-initialised.
    pub fn new(base: u64, size: usize) -> Self {
        Self { base, data: vec![0; size] }
    }

    pub fn offset(&self, addr: u64) -> Option<usize> {
        if addr >= self.base {
            let off = (addr - self.base) as usize;
            if off < self.data.len() {
                return Some(off);
            }
        }
        None
    }

    pub fn load(&mut self, data: &[u8], offset: u64) -> Result<(), MemoryError> {
        self.write_bytes(offset, data)
    }

    pub fn zero_range(&mut self, offset: usize, len: usize) -> Result<(), MemoryError> {
        if offset + len > self.data.len() {
            return Err(MemoryError::OutOfBounds(offset as u64));
        }
        for i in 0..len {
            self.data[offset + i] = 0;
        }
        Ok(())
    }

    fn check_bounds(&self, offset: u64, size: usize) -> Result<usize, MemoryError> {
        let off = offset as usize;
        let end = off.checked_add(size).ok_or(MemoryError::OutOfBounds(offset))?;
        if end > self.data.len() {
            return Err(MemoryError::OutOfBounds(offset));
        }
        Ok(off)
    }

    pub fn load_8(&self, offset: u64) -> Result<u8, MemoryError> {
        let off = self.check_bounds(offset, 1)?;
        Ok(self.data[off])
    }

    pub fn load_16(&self, offset: u64) -> Result<u16, MemoryError> {
        if offset % 2 != 0 {
            return Err(MemoryError::InvalidAlignment(offset));
        }
        let off = self.check_bounds(offset, 2)?;
        let bytes: [u8; 2] = self.data[off..off + 2].try_into().unwrap();
        Ok(u16::from_le_bytes(bytes))
    }

    pub fn load_32(&self, offset: u64) -> Result<u32, MemoryError> {
        if offset % 4 != 0 {
            return Err(MemoryError::InvalidAlignment(offset));
        }
        let off = self.check_bounds(offset, 4)?;
        let bytes: [u8; 4] = self.data[off..off + 4].try_into().unwrap();
        Ok(u32::from_le_bytes(bytes))
    }

    pub fn load_64(&self, offset: u64) -> Result<u64, MemoryError> {
        if offset % 8 != 0 {
            return Err(MemoryError::InvalidAlignment(offset));
    }
        let off = self.check_bounds(offset, 8)?;
        let bytes: [u8; 8] = self.data[off..off + 8].try_into().unwrap();
        Ok(u64::from_le_bytes(bytes))
    }

    pub fn store_8(&mut self, offset: u64, value: u64) -> Result<(), MemoryError> {
        let off = self.check_bounds(offset, 1)?;
        self.data[off] = (value & 0xff) as u8;
        Ok(())
    }

    pub fn store_16(&mut self, offset: u64, value: u64) -> Result<(), MemoryError> {
        if offset % 2 != 0 {
            return Err(MemoryError::InvalidAlignment(offset));
        }
        let off = self.check_bounds(offset, 2)?;
        let bytes = (value as u16).to_le_bytes();
        self.data[off..off + 2].copy_from_slice(&bytes);
        Ok(())
    }

    pub fn store_32(&mut self, offset: u64, value: u64) -> Result<(), MemoryError> {
        if offset % 4 != 0 {
            return Err(MemoryError::InvalidAlignment(offset));
        }
        let off = self.check_bounds(offset, 4)?;
        let bytes = (value as u32).to_le_bytes();
        self.data[off..off + 4].copy_from_slice(&bytes);
        Ok(())
    }

    pub fn store_64(&mut self, offset: u64, value: u64) -> Result<(), MemoryError> {
        if offset % 8 != 0 {
            return Err(MemoryError::InvalidAlignment(offset));
        }
        let off = self.check_bounds(offset, 8)?;
        let bytes = value.to_le_bytes();
        self.data[off..off + 8].copy_from_slice(&bytes);
        Ok(())
    }

    /// Write an arbitrary slice into DRAM starting at `offset`.
    pub fn write_bytes(&mut self, offset: u64, data: &[u8]) -> Result<(), MemoryError> {
        let off = self.check_bounds(offset, data.len())?;
        self.data[off..off + data.len()].copy_from_slice(data);
        Ok(())
    }
}
</file>

<file path="riscv-vm/src/emulator.rs">
use crate::bus::{SystemBus, DRAM_BASE};
use crate::cpu::Cpu;
use crate::Trap;
use goblin::elf::{program_header::PT_LOAD, Elf};
use std::fs::File;
use std::io::{Read, Write};
use std::path::Path;

use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use std::collections::HashMap;

/// Default DRAM size used when constructing an [`Emulator`] via [`Emulator::new`].
///
/// This is large enough for riscv-arch-test binaries and small kernels, while
/// still being reasonably light for host machines.
const DEFAULT_DRAM_MIB: usize = 128;

/// Default size of the signature region when only a base address is provided.
///
/// RISCOF test signatures are typically small; 4 KiB is a conservative
/// default and can be overridden via [`Emulator::set_signature_region`].
const DEFAULT_SIGNATURE_SIZE: u64 = 4 * 1024;

/// High-level emulator wrapper used by test harnesses (e.g. RISCOF backend).
///
/// This mirrors the sketch in `phase-6.md`:
///
/// ```ignore
/// let mut emu = Emulator::new();
/// emu.load_elf("test.elf")?;
/// emu.set_signature_addr(0x8001_0000);
/// while !emu.trapped() { emu.step()?; }
/// let sig = emu.read_signature()?;
/// ```
pub struct Emulator {
    /// CPU core (GPRs, CSRs, privilege mode, TLB, etc).
    pub cpu: Cpu,
    /// System bus with DRAM and all memory-mapped devices.
    pub bus: SystemBus,

    signature_addr: Option<u64>,
    signature_size: u64,

    trapped: bool,
    last_trap: Option<Trap>,

    /// Optional UART output callback invoked once per transmitted byte.
    ///
    /// This provides a deterministic, buffered integration point for hosts
    /// (CLI, web UI, tests) without requiring them to poll the UART FIFO.
    uart_callback: Option<Box<dyn FnMut(u8) + 'static>>,
}

impl Emulator {
    /// Create a new emulator instance with the default DRAM size and reset PC.
    ///
    /// The reset PC is initialised to the DRAM base (0x8000_0000) but will be
    /// overwritten by [`load_elf`] when an ELF image is loaded.
    pub fn new() -> Self {
        Self::with_memory(DEFAULT_DRAM_MIB * 1024 * 1024)
    }

    /// Create a new emulator instance with an explicit DRAM size in bytes.
    pub fn with_memory(dram_size_bytes: usize) -> Self {
        let dram_base = DRAM_BASE;
        let bus = SystemBus::new(dram_base, dram_size_bytes);
        let cpu = Cpu::new(dram_base);

        Self {
            cpu,
            bus,
            signature_addr: None,
            signature_size: 0,
            trapped: false,
            last_trap: None,
            uart_callback: None,
        }
    }

    /// Returns `true` once execution has terminated due to a trap or
    /// an explicit host-level stop condition.
    pub fn trapped(&self) -> bool {
        self.trapped
    }

    /// Returns the last architectural trap observed, if any.
    pub fn last_trap(&self) -> Option<&Trap> {
        self.last_trap.as_ref()
    }

    /// Register a UART output callback.
    ///
    /// The callback is invoked from [`step`] for each byte emitted by the
    /// emulated NS16550A UART. Hosts that prefer pull-based I/O can ignore
    /// this and call [`drain_uart_output`] instead.
    pub fn set_uart_callback<F>(&mut self, cb: F)
    where
        F: FnMut(u8) + 'static,
    {
        self.uart_callback = Some(Box::new(cb));
    }

    /// Push a single input byte into the UART RX FIFO.
    ///
    /// This models a host keystroke or serial input event in a buffered,
    /// deterministic way: given the same sequence of calls and instruction
    /// stream, the guest will see identical input ordering.
    pub fn push_key(&mut self, byte: u8) {
        self.bus.uart.push_input(byte);
    }

    /// Drain all pending UART output bytes into a vector.
    ///
    /// This is useful for tests or hosts that do not wish to use the callback
    /// interface.
    pub fn drain_uart_output(&mut self) -> Vec<u8> {
        let mut out = Vec::new();
        while let Some(b) = self.bus.uart.pop_output() {
            out.push(b);
        }
        out
    }

    /// Execute a single instruction.
    ///
    /// On success, returns `Ok(())`. On architectural traps, this records the
    /// trap in [`last_trap`] and sets [`trapped`] before returning `Err(trap)`.
    pub fn step(&mut self) -> Result<(), Trap> {
        match self.cpu.step(&mut self.bus) {
            Ok(()) => {
                // Deliver UART bytes to host callback if registered.
                if let Some(cb) = self.uart_callback.as_mut() {
                    while let Some(byte) = self.bus.uart.pop_output() {
                        cb(byte);
                    }
                }

                Ok(())
            }
            Err(trap) => {
                self.trapped = true;
                self.last_trap = Some(trap.clone());
                Err(trap)
            }
        }
    }

    /// Load an ELF image from disk into DRAM and update the CPU's PC to the
    /// ELF entry point.
    ///
    /// Returns the resolved entry PC on success.
    pub fn load_elf<P: AsRef<Path>>(
        &mut self,
        path: P,
    ) -> Result<u64, Box<dyn std::error::Error>> {
        let mut file = File::open(path)?;
        let mut buffer = Vec::new();
        file.read_to_end(&mut buffer)?;

        let entry_pc = load_elf_into_dram(&buffer, &mut self.bus)?;
        self.cpu.pc = entry_pc;
        Ok(entry_pc)
    }

    /// Configure the signature region used by `read_signature`.
    ///
    /// - `base` is the physical start address of the signature buffer.
    /// - `size` is the number of bytes to read.
    pub fn set_signature_region(&mut self, base: u64, size: u64) {
        self.signature_addr = Some(base);
        self.signature_size = size;
    }

    /// Convenience helper matching the `phase-6.md` sketch.
    ///
    /// This sets the base address and uses a default size of 4 KiB unless a
    /// region size has already been configured via [`set_signature_region`].
    pub fn set_signature_addr(&mut self, base: u64) {
        self.signature_addr = Some(base);
        if self.signature_size == 0 {
            self.signature_size = DEFAULT_SIGNATURE_SIZE;
        }
    }

    /// Read the configured signature region from DRAM.
    ///
    /// Returns an owned `Vec<u8>` which callers can hex-encode or compare
    /// against reference signatures.
    pub fn read_signature(&self) -> Result<Vec<u8>, String> {
        let base = self
            .signature_addr
            .ok_or_else(|| "signature address not configured".to_string())?;
        if self.signature_size == 0 {
            return Err("signature size is zero; call set_signature_region first".to_string());
        }

        let dram_base = self.bus.dram_base();
        let dram_size = self.bus.dram_size() as u64;

        if base < dram_base || base >= dram_base + dram_size {
            return Err(format!(
                "signature base 0x{base:016x} lies outside DRAM (0x{dram_base:016x}..0x{:016x})",
                dram_base + dram_size
            ));
        }

        let offset = (base - dram_base) as usize;
        let end = offset
            .checked_add(self.signature_size as usize)
            .ok_or_else(|| "signature range overflow".to_string())?;

        if end > self.bus.dram_size() {
            return Err("signature range extends beyond DRAM".to_string());
        }

        // SAFETY: bounds checked above.
        Ok(self.bus.dram.data[offset..end].to_vec())
    }
}

const SNAPSHOT_VERSION: &str = "2.0";

/// Serializable CPU state used in snapshots.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CpuSnapshot {
    pub pc: u64,
    pub mode: crate::csr::Mode,
    pub regs: [u64; 32],
    pub csrs: HashMap<u16, u64>,
}

/// Serializable CLINT state.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClintSnapshot {
    pub msip: [u32; crate::clint::MAX_HARTS],
    pub mtime: u64,
    pub mtimecmp: [u64; crate::clint::MAX_HARTS],
}

/// Serializable PLIC state.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PlicSnapshot {
    pub priority: Vec<u32>,
    pub pending: u32,
    pub enable: Vec<u32>,
    pub threshold: Vec<u32>,
    pub active: Vec<u32>,
}

/// Serializable UART state.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UartSnapshot {
    pub rx_fifo: Vec<u8>,
    pub tx_fifo: Vec<u8>,
    pub ier: u8,
    pub iir: u8,
    pub fcr: u8,
    pub lcr: u8,
    pub mcr: u8,
    pub lsr: u8,
    pub msr: u8,
    pub scr: u8,
    pub dll: u8,
    pub dlm: u8,
}

/// Serializable device state bundle.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DeviceSnapshot {
    pub clint: ClintSnapshot,
    pub plic: PlicSnapshot,
    pub uart: UartSnapshot,
}

/// Memory region snapshot (currently we only snapshot DRAM as a single region).
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemRegionSnapshot {
    pub base: u64,
    pub size: u64,
    pub hash: String,
    pub data: Option<Vec<u8>>,
}

/// Full emulator snapshot including CPU, devices and DRAM.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Snapshot {
    pub version: String,
    pub cpu: CpuSnapshot,
    pub devices: DeviceSnapshot,
    pub memory: Vec<MemRegionSnapshot>,
}

impl Emulator {
    /// Capture a complete, deterministic snapshot of the current emulator state.
    pub fn snapshot(&self) -> Snapshot {
        let cpu = CpuSnapshot {
            pc: self.cpu.pc,
            mode: self.cpu.mode,
            regs: self.cpu.regs,
            csrs: self.cpu.export_csrs(),
        };

        let clint = ClintSnapshot {
            msip: self.bus.clint.msip,
            mtime: self.bus.clint.mtime,
            mtimecmp: self.bus.clint.mtimecmp,
        };

        let plic = PlicSnapshot {
            priority: self.bus.plic.priority.to_vec(),
            pending: self.bus.plic.pending,
            enable: self.bus.plic.enable.to_vec(),
            threshold: self.bus.plic.threshold.to_vec(),
            active: self.bus.plic.active.to_vec(),
        };

        let uart = UartSnapshot {
            rx_fifo: self.bus.uart.input.iter().copied().collect(),
            tx_fifo: self.bus.uart.output.iter().copied().collect(),
            ier: self.bus.uart.ier,
            iir: self.bus.uart.iir,
            fcr: self.bus.uart.fcr,
            lcr: self.bus.uart.lcr,
            mcr: self.bus.uart.mcr,
            lsr: self.bus.uart.lsr,
            msr: self.bus.uart.msr,
            scr: self.bus.uart.scr,
            dll: self.bus.uart.dll,
            dlm: self.bus.uart.dlm,
        };

        let mut hasher = Sha256::new();
        hasher.update(&self.bus.dram.data);
        let hash = hex::encode(hasher.finalize());

        let region = MemRegionSnapshot {
            base: self.bus.dram.base,
            size: self.bus.dram.data.len() as u64,
            hash,
            data: Some(self.bus.dram.data.clone()),
        };

        Snapshot {
            version: SNAPSHOT_VERSION.to_string(),
            cpu,
            devices: DeviceSnapshot { clint, plic, uart },
            memory: vec![region],
        }
    }

    /// Restore emulator state from a previously captured snapshot.
    pub fn apply_snapshot(&mut self, snapshot: &Snapshot) -> Result<(), String> {
        if snapshot.version != SNAPSHOT_VERSION {
            return Err(format!(
                "snapshot version mismatch: expected {}, found {}",
                SNAPSHOT_VERSION, snapshot.version
            ));
        }

        // Restore CPU core.
        self.cpu.pc = snapshot.cpu.pc;
        self.cpu.mode = snapshot.cpu.mode;
        self.cpu.regs = snapshot.cpu.regs;
        self.cpu.import_csrs(&snapshot.cpu.csrs);
        self.trapped = false;
        self.last_trap = None;

        // Restore CLINT.
        self.bus.clint.msip = snapshot.devices.clint.msip;
        self.bus.clint.set_mtime(snapshot.devices.clint.mtime);
        self.bus.clint.mtimecmp = snapshot.devices.clint.mtimecmp;

        // Restore PLIC (truncate if snapshot has more sources/contexts).
        for (i, &val) in snapshot.devices.plic.priority.iter().enumerate() {
            if i < self.bus.plic.priority.len() {
                self.bus.plic.priority[i] = val;
            }
        }
        self.bus.plic.pending = snapshot.devices.plic.pending;
        for (i, &val) in snapshot.devices.plic.enable.iter().enumerate() {
            if i < self.bus.plic.enable.len() {
                self.bus.plic.enable[i] = val;
            }
        }
        for (i, &val) in snapshot.devices.plic.threshold.iter().enumerate() {
            if i < self.bus.plic.threshold.len() {
                self.bus.plic.threshold[i] = val;
            }
        }
        for (i, &val) in snapshot.devices.plic.active.iter().enumerate() {
            if i < self.bus.plic.active.len() {
                self.bus.plic.active[i] = val;
            }
        }

        // Restore UART.
        self.bus.uart.input.clear();
        self.bus.uart.input.extend(snapshot.devices.uart.rx_fifo.iter().copied());
        self.bus.uart.output.clear();
        self.bus.uart.output.extend(snapshot.devices.uart.tx_fifo.iter().copied());
        self.bus.uart.ier = snapshot.devices.uart.ier;
        self.bus.uart.iir = snapshot.devices.uart.iir;
        self.bus.uart.fcr = snapshot.devices.uart.fcr;
        self.bus.uart.lcr = snapshot.devices.uart.lcr;
        self.bus.uart.mcr = snapshot.devices.uart.mcr;
        self.bus.uart.lsr = snapshot.devices.uart.lsr;
        self.bus.uart.msr = snapshot.devices.uart.msr;
        self.bus.uart.scr = snapshot.devices.uart.scr;
        self.bus.uart.dll = snapshot.devices.uart.dll;
        self.bus.uart.dlm = snapshot.devices.uart.dlm;
        self.bus.uart.update_interrupts();

        // Restore DRAM.
        let region = snapshot
            .memory
            .get(0)
            .ok_or_else(|| "snapshot missing primary memory region".to_string())?;

        let data = region
            .data
            .as_ref()
            .ok_or_else(|| "snapshot memory region has no inline data".to_string())?;

        if self.bus.dram.base != region.base {
            return Err(format!(
                "snapshot DRAM base mismatch: emulator=0x{:x}, snapshot=0x{:x}",
                self.bus.dram.base, region.base
            ));
        }
        if self.bus.dram.data.len() != data.len() {
            return Err(format!(
                "snapshot DRAM size mismatch: emulator={} bytes, snapshot={} bytes",
                self.bus.dram.data.len(),
                data.len()
            ));
        }

        let mut hasher = Sha256::new();
        hasher.update(data);
        let current_hash = hex::encode(hasher.finalize());
        if current_hash != region.hash {
            return Err(format!(
                "snapshot DRAM hash mismatch for base 0x{:x}",
                region.base
            ));
        }

        self.bus.dram.data.clone_from_slice(data);

        Ok(())
    }

    /// Construct a new emulator instance from a snapshot.
    pub fn from_snapshot(snapshot: Snapshot) -> Result<Self, String> {
        let region = snapshot
            .memory
            .get(0)
            .ok_or_else(|| "snapshot missing primary memory region".to_string())?;
        let dram_size = region
            .size
            .try_into()
            .map_err(|_| "snapshot DRAM size does not fit in usize".to_string())?;

        let mut emu = Emulator::with_memory(dram_size);
        emu.apply_snapshot(&snapshot)?;
        Ok(emu)
    }

    /// Save a snapshot to disk using bincode.
    pub fn save_snapshot_to_path<P: AsRef<Path>>(
        &self,
        path: P,
    ) -> Result<(), Box<dyn std::error::Error>> {
        let snap = self.snapshot();
        let mut file = File::create(path)?;
        bincode::serialize_into(&mut file, &snap)?;
        file.flush()?;
        Ok(())
    }

    /// Load a snapshot from disk and construct a new emulator instance.
    pub fn load_snapshot_from_path<P: AsRef<Path>>(
        path: P,
    ) -> Result<Self, Box<dyn std::error::Error>> {
        let mut file = File::open(path)?;
        let snapshot: Snapshot = bincode::deserialize_from(&mut file)?;
        let emu = Emulator::from_snapshot(snapshot)
            .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;
        Ok(emu)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::bus::Bus;

    #[test]
    fn snapshot_roundtrip_preserves_state() {
        let mut emu = Emulator::with_memory(1024 * 1024);

        // Simple CPU state.
        emu.cpu.pc = DRAM_BASE + 0x1000;
        emu.cpu.write_reg(crate::decoder::Register::X5, 0xdead_beef_dead_beef);

        // Touch DRAM and devices.
        let addr = emu.bus.dram_base() + 0x80;
        emu.bus.write64(addr, 0x0123_4567_89ab_cdef).unwrap();
        emu.bus.clint.mtime = 1234;
        emu.bus.clint.mtimecmp[0] = 5678;
        emu.bus.uart.push_input(b'A');

        let snap = emu.snapshot();
        let bytes = bincode::serialize(&snap).unwrap();
        let snap2: Snapshot = bincode::deserialize(&bytes).unwrap();

        let emu2 = Emulator::from_snapshot(snap2).unwrap();

        assert_eq!(emu.cpu.pc, emu2.cpu.pc);
        assert_eq!(
            emu.cpu.read_reg(crate::decoder::Register::X5),
            emu2.cpu.read_reg(crate::decoder::Register::X5)
        );
        assert_eq!(emu.bus.dram.data, emu2.bus.dram.data);
        assert_eq!(emu.bus.clint.mtime, emu2.bus.clint.mtime);
        assert_eq!(emu.bus.clint.mtimecmp, emu2.bus.clint.mtimecmp);
        assert_eq!(emu.bus.uart.input, emu2.bus.uart.input);
    }
}

fn load_elf_into_dram(
    buffer: &[u8],
    bus: &mut SystemBus,
) -> Result<u64, Box<dyn std::error::Error>> {
    let elf = Elf::parse(buffer)?;
    let base = bus.dram_base();
    let dram_end = base + bus.dram_size() as u64;

    for ph in &elf.program_headers {
        if ph.p_type != PT_LOAD || ph.p_memsz == 0 {
            continue;
        }

        let file_size = ph.p_filesz as usize;
        let mem_size = ph.p_memsz as usize;
        let file_offset = ph.p_offset as usize;
        if file_offset + file_size > buffer.len() {
            return Err(format!(
                "ELF segment exceeds file bounds (offset 0x{:x})",
                file_offset
            )
            .into());
        }

        let target_addr = if ph.p_paddr != 0 {
            ph.p_paddr
        } else {
            ph.p_vaddr
        };
        if target_addr < base {
            return Err(format!(
                "Segment start 0x{:x} lies below DRAM base 0x{:x}",
                target_addr, base
            )
            .into());
        }
        let seg_end = target_addr
            .checked_add(mem_size as u64)
            .ok_or_else(|| "Segment end overflow".to_string())?;
        if seg_end > dram_end {
            return Err(format!(
                "Segment 0x{:x}-0x{:x} exceeds DRAM (end 0x{:x})",
                target_addr, seg_end, dram_end
            )
            .into());
        }

        let dram_offset = (target_addr - base) as u64;
        if file_size > 0 {
            let end = file_offset + file_size;
            bus.dram
                .load(&buffer[file_offset..end], dram_offset)
                .map_err(|e| format!("Failed to load segment: {}", e))?;
        }
        if mem_size > file_size {
            let zero_start = dram_offset as usize + file_size;
            bus.dram
                .zero_range(zero_start, mem_size - file_size)
                .map_err(|e| format!("Failed to zero bss: {}", e))?;
        }
        log::debug!(
            "Loaded segment: addr=0x{:x}, filesz=0x{:x}, memsz=0x{:x}",
            target_addr,
            file_size,
            mem_size
        );
    }

    Ok(elf.entry)
}
</file>

<file path="riscv-vm/src/lib.rs">
pub mod bus;
pub mod cpu;
pub mod decoder;
pub mod csr;
pub mod mmu;
pub mod dram;
pub mod clint;
pub mod plic;
pub mod uart;
pub mod net;
pub mod net_ws;
pub mod virtio;
pub mod emulator;

#[cfg(not(target_arch = "wasm32"))]
pub mod console;

#[cfg(not(target_arch = "wasm32"))]
pub mod net_tap;

#[cfg(not(target_arch = "wasm32"))]
pub mod net_libp2p;

use serde::{Deserialize, Serialize};

// WASM bindings
#[cfg(target_arch = "wasm32")]
use wasm_bindgen::prelude::*;

#[cfg(target_arch = "wasm32")]
use crate::bus::{SystemBus, DRAM_BASE};

/// Network connection status for the WASM VM.
#[cfg(target_arch = "wasm32")]
#[wasm_bindgen]
#[derive(Clone, Copy, PartialEq, Eq)]
pub enum NetworkStatus {
    Disconnected = 0,
    Connecting = 1,
    Connected = 2,
    Error = 3,
}

/// WASM-exposed VM wrapper for running RISC-V kernels in the browser.
#[cfg(target_arch = "wasm32")]
#[wasm_bindgen]
pub struct WasmVm {
    bus: SystemBus,
    cpu: cpu::Cpu,
    net_status: NetworkStatus,
    poll_counter: u32,
}

#[cfg(target_arch = "wasm32")]
#[wasm_bindgen]
impl WasmVm {
    /// Create a new VM instance and load a kernel (ELF or raw binary).
    #[wasm_bindgen(constructor)]
    pub fn new(kernel: &[u8]) -> Result<WasmVm, JsValue> {
        // Set up panic hook for better error messages in the browser console
        console_error_panic_hook::set_once();

        const DRAM_SIZE: usize = 512 * 1024 * 1024; // 512 MiB
        let mut bus = SystemBus::new(DRAM_BASE, DRAM_SIZE);
        
        // Check if it's an ELF file and load appropriately
        let entry_pc = if kernel.starts_with(b"\x7FELF") {
            // Parse and load ELF
            load_elf_wasm(kernel, &mut bus)
                .map_err(|e| JsValue::from_str(&format!("Failed to load ELF kernel: {}", e)))?
        } else {
            // Load raw binary at DRAM_BASE
            bus.dram
                .load(kernel, 0)
                .map_err(|e| JsValue::from_str(&format!("Failed to load kernel: {}", e)))?;
            DRAM_BASE
        };

        let cpu = cpu::Cpu::new(entry_pc);

        Ok(WasmVm { 
            bus, 
            cpu, 
            net_status: NetworkStatus::Disconnected,
            poll_counter: 0,
        })
    }

    /// Load a disk image and attach it as a VirtIO block device.
    /// This should be called before starting execution if the kernel needs a filesystem.
    pub fn load_disk(&mut self, disk_image: &[u8]) {
        let vblk = virtio::VirtioBlock::new(disk_image.to_vec());
        self.bus.virtio_devices.push(Box::new(vblk));
    }

    /// Connect to a WebSocket relay server for networking.
    /// The URL should be like "ws://localhost:8765".
    pub fn connect_network(&mut self, ws_url: &str) -> Result<(), JsValue> {
        use crate::net_ws::WsBackend;
        use crate::virtio::VirtioNet;
        
        self.net_status = NetworkStatus::Connecting;
        
        let backend = WsBackend::new(ws_url);
        let mut vnet = VirtioNet::new(Box::new(backend));
        vnet.debug = false; // Set to true for debugging
        
        self.bus.virtio_devices.push(Box::new(vnet));
        self.net_status = NetworkStatus::Connected;
        
        Ok(())
    }
    
    /// Disconnect from the network.
    pub fn disconnect_network(&mut self) {
        // Remove VirtioNet devices (device_id == 1)
        self.bus.virtio_devices.retain(|dev| dev.device_id() != 1);
        self.net_status = NetworkStatus::Disconnected;
    }
    
    /// Get the current network connection status.
    pub fn network_status(&self) -> NetworkStatus {
        self.net_status
    }

    /// Execute a single instruction.
    pub fn step(&mut self) {
        // Poll VirtIO devices periodically for incoming network packets
        // Poll every 100 instructions for good network responsiveness
        self.poll_counter = self.poll_counter.wrapping_add(1);
        if self.poll_counter % 100 == 0 {
            self.bus.poll_virtio();
        }
        
        // Ignore traps for now - the kernel handles them
        let _ = self.cpu.step(&mut self.bus);
    }

    /// Get a byte from the UART output buffer, if available.
    pub fn get_output(&mut self) -> Option<u8> {
        self.bus.uart.pop_output()
    }

    /// Push an input byte to the UART.
    pub fn input(&mut self, byte: u8) {
        self.bus.uart.push_input(byte);
    }

    /// Get current memory usage (DRAM size) in bytes.
    pub fn get_memory_usage(&self) -> u64 {
        self.bus.dram.data.len() as u64
    }
}

/// Load an ELF kernel into DRAM (WASM-compatible version).
#[cfg(target_arch = "wasm32")]
fn load_elf_wasm(buffer: &[u8], bus: &mut SystemBus) -> Result<u64, String> {
    use goblin::elf::{program_header::PT_LOAD, Elf};
    
    let elf = Elf::parse(buffer).map_err(|e| format!("ELF parse error: {}", e))?;
    let base = bus.dram_base();
    let dram_end = base + bus.dram_size() as u64;

    for ph in &elf.program_headers {
        if ph.p_type != PT_LOAD || ph.p_memsz == 0 {
            continue;
        }

        let file_size = ph.p_filesz as usize;
        let mem_size = ph.p_memsz as usize;
        let file_offset = ph.p_offset as usize;
        if file_offset + file_size > buffer.len() {
            return Err(format!(
                "ELF segment exceeds file bounds (offset 0x{:x})",
                file_offset
            ));
        }

        let target_addr = if ph.p_paddr != 0 {
            ph.p_paddr
        } else {
            ph.p_vaddr
        };
        if target_addr < base {
            return Err(format!(
                "Segment start 0x{:x} lies below DRAM base 0x{:x}",
                target_addr, base
            ));
        }
        let seg_end = target_addr
            .checked_add(mem_size as u64)
            .ok_or_else(|| "Segment end overflow".to_string())?;
        if seg_end > dram_end {
            return Err(format!(
                "Segment 0x{:x}-0x{:x} exceeds DRAM (end 0x{:x})",
                target_addr, seg_end, dram_end
            ));
        }

        let dram_offset = (target_addr - base) as u64;
        if file_size > 0 {
            let end = file_offset + file_size;
            bus.dram
                .load(&buffer[file_offset..end], dram_offset)
                .map_err(|e| format!("Failed to load segment: {}", e))?;
        }
        if mem_size > file_size {
            let zero_start = dram_offset as usize + file_size;
            bus.dram
                .zero_range(zero_start, mem_size - file_size)
                .map_err(|e| format!("Failed to zero bss: {}", e))?;
        }
    }

    Ok(elf.entry)
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum Trap {
    InstructionAddressMisaligned(u64),
    InstructionAccessFault(u64),
    IllegalInstruction(u64),
    Breakpoint,
    LoadAddressMisaligned(u64),
    LoadAccessFault(u64),
    StoreAddressMisaligned(u64),
    StoreAccessFault(u64),
    EnvironmentCallFromU,
    EnvironmentCallFromS,
    EnvironmentCallFromM,
    InstructionPageFault(u64),
    LoadPageFault(u64),
    StorePageFault(u64),
    
    MachineSoftwareInterrupt,
    MachineTimerInterrupt,
    MachineExternalInterrupt,
    SupervisorSoftwareInterrupt,
    SupervisorTimerInterrupt,
    SupervisorExternalInterrupt,

    // Custom internal errors
    RequestedTrap(u64), // For testing (software interrupts, etc)
    Fatal(String),
}

impl std::fmt::Display for Trap {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{:?}", self)
    }
}

impl std::error::Error for Trap {}
</file>

<file path="riscv-vm/src/main.rs">
use clap::Parser;
use goblin::elf::{program_header::PT_LOAD, Elf};
use riscv_vm::bus::{Bus, SystemBus};
use riscv_vm::cpu::Cpu;
use riscv_vm::Trap;
use riscv_vm::csr::{CSR_MCAUSE, CSR_MEPC, CSR_MTVAL, CSR_MTVEC, CSR_SCAUSE, CSR_SEPC, CSR_STVAL, CSR_STVEC};
use std::fs::File;
use std::io::Read;
use std::path::PathBuf;

use riscv_vm::console::Console;

#[derive(Parser, Debug)]
#[command(author, version, about, long_about = None)]
struct Args {
    /// Path to binary to load
    #[arg(short, long)]
    kernel: PathBuf,

    /// Address to load kernel at (default 0x8000_0000)
    #[arg(long, default_value_t = 0x8000_0000)]
    load_addr: u64,

    /// DRAM size in MiB
    #[arg(long, default_value_t = 512)]
    mem_mib: usize,

    /// Optional path to a VirtIO Block disk image (e.g. xv6 fs.img)
    #[arg(long)]
    disk: Option<PathBuf>,

    /// Optional TAP interface name for VirtIO network device (e.g. tap0)
    /// Requires the interface to exist: sudo ip tuntap add dev tap0 mode tap
    #[arg(long)]
    net_tap: Option<String>,

    /// Enable VirtIO network device with a dummy backend (for testing, no actual packets)
    #[arg(long)]
    net_dummy: bool,

    /// Connect to a WebSocket server for networking (e.g. ws://localhost:8765)
    /// Works on macOS and in browser/WASM
    #[arg(long)]
    net_ws: Option<String>,

    /// Connect to a libp2p relay for networking (e.g. /ip4/127.0.0.1/udp/4001/quic-v1/p2p/PEER_ID)
    /// Supports NAT traversal and peer-to-peer connections
    #[arg(long)]
    net_libp2p: Option<String>,
}

// Debug helper: dump VirtIO MMIO identity registers expected by xv6.
fn dump_virtio_id(bus: &mut SystemBus) {
    const VIRTIO0_BASE: u64 = 0x1000_1000;
    fn r32(bus: &mut SystemBus, off: u64) -> u32 {
        bus.read32(VIRTIO0_BASE + off).unwrap_or(0)
    }
    let magic = r32(bus, 0x000);
    let ver = r32(bus, 0x004);
    let devid = r32(bus, 0x008);
    let vendor = r32(bus, 0x00c);
    eprintln!(
        "VirtIO ID: MAGIC=0x{:08x} VERSION={} DEVICE_ID={} VENDOR=0x{:08x}",
        magic, ver, devid, vendor
    );
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    env_logger::init();
    let args = Args::parse();

    let mut file = File::open(&args.kernel)?;
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer)?;

    let dram_size_bytes = args
        .mem_mib
        .checked_mul(1024 * 1024)
        .ok_or("Requested memory size is too large")?;

    // Initialize DRAM at 0x8000_0000
    let dram_base = 0x8000_0000;
    let mut bus = SystemBus::new(dram_base, dram_size_bytes);

    // If a disk image is provided, wire up VirtIO Block at 0x1000_1000
    if let Some(disk_path) = &args.disk {
        let mut disk_file = File::open(disk_path)?;
        let mut disk_buf = Vec::new();
        disk_file.read_to_end(&mut disk_buf)?;
        let vblk = riscv_vm::virtio::VirtioBlock::new(disk_buf);
        bus.virtio_devices.push(Box::new(vblk));
        println!("VirtIO Block device attached at 0x1000_1000 (IRQ 1)");
    }

    // If a TAP interface is provided, wire up VirtIO Net with TAP backend
    if let Some(tap_name) = &args.net_tap {
        let tap_backend = riscv_vm::net_tap::TapBackend::new(tap_name);
        let vnet = riscv_vm::virtio::VirtioNet::new(Box::new(tap_backend));
        let device_idx = bus.virtio_devices.len();
        let irq = 1 + device_idx; // IRQ 1 for first device, 2 for second, etc.
        bus.virtio_devices.push(Box::new(vnet));
        let base_addr = 0x1000_1000 + (device_idx as u64) * 0x1000;
        println!("VirtIO Net device (TAP: {}) attached at 0x{:x} (IRQ {})", tap_name, base_addr, irq);
    } else if let Some(ws_url) = &args.net_ws {
        // Wire up VirtIO Net with WebSocket backend
        let ws_backend = riscv_vm::net_ws::WsBackend::new(ws_url);
        let vnet = riscv_vm::virtio::VirtioNet::new(Box::new(ws_backend));
        let device_idx = bus.virtio_devices.len();
        let irq = 1 + device_idx;
        bus.virtio_devices.push(Box::new(vnet));
        let base_addr = 0x1000_1000 + (device_idx as u64) * 0x1000;
        println!("VirtIO Net device (WebSocket: {}) attached at 0x{:x} (IRQ {})", ws_url, base_addr, irq);
    } else if let Some(libp2p_addr) = &args.net_libp2p {
        // Wire up VirtIO Net with libp2p backend (QUIC relay)
        let libp2p_backend = riscv_vm::net_libp2p::Libp2pBackend::new(libp2p_addr);
        let vnet = riscv_vm::virtio::VirtioNet::new(Box::new(libp2p_backend));
        let device_idx = bus.virtio_devices.len();
        let irq = 1 + device_idx;
        bus.virtio_devices.push(Box::new(vnet));
        let base_addr = 0x1000_1000 + (device_idx as u64) * 0x1000;
        println!("VirtIO Net device (libp2p: {}) attached at 0x{:x} (IRQ {})", libp2p_addr, base_addr, irq);
    } else if args.net_dummy {
        // Wire up VirtIO Net with dummy backend (for testing)
        let dummy_backend = riscv_vm::net::DummyBackend::new();
        let vnet = riscv_vm::virtio::VirtioNet::new(Box::new(dummy_backend));
        let device_idx = bus.virtio_devices.len();
        let irq = 1 + device_idx;
        bus.virtio_devices.push(Box::new(vnet));
        let base_addr = 0x1000_1000 + (device_idx as u64) * 0x1000;
        println!("VirtIO Net device (Dummy) attached at 0x{:x} (IRQ {})", base_addr, irq);
    }

    let entry_pc = if buffer.starts_with(b"\x7FELF") {
        println!("Detected ELF payload, loading program segments...");
        load_elf_into_dram(&buffer, &mut bus)?
    } else {
        if args.load_addr < dram_base {
            eprintln!("Load address must be >= 0x{:x}", dram_base);
            return Ok(());
        }
        let offset = args.load_addr - dram_base;
        println!(
            "Loading raw binary ({} bytes) at 0x{:x}",
            buffer.len(),
            args.load_addr
        );
        bus.dram
            .load(&buffer, offset)
            .map_err(|e| std::io::Error::new(std::io::ErrorKind::Other, e))?;
        args.load_addr
    };

    let mut cpu = Cpu::new(entry_pc);

    println!("Starting execution at 0x{:x}", cpu.pc);
    // Early probe dump (harmless if device absent): helps debug xv6 panic on probe.
    dump_virtio_id(&mut bus);

    let mut step_count = 0u64;
    let mut last_report_step = 0u64;
    
    // Initialize console for host input
    let console = Console::new();
    let mut escaped = false;

    loop {
        // Poll console input
        if let Some(b) = console.poll() {
            if escaped {
                if b == b'x' {
                    println!("\nTerminated by user.");
                    break;
                } else if b == 1 {
                    // Ctrl-A twice -> send Ctrl-A to guest
                    bus.uart.push_input(1);
                } else {
                    // Ctrl-A then something else -> send that something else
                    // (Ctrl-A is swallowed)
                    bus.uart.push_input(b);
                }
                escaped = false;
            } else {
                if b == 1 { // Ctrl-A
                    escaped = true;
                } else {
                    bus.uart.push_input(b);
                }
            }
        }

        let step_result = cpu.step(&mut bus);
        step_count += 1;
        
        // Poll VirtIO devices for incoming network packets every 100 instructions
        // More frequent polling improves network responsiveness for interactive protocols
        if step_count % 100 == 0 {
            bus.poll_virtio();
        }
        
        // Progress report every 10M instructions (not every instruction!)
        if step_count - last_report_step >= 10_000_000 {
            // eprinteln!("[{} M insns] pc=0x{:x} mode={:?}", step_count / 1_000_000, cpu.pc, cpu.mode);
            last_report_step = step_count;
        }
        

        if let Err(trap) = step_result {
            match trap {
                // Test finisher / explicit host stop requested by the guest.
                Trap::RequestedTrap(code) => {
                    println!("Guest requested stop via test finisher: 0x{code:x}");
                    break;
                }
                // Non-recoverable emulator error: dump state and exit.
                Trap::Fatal(msg) => {
                    eprintln!("Fatal emulator error: {msg}");
                    println!("PC: 0x{:x}", cpu.pc);
                    for i in 0..32 {
                        if i % 4 == 0 {
                            println!();
                        }
                        print!("x{:<2}: 0x{:<16x} ", i, cpu.regs[i]);
                    }
                    println!();
                    break;
                }
                // Architectural traps (interrupts, page faults, ecalls, etc.)
                // are fully handled inside Cpu::handle_trap by updating CSRs
                // and redirecting PC to mtvec/stvec. We simply continue
                // stepping so that the guest handler can run.
                _other => {
                    // Traps are handled inside cpu.step() - just continue execution.
                    // Use RUST_LOG=debug to see trap details.
                    if log::log_enabled!(log::Level::Debug) {
                        let mepc  = cpu.read_csr(CSR_MEPC).unwrap_or(0);
                        let mcause = cpu.read_csr(CSR_MCAUSE).unwrap_or(0);
                        let mtval = cpu.read_csr(CSR_MTVAL).unwrap_or(0);
                        let mtvec = cpu.read_csr(CSR_MTVEC).unwrap_or(0);
                        log::debug!(
                            "Trap: {:?} pc=0x{:x} mepc=0x{:x} mcause=0x{:x} mtval=0x{:x} mtvec=0x{:x}",
                            _other, cpu.pc, mepc, mcause, mtval, mtvec
                        );
                    }
                }
            }
        }

        // Check UART output - handle raw mode by converting \n to \r\n
        use std::io::Write;
        let stdout = std::io::stdout();
        let mut stdout_lock = stdout.lock();
        while let Some(byte) = bus.uart.pop_output() {
            // In raw terminal mode, \n alone doesn't return cursor to column 0.
            // We need to emit \r\n for proper line breaks.
            if byte == b'\n' {
                let _ = stdout_lock.write_all(b"\r\n");
            } else if byte == b'\r' {
                // Carriage return - just emit it
                let _ = stdout_lock.write_all(b"\r");
            } else {
                let _ = stdout_lock.write_all(&[byte]);
            }
        }
        let _ = stdout_lock.flush();

        // Stop if PC is 0 in Machine/Supervisor mode (likely trap to unmapped vector).
        // User mode PC=0 is valid (xv6 initcode).
        if cpu.pc == 0 && cpu.mode != riscv_vm::csr::Mode::User {
            let mepc  = cpu.read_csr(CSR_MEPC).unwrap_or(0);
            let mcause = cpu.read_csr(CSR_MCAUSE).unwrap_or(0);
            let mtval = cpu.read_csr(CSR_MTVAL).unwrap_or(0);
            let mtvec = cpu.read_csr(CSR_MTVEC).unwrap_or(0);
            let sepc  = cpu.read_csr(CSR_SEPC).unwrap_or(0);
            let scause = cpu.read_csr(CSR_SCAUSE).unwrap_or(0);
            let stval = cpu.read_csr(CSR_STVAL).unwrap_or(0);
            let stvec = cpu.read_csr(CSR_STVEC).unwrap_or(0);
            println!("PC reached 0, stopping.");
            println!(
                "Final state:\n  pc=0x{:016x} mode={:?}\n  M: mepc=0x{:016x} mcause=0x{:016x} mtval=0x{:016x} mtvec=0x{:016x}\n  S: sepc=0x{:016x} scause=0x{:016x} stval=0x{:016x} stvec=0x{:016x}",
                cpu.pc, cpu.mode, mepc, mcause, mtval, mtvec, sepc, scause, stval, stvec
            );
            break;
        }
    }

    Ok(())
}

fn load_elf_into_dram(
    buffer: &[u8],
    bus: &mut SystemBus,
) -> Result<u64, Box<dyn std::error::Error>> {
    let elf = Elf::parse(buffer)?;
    let base = bus.dram_base();
    let dram_end = base + bus.dram_size() as u64;

    for ph in &elf.program_headers {
        if ph.p_type != PT_LOAD || ph.p_memsz == 0 {
            continue;
        }

        let file_size = ph.p_filesz as usize;
        let mem_size = ph.p_memsz as usize;
        let file_offset = ph.p_offset as usize;
        if file_offset + file_size > buffer.len() {
            return Err(format!(
                "ELF segment exceeds file bounds (offset 0x{:x})",
                file_offset
            )
            .into());
        }

        let target_addr = if ph.p_paddr != 0 {
            ph.p_paddr
        } else {
            ph.p_vaddr
        };
        if target_addr < base {
            return Err(format!(
                "Segment start 0x{:x} lies below DRAM base 0x{:x}",
                target_addr, base
            )
            .into());
        }
        let seg_end = target_addr
            .checked_add(mem_size as u64)
            .ok_or_else(|| "Segment end overflow".to_string())?;
        if seg_end > dram_end {
            return Err(format!(
                "Segment 0x{:x}-0x{:x} exceeds DRAM (end 0x{:x})",
                target_addr, seg_end, dram_end
            )
            .into());
        }

        let dram_offset = (target_addr - base) as u64;
        if file_size > 0 {
            let end = file_offset + file_size;
            bus.dram
                .load(&buffer[file_offset..end], dram_offset)
                .map_err(|e| format!("Failed to load segment: {}", e))?;
        }
        if mem_size > file_size {
            let zero_start = dram_offset as usize + file_size;
            bus.dram
                .zero_range(zero_start, mem_size - file_size)
                .map_err(|e| format!("Failed to zero bss: {}", e))?;
        }
        log::debug!(
            "Loaded segment: addr=0x{:x}, filesz=0x{:x}, memsz=0x{:x}",
            target_addr,
            file_size,
            mem_size
        );
    }

    Ok(elf.entry)
}
</file>

<file path="riscv-vm/src/mmu.rs">
use crate::bus::Bus;
use crate::csr::Mode;
use crate::Trap;

#[derive(Clone, Copy, PartialEq, Eq, Debug)]
pub enum AccessType {
    Instruction,
    Load,
    Store,
}

const PAGE_SIZE: u64 = 4096;
const PTE_SIZE: u64 = 8;
const MAX_LEVELS: usize = 4;

const TLB_SIZE: usize = 64;

#[derive(Clone, Copy, Debug)]
pub struct TlbEntry {
    pub vpn: u64,
    pub ppn: u64,
    pub valid: bool,
    pub asid: u64,
    pub global: bool, // Global mapping bit
    pub r: bool,
    pub w: bool,
    pub x: bool,
    pub u: bool,
    pub a: bool,
    pub d: bool,
}

impl Default for TlbEntry {
    fn default() -> Self {
        Self {
            vpn: 0,
            ppn: 0,
            valid: false,
            asid: 0,
            global: false,
            r: false,
            w: false,
            x: false,
            u: false,
            a: false,
            d: false,
        }
    }
}

pub struct Tlb {
    entries: [TlbEntry; TLB_SIZE],
}

impl Tlb {
    pub fn new() -> Self {
        Self {
            entries: [TlbEntry::default(); TLB_SIZE],
        }
    }

    pub fn flush(&mut self) {
        for entry in self.entries.iter_mut() {
            entry.valid = false;
        }
    }

    pub fn flush_asid(&mut self, asid: u64) {
        for entry in self.entries.iter_mut() {
            if !entry.global && entry.asid == asid {
                entry.valid = false;
            }
        }
    }

    pub fn flush_page(&mut self, vpn: u64, asid: u64) {
        let idx = (vpn as usize) % TLB_SIZE;
        let entry = &mut self.entries[idx];

        if entry.valid && entry.vpn == vpn {
            // For page-specific flush, invalidate matching ASID mappings.
            // Global mappings ignore ASID and are treated as matching.
            let match_asid = entry.global || entry.asid == asid;
            if match_asid {
                entry.valid = false;
            }
        }
    }

    pub fn lookup(&self, vpn: u64, asid: u64) -> Option<&TlbEntry> {
        let idx = (vpn as usize) % TLB_SIZE;
        let entry = &self.entries[idx];

        // Hit if: valid AND VPN matches AND (entry is global OR ASID matches).
        if entry.valid && entry.vpn == vpn && (entry.global || entry.asid == asid) {
            Some(entry)
        } else {
            None
        }
    }

    pub fn insert(&mut self, entry: TlbEntry) {
        let idx = (entry.vpn as usize) % TLB_SIZE;
        self.entries[idx] = entry;
    }
}

/// Sv39/Sv48 translation + A/D bit updates.
///
/// `addr` is a virtual address. Returns the translated physical address or a
/// `Trap` corresponding to the appropriate page/access fault.
pub fn translate(
    bus: &mut dyn Bus,
    tlb: &mut Tlb,
    mode: Mode,
    satp: u64,
    mstatus: u64,
    addr: u64,
    access_type: AccessType,
) -> Result<u64, Trap> {
    // No translation in Machine mode (always Bare).
    if mode == Mode::Machine {
        return Ok(addr);
    }

    let satp_mode = (satp >> 60) & 0xF;
    let current_asid = (satp >> 44) & 0xFFFF;

    let (levels, va_bits, vpn_full_mask): (usize, u64, u64) = match satp_mode {
        0 => {
            // Bare: no translation.
            return Ok(addr);
        }
        8 => {
            // Sv39
            let levels = 3;
            let va_bits = 39;
            let vpn_full_mask = (1u64 << (9 * levels)) - 1;
            (levels, va_bits, vpn_full_mask)
        }
        9 => {
            // Sv48 (supported by this MMU, though not required for virt).
            let levels = 4;
            let va_bits = 48;
            let vpn_full_mask = (1u64 << (9 * levels)) - 1;
            (levels, va_bits, vpn_full_mask)
        }
        _ => {
            // Unsupported mode: treat as Bare.
            return Ok(addr);
        }
    };

    // Check canonical form of the virtual address for the configured VA width.
    let sign_bit = va_bits - 1;
    let upper_mask = !((1u64 << va_bits) - 1);
    let sign = (addr >> sign_bit) & 1;
    let expected_upper = if sign == 1 { upper_mask } else { 0 };
    if (addr & upper_mask) != expected_upper {
        return Err(page_fault(access_type, addr));
    }

    let vpn_full = (addr >> 12) & vpn_full_mask;

    // TLB hit path.
    if let Some(entry) = tlb.lookup(vpn_full, current_asid) {
        if check_permission_tlb(mode, mstatus, entry, access_type) {
            // For now we do not lazily update A/D on TLB hits  page table
            // entries are already marked by the walk that inserted this entry.
            let offset = addr & 0xFFF;
            let pa = (entry.ppn << 12) | offset;
            return Ok(pa);
        } else {
            return Err(page_fault(access_type, addr));
        }
    }

    // Page table walk on TLB miss.
    let mut vpn = [0u64; MAX_LEVELS];
    for level in 0..levels {
        vpn[level] = (addr >> (12 + 9 * level as u64)) & 0x1FF;
    }

    let root_ppn = satp & ((1u64 << 44) - 1);
    let mut a = root_ppn * PAGE_SIZE;

    for i in (0..levels).rev() {
        let pte_addr = a + vpn[i] * PTE_SIZE;

        let pte = match bus.load(pte_addr, 8) {
            Ok(val) => val,
            Err(_) => return Err(access_fault(access_type, addr)),
        };

        let v = (pte >> 0) & 1;
        let r = (pte >> 1) & 1;
        let w = (pte >> 2) & 1;
        let x = (pte >> 3) & 1;

        // Invalid or malformed.
        if v == 0 || (r == 0 && w == 1) {
            return Err(page_fault(access_type, addr));
        }

        // Pointer to next level if R=X=0.
        if r == 0 && x == 0 {
            if i == 0 {
                return Err(page_fault(access_type, addr));
            }
            let ppn = (pte >> 10) & 0xFFF_FFFF_FFFF;
            a = ppn * PAGE_SIZE;
            continue;
        }

        // Leaf PTE.
        let mut entry = TlbEntry {
            vpn: vpn_full,
            ppn: (pte >> 10) & 0xFFF_FFFF_FFFF,
            valid: true,
            asid: current_asid,
            global: (pte >> 5) & 1 != 0, // G bit
            r: r != 0,
            w: w != 0,
            x: x != 0,
            u: (pte >> 4) & 1 != 0,
            a: (pte >> 6) & 1 != 0,
            d: (pte >> 7) & 1 != 0,
        };

        if !check_permission_tlb(mode, mstatus, &entry, access_type) {
            return Err(page_fault(access_type, addr));
        }

        // Superpage alignment checks (Sv39/48 spec).
        if i > 0 {
            let ppn_mask = (1 << (9 * i)) - 1;
            let ppn = (pte >> 10) & 0xFFF_FFFF_FFFF;
            if (ppn & ppn_mask) != 0 {
                return Err(page_fault(access_type, addr));
            }
        }

        // A/D bit updates: set in memory and in the cached entry.
        let mut new_pte = pte;
        let mut update = false;

        if !entry.a {
            new_pte |= 1 << 6;
            entry.a = true;
            update = true;
        }
        if matches!(access_type, AccessType::Store) && !entry.d {
            new_pte |= 1 << 7;
            entry.d = true;
            update = true;
        }

        if update {
            if bus.store(pte_addr, 8, new_pte).is_err() {
                return Err(access_fault(access_type, addr));
            }
        }

        let offset_in_page = addr & 0xFFF;

        // Construct final PPN, filling low parts from the VA on superpages.
        let ppn = (pte >> 10) & 0xFFF_FFFF_FFFF;
        let vpn_mask = (1 << (9 * i)) - 1;
        let result_ppn = (ppn & !vpn_mask) | ((addr >> 12) & vpn_mask);

        entry.ppn = result_ppn;
        tlb.insert(entry);

        let pa = (result_ppn << 12) | offset_in_page;
        return Ok(pa);
    }

    Err(page_fault(access_type, addr))
}

fn check_permission_tlb(mode: Mode, mstatus: u64, entry: &TlbEntry, access_type: AccessType) -> bool {
    let mxr = (mstatus >> 19) & 1;
    let sum = (mstatus >> 18) & 1;

    match mode {
        Mode::Supervisor => {
            if entry.u {
                if matches!(access_type, AccessType::Instruction) {
                    return false;
                }
                if sum == 0 {
                    return false;
                }
            }
        }
        Mode::User => {
            if !entry.u {
                return false;
            }
        }
        Mode::Machine => {}
    }

    match access_type {
        AccessType::Instruction => entry.x,
        AccessType::Store => entry.w,
        AccessType::Load => {
            if entry.r {
                true
            } else {
                mxr == 1 && entry.x
            }
        }
    }
}

fn page_fault(access_type: AccessType, addr: u64) -> Trap {
    match access_type {
        AccessType::Instruction => Trap::InstructionPageFault(addr),
        AccessType::Load => Trap::LoadPageFault(addr),
        AccessType::Store => Trap::StorePageFault(addr),
    }
}

fn access_fault(access_type: AccessType, addr: u64) -> Trap {
    match access_type {
        AccessType::Instruction => Trap::InstructionAccessFault(addr),
        AccessType::Load => Trap::LoadAccessFault(addr),
        AccessType::Store => Trap::StoreAccessFault(addr),
    }
}
</file>

<file path="riscv-vm/src/net_libp2p.rs">
//! libp2p network backend for connecting to the QUIC relay.
//!
//! This backend tunnels Ethernet frames over libp2p gossipsub,
//! enabling peer-to-peer networking with NAT traversal support.
//!
//! Includes a virtual gateway that responds to ARP requests for 10.0.2.2,
//! enabling local ping testing without requiring another peer.

use crate::net::NetworkBackend;
use std::sync::mpsc::{channel, Receiver, Sender, TryRecvError};
use std::sync::{Arc, Mutex};

#[cfg(not(target_arch = "wasm32"))]
mod native {
    use super::*;
    use futures::StreamExt;
    use libp2p::{
        gossipsub::{self, IdentTopic, MessageAuthenticity},
        identify,
        identity::Keypair,
        noise,
        ping,
        relay,
        swarm::{NetworkBehaviour, SwarmEvent},
        tcp, yamux, Multiaddr, PeerId, SwarmBuilder,
    };
    use std::collections::VecDeque;
    use std::thread;
    use std::time::Duration;

    /// Gossipsub topic for VM Ethernet frames
    const VM_TOPIC: &str = "riscv-vm";

    /// Maximum number of packets to buffer
    const MAX_RX_QUEUE_SIZE: usize = 256;

    /// Virtual gateway configuration
    /// The gateway responds to ARP requests and ICMP pings, simulating a router
    const GATEWAY_IP: [u8; 4] = [10, 0, 2, 2];
    const GATEWAY_MAC: [u8; 6] = [0x52, 0x54, 0x00, 0x12, 0x34, 0x56]; // Virtual gateway MAC

    /// Network behaviour for the VM client
    #[derive(NetworkBehaviour)]
    struct VmClientBehaviour {
        /// Gossipsub for pub/sub messaging (Ethernet frames)
        gossipsub: gossipsub::Behaviour,

        /// Circuit relay client for NAT traversal
        relay_client: relay::client::Behaviour,

        /// Identify protocol
        identify: identify::Behaviour,

        /// Ping for liveness
        ping: ping::Behaviour,
    }

    /// Commands sent to the libp2p event loop
    enum Command {
        Send(Vec<u8>),
        Shutdown,
    }

    /// Pending reply with delivery time
    struct PendingReply {
        data: Vec<u8>,
        deliver_at: std::time::Instant,
    }

    /// Check if an Ethernet frame is an ARP request for the gateway IP
    fn is_arp_request_for_gateway(frame: &[u8]) -> bool {
        // Minimum ARP frame: 14 (eth) + 28 (arp) = 42 bytes
        if frame.len() < 42 {
            return false;
        }
        // Check ethertype is ARP (0x0806)
        if frame[12] != 0x08 || frame[13] != 0x06 {
            return false;
        }
        // Check ARP operation is request (1)
        if frame[20] != 0x00 || frame[21] != 0x01 {
            return false;
        }
        // Check target protocol address is gateway IP
        frame[38..42] == GATEWAY_IP
    }

    /// Generate an ARP reply for the gateway
    fn generate_arp_reply(request: &[u8]) -> Vec<u8> {
        let mut reply = vec![0u8; 42];
        
        // Ethernet header
        reply[0..6].copy_from_slice(&request[6..12]); // dst = sender's MAC
        reply[6..12].copy_from_slice(&GATEWAY_MAC);    // src = gateway MAC
        reply[12..14].copy_from_slice(&[0x08, 0x06]); // ethertype = ARP
        
        // ARP header
        reply[14..16].copy_from_slice(&[0x00, 0x01]); // hardware type = ethernet
        reply[16..18].copy_from_slice(&[0x08, 0x00]); // protocol type = IPv4
        reply[18] = 6;                                 // hardware addr len
        reply[19] = 4;                                 // protocol addr len
        reply[20..22].copy_from_slice(&[0x00, 0x02]); // operation = reply
        reply[22..28].copy_from_slice(&GATEWAY_MAC);   // sender hardware addr = gateway MAC
        reply[28..32].copy_from_slice(&GATEWAY_IP);    // sender protocol addr = gateway IP
        reply[32..38].copy_from_slice(&request[22..28]); // target hardware addr = requestor's MAC
        reply[38..42].copy_from_slice(&request[28..32]); // target protocol addr = requestor's IP
        
        reply
    }

    /// Check if a frame is an ICMP echo request (ping) to the gateway
    fn is_icmp_echo_request_to_gateway(frame: &[u8]) -> bool {
        // Minimum: 14 (eth) + 20 (ip) + 8 (icmp) = 42 bytes
        if frame.len() < 42 {
            return false;
        }
        // Check ethertype is IPv4 (0x0800)
        if frame[12] != 0x08 || frame[13] != 0x00 {
            return false;
        }
        // Check IP protocol is ICMP (1)
        if frame[23] != 1 {
            return false;
        }
        // Check destination IP is gateway
        if frame[30..34] != GATEWAY_IP {
            return false;
        }
        // Check ICMP type is echo request (8)
        frame[34] == 8
    }

    /// Generate an ICMP echo reply from the gateway
    fn generate_icmp_reply(request: &[u8]) -> Vec<u8> {
        let mut reply = request.to_vec();
        
        // Swap Ethernet addresses
        reply[0..6].copy_from_slice(&request[6..12]); // dst = sender's MAC
        reply[6..12].copy_from_slice(&GATEWAY_MAC);    // src = gateway MAC
        
        // Swap IP addresses (src is at offset 26, dst at offset 30)
        let orig_src_ip: [u8; 4] = request[26..30].try_into().unwrap();
        let orig_dst_ip: [u8; 4] = request[30..34].try_into().unwrap();
        reply[26..30].copy_from_slice(&orig_dst_ip); // src IP = gateway (was dst)
        reply[30..34].copy_from_slice(&orig_src_ip); // dst IP = original sender
        
        // Recalculate IP header checksum (bytes 24-25 in frame = offset 10-11 in IP header)
        // First clear the old checksum
        reply[24] = 0;
        reply[25] = 0;
        // Calculate checksum over IP header (20 bytes starting at offset 14)
        let ip_checksum = compute_checksum(&reply[14..34]);
        reply[24] = (ip_checksum >> 8) as u8;
        reply[25] = (ip_checksum & 0xff) as u8;
        
        // Change ICMP type to echo reply (0)
        reply[34] = 0;
        
        // Recalculate ICMP checksum
        // Clear old checksum
        reply[36] = 0;
        reply[37] = 0;
        
        // Calculate new checksum over ICMP message
        let icmp_start = 34;
        let icmp_data = &reply[icmp_start..];
        let checksum = compute_checksum(icmp_data);
        reply[36] = (checksum >> 8) as u8;
        reply[37] = (checksum & 0xff) as u8;
        
        reply
    }

    /// Compute Internet checksum (one's complement sum)
    fn compute_checksum(data: &[u8]) -> u16 {
        let mut sum: u32 = 0;
        let mut i = 0;
        while i + 1 < data.len() {
            sum += u16::from_be_bytes([data[i], data[i + 1]]) as u32;
            i += 2;
        }
        if i < data.len() {
            sum += (data[i] as u32) << 8;
        }
        while sum > 0xFFFF {
            sum = (sum & 0xFFFF) + (sum >> 16);
        }
        !(sum as u16)
    }

    /// libp2p network backend for native platforms.
    pub struct Libp2pBackend {
        /// Relay multiaddress (e.g., /ip4/127.0.0.1/udp/4001/quic-v1/p2p/PEER_ID)
        relay_addr: String,
        /// MAC address for this VM
        mac: [u8; 6],
        /// Channel to send commands to the event loop
        cmd_tx: Option<Sender<Command>>,
        /// Channel to receive packets from the event loop
        rx_from_swarm: Option<Receiver<Vec<u8>>>,
        /// Connection state
        connected: Arc<Mutex<bool>>,
        /// Error message if any
        error_message: Arc<Mutex<Option<String>>>,
        /// Local peer ID
        local_peer_id: Arc<Mutex<Option<PeerId>>>,
        /// Queue for locally-generated gateway responses (ARP replies, ICMP replies)
        /// Uses Arc<Mutex> because `send` takes &self, not &mut self
        /// Contains PendingReply with delivery time to simulate network latency
        local_reply_queue: Arc<Mutex<VecDeque<PendingReply>>>,
    }

    impl Libp2pBackend {
        pub fn new(relay_addr: &str) -> Self {
            // Generate a random MAC based on relay address hash
            let mut mac = [0x52, 0x54, 0x00, 0x00, 0x00, 0x00];
            let hash: u32 = relay_addr
                .bytes()
                .fold(0u32, |acc, b| acc.wrapping_mul(31).wrapping_add(b as u32));
            mac[3] = ((hash >> 16) & 0xff) as u8;
            mac[4] = ((hash >> 8) & 0xff) as u8;
            mac[5] = (hash & 0xff) as u8;

            Self {
                relay_addr: relay_addr.to_string(),
                mac,
                cmd_tx: None,
                rx_from_swarm: None,
                connected: Arc::new(Mutex::new(false)),
                error_message: Arc::new(Mutex::new(None)),
                local_peer_id: Arc::new(Mutex::new(None)),
                local_reply_queue: Arc::new(Mutex::new(VecDeque::new())),
            }
        }

        /// Check if connected to the relay
        pub fn is_connected(&self) -> bool {
            *self.connected.lock().unwrap()
        }

        /// Get any error message
        pub fn error_message(&self) -> Option<String> {
            self.error_message.lock().unwrap().clone()
        }

        /// Get local peer ID
        pub fn local_peer_id(&self) -> Option<String> {
            self.local_peer_id.lock().unwrap().map(|p| p.to_string())
        }

        /// Run the libp2p event loop in a separate thread
        fn run_event_loop(
            relay_addr: String,
            cmd_rx: Receiver<Command>,
            packet_tx: Sender<Vec<u8>>,
            connected: Arc<Mutex<bool>>,
            error_message: Arc<Mutex<Option<String>>>,
            local_peer_id_store: Arc<Mutex<Option<PeerId>>>,
        ) {
            // Create a tokio runtime for this thread
            let rt = match tokio::runtime::Runtime::new() {
                Ok(rt) => rt,
                Err(e) => {
                    *error_message.lock().unwrap() = Some(format!("Failed to create runtime: {}", e));
                    return;
                }
            };

            rt.block_on(async move {
                // Generate keypair
                let local_key = Keypair::generate_ed25519();
                let local_peer_id = PeerId::from(local_key.public());
                *local_peer_id_store.lock().unwrap() = Some(local_peer_id);
                log::info!("[Libp2pBackend] Local peer ID: {}", local_peer_id);

                // Build the swarm step by step
                let tcp_builder = match SwarmBuilder::with_existing_identity(local_key.clone())
                    .with_tokio()
                    .with_tcp(
                        tcp::Config::default(),
                        noise::Config::new,
                        yamux::Config::default,
                    ) {
                    Ok(b) => b,
                    Err(e) => {
                        *error_message.lock().unwrap() = Some(format!("Failed to setup TCP: {}", e));
                        return;
                    }
                };

                let quic_builder = tcp_builder.with_quic();

                let relay_builder = match quic_builder.with_relay_client(noise::Config::new, yamux::Config::default) {
                    Ok(b) => b,
                    Err(e) => {
                        *error_message.lock().unwrap() = Some(format!("Failed to setup relay client: {}", e));
                        return;
                    }
                };

                let behaviour_builder = match relay_builder.with_behaviour(|keypair, relay_client| {
                    // Gossipsub configuration
                    let gossipsub_config = gossipsub::ConfigBuilder::default()
                        .heartbeat_interval(Duration::from_secs(10))
                        .validation_mode(gossipsub::ValidationMode::Permissive)
                        .message_id_fn(|msg| {
                            let mut hasher = std::collections::hash_map::DefaultHasher::new();
                            std::hash::Hash::hash(&msg.data, &mut hasher);
                            std::hash::Hash::hash(&msg.source, &mut hasher);
                            std::hash::Hash::hash(&std::time::Instant::now(), &mut hasher);
                            gossipsub::MessageId::from(std::hash::Hasher::finish(&hasher).to_string())
                        })
                        .build()
                        .expect("Valid gossipsub config");

                    let gossipsub = gossipsub::Behaviour::new(
                        MessageAuthenticity::Signed(keypair.clone()),
                        gossipsub_config,
                    )
                    .expect("Valid gossipsub behaviour");

                    // Identify
                    let identify = identify::Behaviour::new(identify::Config::new(
                        "/riscv-vm-client/1.0.0".to_string(),
                        keypair.public(),
                    ));

                    VmClientBehaviour {
                        gossipsub,
                        relay_client,
                        identify,
                        ping: ping::Behaviour::new(ping::Config::new()),
                    }
                }) {
                    Ok(b) => b,
                    Err(e) => {
                        *error_message.lock().unwrap() = Some(format!("Failed to setup behaviour: {}", e));
                        return;
                    }
                };

                let mut swarm = behaviour_builder
                    .with_swarm_config(|cfg| cfg.with_idle_connection_timeout(Duration::from_secs(60)))
                    .build();

                // Subscribe to VM topic
                let topic = IdentTopic::new(VM_TOPIC);
                if let Err(e) = swarm.behaviour_mut().gossipsub.subscribe(&topic) {
                    *error_message.lock().unwrap() = Some(format!("Failed to subscribe: {}", e));
                    return;
                }
                log::info!("[Libp2pBackend] Subscribed to topic: {}", VM_TOPIC);

                // Parse and dial relay address
                let relay_multiaddr: Multiaddr = match relay_addr.parse() {
                    Ok(addr) => addr,
                    Err(e) => {
                        *error_message.lock().unwrap() = Some(format!("Invalid relay address: {}", e));
                        return;
                    }
                };

                log::info!("[Libp2pBackend] Dialing relay: {}", relay_multiaddr);
                if let Err(e) = swarm.dial(relay_multiaddr.clone()) {
                    *error_message.lock().unwrap() = Some(format!("Failed to dial relay: {}", e));
                    return;
                }

                // Event loop
                let mut pending_packets: VecDeque<Vec<u8>> = VecDeque::new();

                loop {
                    // Check for commands (non-blocking)
                    match cmd_rx.try_recv() {
                        Ok(Command::Send(data)) => {
                            if *connected.lock().unwrap() {
                                // Publish to gossipsub
                                if let Err(e) = swarm.behaviour_mut().gossipsub.publish(topic.clone(), data) {
                                    log::warn!("[Libp2pBackend] Failed to publish: {}", e);
                                }
                            } else {
                                // Queue until connected
                                if pending_packets.len() < MAX_RX_QUEUE_SIZE {
                                    pending_packets.push_back(data);
                                }
                            }
                        }
                        Ok(Command::Shutdown) => {
                            log::info!("[Libp2pBackend] Shutting down");
                            break;
                        }
                        Err(TryRecvError::Disconnected) => {
                            log::info!("[Libp2pBackend] Command channel closed");
                            break;
                        }
                        Err(TryRecvError::Empty) => {}
                    }

                    // Process swarm events with timeout
                    tokio::select! {
                        event = swarm.select_next_some() => {
                            match event {
                                SwarmEvent::ConnectionEstablished { peer_id, .. } => {
                                    log::info!("[Libp2pBackend] Connected to {}", peer_id);
                                    *connected.lock().unwrap() = true;
                                    *error_message.lock().unwrap() = None;

                                    // Flush pending packets
                                    while let Some(data) = pending_packets.pop_front() {
                                        if let Err(e) = swarm.behaviour_mut().gossipsub.publish(topic.clone(), data) {
                                            log::warn!("[Libp2pBackend] Failed to publish queued packet: {}", e);
                                        }
                                    }
                                }

                                SwarmEvent::ConnectionClosed { peer_id, cause, .. } => {
                                    log::info!("[Libp2pBackend] Disconnected from {}: {:?}", peer_id, cause);
                                    // Only mark as disconnected if we have no other connections
                                    if swarm.network_info().num_peers() == 0 {
                                        *connected.lock().unwrap() = false;
                                    }
                                }

                                SwarmEvent::Behaviour(VmClientBehaviourEvent::Gossipsub(
                                    gossipsub::Event::Message { message, propagation_source, .. }
                                )) => {
                                    // Don't process our own messages
                                    if message.source != Some(local_peer_id) {
                                        log::debug!(
                                            "[Libp2pBackend] Received {} bytes from {}",
                                            message.data.len(),
                                            propagation_source
                                        );
                                        let _ = packet_tx.send(message.data);
                                    }
                                }

                                SwarmEvent::Behaviour(VmClientBehaviourEvent::Gossipsub(
                                    gossipsub::Event::Subscribed { peer_id, topic }
                                )) => {
                                    log::info!("[Libp2pBackend] Peer {} subscribed to {}", peer_id, topic);
                                }

                                SwarmEvent::OutgoingConnectionError { peer_id, error, .. } => {
                                    if let Some(peer) = peer_id {
                                        log::warn!("[Libp2pBackend] Connection error to {}: {}", peer, error);
                                    }
                                    *error_message.lock().unwrap() = Some(format!("Connection error: {}", error));
                                }

                                _ => {}
                            }
                        }

                        _ = tokio::time::sleep(Duration::from_millis(10)) => {
                            // Timeout to allow checking commands
                        }
                    }
                }
            });
        }
    }

    impl NetworkBackend for Libp2pBackend {
        fn init(&mut self) -> Result<(), String> {
            log::info!("[Libp2pBackend] Connecting to {}", self.relay_addr);

            let (cmd_tx, cmd_rx) = channel();
            let (packet_tx, packet_rx) = channel();

            self.cmd_tx = Some(cmd_tx);
            self.rx_from_swarm = Some(packet_rx);

            let relay_addr = self.relay_addr.clone();
            let connected = self.connected.clone();
            let error_message = self.error_message.clone();
            let local_peer_id = self.local_peer_id.clone();

            // Spawn the event loop in a separate thread
            thread::spawn(move || {
                Self::run_event_loop(relay_addr, cmd_rx, packet_tx, connected, error_message, local_peer_id);
            });

            // Wait a bit for connection (non-blocking init)
            for _ in 0..50 {
                if *self.connected.lock().unwrap() {
                    log::info!("[Libp2pBackend] Connected successfully!");
                    return Ok(());
                }
                if let Some(ref err) = *self.error_message.lock().unwrap() {
                    return Err(err.clone());
                }
                std::thread::sleep(Duration::from_millis(100));
            }

            // Connection is async, so we return Ok even if not connected yet
            log::info!("[Libp2pBackend] Initialization started (connection pending)");
            Ok(())
        }

        fn recv(&mut self) -> Result<Option<Vec<u8>>, String> {
            // First, check for locally-generated gateway responses (ARP replies, ICMP replies)
            // Only return replies that are ready to be delivered (simulates network latency)
            {
                let mut queue = self.local_reply_queue.lock().unwrap();
                let now = std::time::Instant::now();
                // Check if the first pending reply is ready
                if let Some(pending) = queue.front() {
                    if now >= pending.deliver_at {
                        let reply = queue.pop_front().unwrap();
                        log::debug!("[Libp2pBackend] recv() returning {} bytes from local gateway reply", reply.data.len());
                        return Ok(Some(reply.data));
                    }
                }
            }
            
            // Then check for packets from the network
            if let Some(ref rx) = self.rx_from_swarm {
                match rx.try_recv() {
                    Ok(data) => {
                        log::trace!("[Libp2pBackend] recv() returning {} bytes", data.len());
                        Ok(Some(data))
                    }
                    Err(TryRecvError::Empty) => Ok(None),
                    Err(TryRecvError::Disconnected) => Err("libp2p disconnected".to_string()),
                }
            } else {
                Ok(None)
            }
        }

        fn send(&self, buf: &[u8]) -> Result<(), String> {
            let now = std::time::Instant::now();
            
            // Check if this is an ARP request for the gateway - if so, generate a local reply
            if is_arp_request_for_gateway(buf) {
                let reply = generate_arp_reply(buf);
                log::info!("[Libp2pBackend] Intercepted ARP request for gateway, queueing ARP reply");
                // ARP replies are delivered quickly (1ms simulated latency)
                let pending = PendingReply {
                    data: reply,
                    deliver_at: now + Duration::from_millis(1),
                };
                self.local_reply_queue.lock().unwrap().push_back(pending);
                // Don't send ARP requests to the network - just handle locally
                return Ok(());
            }
            
            // Check if this is an ICMP ping to the gateway - if so, generate a local reply
            if is_icmp_echo_request_to_gateway(buf) {
                let reply = generate_icmp_reply(buf);
                log::info!("[Libp2pBackend] Intercepted ICMP ping to gateway, queueing ICMP reply");
                // ICMP replies have a small delay (10ms simulated latency)
                // This ensures the kernel has finished sending before the reply arrives
                let pending = PendingReply {
                    data: reply,
                    deliver_at: now + Duration::from_millis(10),
                };
                self.local_reply_queue.lock().unwrap().push_back(pending);
                // Don't send pings to gateway to the network - just handle locally
                return Ok(());
            }
            
            // For all other packets, send to the network via libp2p
            if let Some(ref tx) = self.cmd_tx {
                tx.send(Command::Send(buf.to_vec()))
                    .map_err(|e| format!("Send failed: {}", e))
            } else {
                Err("libp2p not initialized".to_string())
            }
        }

        fn mac_address(&self) -> [u8; 6] {
            self.mac
        }
    }

    impl Drop for Libp2pBackend {
        fn drop(&mut self) {
            if let Some(ref tx) = self.cmd_tx {
                let _ = tx.send(Command::Shutdown);
            }
        }
    }
}

#[cfg(not(target_arch = "wasm32"))]
pub use native::Libp2pBackend;

// For WASM, we'll still use WebSocket since browser libp2p requires different setup
// The relay can bridge WebSocket clients to the libp2p network
#[cfg(target_arch = "wasm32")]
pub use crate::net_ws::WsBackend as Libp2pBackend;
</file>

<file path="riscv-vm/src/net_tap.rs">
//! TAP network backend for native (non-WASM) builds.
//!
//! This module provides a network backend that uses a TAP interface
//! to communicate with the host network stack on Linux/macOS.

use crate::net::NetworkBackend;
use std::io::Write;
use std::os::unix::io::AsRawFd;

/// TAP network backend using the tun-tap crate.
pub struct TapBackend {
    name: String,
    iface: Option<tun_tap::Iface>,
    mac: [u8; 6],
}

impl TapBackend {
    /// Create a new TAP backend with the given interface name.
    /// 
    /// The interface will not be opened until `init()` is called.
    /// Creating the TAP interface typically requires root privileges.
    /// 
    /// # Example
    /// ```ignore
    /// let mut tap = TapBackend::new("tap0");
    /// tap.init()?;
    /// ```
    pub fn new(name: &str) -> Self {
        Self {
            name: name.to_string(),
            iface: None,
            // Default MAC - locally administered, unicast
            mac: [0x52, 0x54, 0x00, 0x12, 0x34, 0x56],
        }
    }
    
    /// Create a TAP backend with a custom MAC address.
    pub fn with_mac(name: &str, mac: [u8; 6]) -> Self {
        Self {
            name: name.to_string(),
            iface: None,
            mac,
        }
    }
    
    /// Set the interface to non-blocking mode.
    fn set_nonblocking(&self) -> Result<(), String> {
        if let Some(ref iface) = self.iface {
            let fd = iface.as_raw_fd();
            
            // Get current flags
            let flags = unsafe { libc::fcntl(fd, libc::F_GETFL) };
            if flags < 0 {
                return Err(format!(
                    "Failed to get fd flags: {}",
                    std::io::Error::last_os_error()
                ));
            }
            
            // Set non-blocking flag
            let result = unsafe { libc::fcntl(fd, libc::F_SETFL, flags | libc::O_NONBLOCK) };
            if result < 0 {
                return Err(format!(
                    "Failed to set non-blocking mode: {}",
                    std::io::Error::last_os_error()
                ));
            }
        }
        Ok(())
    }
}

impl NetworkBackend for TapBackend {
    fn init(&mut self) -> Result<(), String> {
        // Open the TAP interface
        let iface = tun_tap::Iface::without_packet_info(&self.name, tun_tap::Mode::Tap)
            .map_err(|e| format!("Failed to open TAP interface '{}': {}", self.name, e))?;
        
        self.iface = Some(iface);
        
        // Set non-blocking mode for recv polling
        self.set_nonblocking()?;
        
        log::info!("[TapBackend] Opened TAP interface '{}'", self.name);
        Ok(())
    }
    
    fn recv(&mut self) -> Result<Option<Vec<u8>>, String> {
        let iface = self.iface.as_mut().ok_or("TAP interface not initialized")?;
        
        // Buffer for maximum Ethernet frame size (MTU 1500 + headers)
        let mut buf = vec![0u8; 1514];
        
        match iface.recv(&mut buf) {
            Ok(n) => {
                buf.truncate(n);
                log::trace!("[TapBackend] Received {} byte packet", n);
                Ok(Some(buf))
            }
            Err(e) => {
                // Check if it's a would-block error (no data available)
                if e.kind() == std::io::ErrorKind::WouldBlock {
                    Ok(None)
                } else {
                    Err(format!("TAP recv error: {}", e))
                }
            }
        }
    }
    
    fn send(&self, buf: &[u8]) -> Result<(), String> {
        let iface = self.iface.as_ref().ok_or("TAP interface not initialized")?;
        
        // tun_tap::Iface doesn't implement Send on the write side,
        // so we need to use the raw fd for writing. However, for simplicity
        // we'll just write directly. Note: this may need adjustment for
        // thread safety in the future.
        let mut iface_clone = unsafe {
            // This is safe because we're only writing and the fd is valid
            std::fs::File::from_raw_fd(std::os::unix::io::AsRawFd::as_raw_fd(iface))
        };
        
        let result = iface_clone.write_all(buf);
        
        // Don't drop the file - it doesn't own the fd
        std::mem::forget(iface_clone);
        
        result.map_err(|e| format!("TAP send error: {}", e))?;
        log::trace!("[TapBackend] Sent {} byte packet", buf.len());
        Ok(())
    }
    
    fn mac_address(&self) -> [u8; 6] {
        self.mac
    }
}

// Manual implementation to handle the Iface not being Send
unsafe impl Send for TapBackend {}

use std::os::unix::io::FromRawFd;

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_tap_backend_creation() {
        let tap = TapBackend::new("test0");
        assert_eq!(tap.name, "test0");
        assert!(tap.iface.is_none());
    }
    
    #[test]
    fn test_tap_backend_custom_mac() {
        let mac = [0xAA, 0xBB, 0xCC, 0xDD, 0xEE, 0xFF];
        let tap = TapBackend::with_mac("test0", mac);
        assert_eq!(tap.mac_address(), mac);
    }
    
    // Note: Actually opening a TAP interface requires root privileges,
    // so we can't test init() in regular unit tests.
}
</file>

<file path="riscv-vm/src/net_ws.rs">
//! WebSocket network backend for cross-platform networking.
//!
//! This backend tunnels Ethernet frames over WebSocket, enabling
//! networking on platforms without TAP support (macOS, WASM/browser).

use crate::net::NetworkBackend;
use std::sync::mpsc::{channel, Receiver, Sender, TryRecvError};
use std::sync::{Arc, Mutex};

#[cfg(not(target_arch = "wasm32"))]
mod native {
    use super::*;
    use std::thread;
    use tungstenite::{connect, Message, WebSocket};
    use tungstenite::stream::MaybeTlsStream;
    use std::net::TcpStream;

    /// WebSocket backend for native platforms (macOS, Linux, Windows).
    pub struct WsBackend {
        url: String,
        mac: [u8; 6],
        tx_to_ws: Option<Sender<Vec<u8>>>,
        rx_from_ws: Option<Receiver<Vec<u8>>>,
        connected: Arc<Mutex<bool>>,
        error_message: Arc<Mutex<Option<String>>>,
    }

    impl WsBackend {
        pub fn new(url: &str) -> Self {
            // Generate a random-ish MAC based on URL hash
            let mut mac = [0x52, 0x54, 0x00, 0x00, 0x00, 0x00];
            let hash: u32 = url.bytes().fold(0u32, |acc, b| acc.wrapping_mul(31).wrapping_add(b as u32));
            mac[3] = ((hash >> 16) & 0xff) as u8;
            mac[4] = ((hash >> 8) & 0xff) as u8;
            mac[5] = (hash & 0xff) as u8;
            
            Self {
                url: url.to_string(),
                mac,
                tx_to_ws: None,
                rx_from_ws: None,
                connected: Arc::new(Mutex::new(false)),
                error_message: Arc::new(Mutex::new(None)),
            }
        }
        
        /// Check if the backend is currently connected.
        pub fn is_connected(&self) -> bool {
            *self.connected.lock().unwrap()
        }
        
        /// Get any error message from the connection.
        pub fn error_message(&self) -> Option<String> {
            self.error_message.lock().unwrap().clone()
        }

        /// Reader thread - reads from WebSocket and sends to channel
        fn reader_thread(
            mut socket: WebSocket<MaybeTlsStream<TcpStream>>,
            tx_received: Sender<Vec<u8>>,
            rx_to_send: Receiver<Vec<u8>>,
            connected: Arc<Mutex<bool>>,
        ) {
            // Set socket to blocking mode for reliable reads
            if let MaybeTlsStream::Plain(ref stream) = *socket.get_ref() {
                let _ = stream.set_nonblocking(false);
                // Set a read timeout so we can also check for outgoing messages
                let _ = stream.set_read_timeout(Some(std::time::Duration::from_millis(10)));
            }
            
            loop {
                // First, check if we have outgoing messages to send
                loop {
                    match rx_to_send.try_recv() {
                        Ok(data) => {
                            log::trace!("[WsBackend] Sending {} bytes", data.len());
                            if let Err(e) = socket.send(Message::Binary(data.into())) {
                                log::warn!("[WsBackend] Send error: {}", e);
                                *connected.lock().unwrap() = false;
                                return;
                            }
                        }
                        Err(TryRecvError::Empty) => break,
                        Err(TryRecvError::Disconnected) => {
                            log::info!("[WsBackend] Send channel closed, exiting");
                            *connected.lock().unwrap() = false;
                            return;
                        }
                    }
                }
                
                // Flush any pending writes
                if let Err(e) = socket.flush() {
                    if !matches!(e, tungstenite::Error::Io(ref io) if io.kind() == std::io::ErrorKind::WouldBlock) {
                        log::warn!("[WsBackend] Flush error: {}", e);
                    }
                }
                
                // Try to read from WebSocket
                match socket.read() {
                    Ok(Message::Binary(data)) => {
                        log::debug!("[WsBackend] Received {} bytes from relay", data.len());
                        if tx_received.send(data.into()).is_err() {
                            log::info!("[WsBackend] Receiver dropped, exiting");
                            *connected.lock().unwrap() = false;
                            return;
                        }
                    }
                    Ok(Message::Close(_)) => {
                        log::info!("[WsBackend] WebSocket closed by server");
                        *connected.lock().unwrap() = false;
                        return;
                    }
                    Ok(Message::Ping(data)) => {
                        // Respond to ping with pong
                        let _ = socket.send(Message::Pong(data));
                    }
                    Ok(_) => {} // Ignore text, pong
                    Err(tungstenite::Error::Io(ref e)) if e.kind() == std::io::ErrorKind::WouldBlock => {
                        // Timeout - no data available, continue loop
                    }
                    Err(tungstenite::Error::Io(ref e)) if e.kind() == std::io::ErrorKind::TimedOut => {
                        // Timeout - no data available, continue loop
                    }
                    Err(e) => {
                        log::warn!("[WsBackend] Read error: {}", e);
                        *connected.lock().unwrap() = false;
                        return;
                    }
                }
            }
        }
    }

    impl NetworkBackend for WsBackend {
        fn init(&mut self) -> Result<(), String> {
            log::info!("[WsBackend] Connecting to {}", self.url);
            
            let (socket, _response) = connect(&self.url)
                .map_err(|e| {
                    let msg = format!("Failed to connect: {}", e);
                    log::error!("[WsBackend] {}", msg);
                    *self.error_message.lock().unwrap() = Some(msg.clone());
                    msg
                })?;
            
            log::info!("[WsBackend] Connected successfully!");
            *self.connected.lock().unwrap() = true;
            *self.error_message.lock().unwrap() = None;
            
            let (tx_to_ws, rx_to_send) = channel();
            let (tx_received, rx_from_ws) = channel();
            
            self.tx_to_ws = Some(tx_to_ws);
            self.rx_from_ws = Some(rx_from_ws);
            
            let connected = self.connected.clone();
            
            thread::spawn(move || {
                Self::reader_thread(socket, tx_received, rx_to_send, connected);
            });
            
            log::info!("[WsBackend] Initialized successfully");
            Ok(())
        }

        fn recv(&mut self) -> Result<Option<Vec<u8>>, String> {
            if let Some(ref rx) = self.rx_from_ws {
                match rx.try_recv() {
                    Ok(data) => {
                        log::trace!("[WsBackend] recv() returning {} bytes", data.len());
                        Ok(Some(data))
                    }
                    Err(TryRecvError::Empty) => Ok(None),
                    Err(TryRecvError::Disconnected) => {
                        Err("WebSocket disconnected".to_string())
                    }
                }
            } else {
                Ok(None)
            }
        }

        fn send(&self, buf: &[u8]) -> Result<(), String> {
            if !*self.connected.lock().unwrap() {
                return Err("Not connected".to_string());
            }
            
            if let Some(ref tx) = self.tx_to_ws {
                tx.send(buf.to_vec()).map_err(|e| format!("Send failed: {}", e))
            } else {
                Err("WebSocket not initialized".to_string())
            }
        }

        fn mac_address(&self) -> [u8; 6] {
            self.mac
        }
    }
}

#[cfg(target_arch = "wasm32")]
mod wasm {
    use super::*;
    use wasm_bindgen::prelude::*;
    use wasm_bindgen::JsCast;
    use web_sys::{WebSocket, MessageEvent, ErrorEvent, CloseEvent, BinaryType};
    use js_sys::{ArrayBuffer, Uint8Array};
    use std::cell::RefCell;
    use std::rc::Rc;
    use std::collections::VecDeque;

    /// Maximum number of packets to buffer before dropping
    const MAX_RX_QUEUE_SIZE: usize = 256;
    
    /// Connection state for tracking
    #[derive(Clone, Copy, PartialEq, Eq, Debug)]
    pub enum ConnectionState {
        Disconnected,
        Connecting,
        Connected,
        Error,
    }

    /// WebSocket backend for WASM/browser.
    pub struct WsBackend {
        url: String,
        mac: [u8; 6],
        ws: Option<WebSocket>,
        rx_queue: Rc<RefCell<VecDeque<Vec<u8>>>>,
        state: Rc<RefCell<ConnectionState>>,
        error_message: Rc<RefCell<Option<String>>>,
        packets_dropped: Rc<RefCell<u64>>,
    }

    // WASM types are !Send by default, but we need Send for NetworkBackend.
    // This is safe because WASM is single-threaded.
    unsafe impl Send for WsBackend {}

    impl WsBackend {
        pub fn new(url: &str) -> Self {
            let mut mac = [0x52, 0x54, 0x00, 0x00, 0x00, 0x00];
            let hash: u32 = url.bytes().fold(0u32, |acc, b| acc.wrapping_mul(31).wrapping_add(b as u32));
            mac[3] = ((hash >> 16) & 0xff) as u8;
            mac[4] = ((hash >> 8) & 0xff) as u8;
            mac[5] = (hash & 0xff) as u8;
            
            Self {
                url: url.to_string(),
                mac,
                ws: None,
                rx_queue: Rc::new(RefCell::new(VecDeque::with_capacity(MAX_RX_QUEUE_SIZE))),
                state: Rc::new(RefCell::new(ConnectionState::Disconnected)),
                error_message: Rc::new(RefCell::new(None)),
                packets_dropped: Rc::new(RefCell::new(0)),
            }
        }
        
        /// Check if the backend is currently connected.
        pub fn is_connected(&self) -> bool {
            *self.state.borrow() == ConnectionState::Connected
        }
        
        /// Get the current connection state.
        pub fn connection_state(&self) -> ConnectionState {
            *self.state.borrow()
        }
        
        /// Get any error message.
        pub fn error_message(&self) -> Option<String> {
            self.error_message.borrow().clone()
        }
        
        /// Get the number of packets dropped due to buffer overflow.
        pub fn packets_dropped(&self) -> u64 {
            *self.packets_dropped.borrow()
        }
    }

    impl NetworkBackend for WsBackend {
        fn init(&mut self) -> Result<(), String> {
            *self.state.borrow_mut() = ConnectionState::Connecting;
            *self.error_message.borrow_mut() = None;
            
            let ws = WebSocket::new(&self.url)
                .map_err(|e| {
                    *self.state.borrow_mut() = ConnectionState::Error;
                    let msg = format!("Failed to create WebSocket: {:?}", e);
                    *self.error_message.borrow_mut() = Some(msg.clone());
                    msg
                })?;
            
            ws.set_binary_type(BinaryType::Arraybuffer);
            
            // Set up message handler with buffer overflow protection
            let rx_queue = self.rx_queue.clone();
            let packets_dropped = self.packets_dropped.clone();
            let onmessage_callback = Closure::<dyn FnMut(_)>::new(move |e: MessageEvent| {
                if let Ok(abuf) = e.data().dyn_into::<ArrayBuffer>() {
                    let array = Uint8Array::new(&abuf);
                    let mut data = vec![0u8; array.length() as usize];
                    array.copy_to(&mut data);
                    
                    let mut queue = rx_queue.borrow_mut();
                    // Handle buffer overflow - drop oldest packets if queue is full
                    while queue.len() >= MAX_RX_QUEUE_SIZE {
                        queue.pop_front();
                        *packets_dropped.borrow_mut() += 1;
                    }
                    queue.push_back(data);
                }
            });
            ws.set_onmessage(Some(onmessage_callback.as_ref().unchecked_ref()));
            onmessage_callback.forget();
            
            // Set up open handler
            let state_open = self.state.clone();
            let error_clear = self.error_message.clone();
            let onopen_callback = Closure::<dyn FnMut()>::new(move || {
                *state_open.borrow_mut() = ConnectionState::Connected;
                *error_clear.borrow_mut() = None;
                log::info!("[WsBackend] WebSocket connected!");
            });
            ws.set_onopen(Some(onopen_callback.as_ref().unchecked_ref()));
            onopen_callback.forget();
            
            // Set up error handler
            let state_error = self.state.clone();
            let error_message = self.error_message.clone();
            let onerror_callback = Closure::<dyn FnMut(_)>::new(move |e: ErrorEvent| {
                *state_error.borrow_mut() = ConnectionState::Error;
                let msg = format!("WebSocket error: {}", e.message());
                *error_message.borrow_mut() = Some(msg.clone());
                log::error!("[WsBackend] {}", msg);
            });
            ws.set_onerror(Some(onerror_callback.as_ref().unchecked_ref()));
            onerror_callback.forget();
            
            // Set up close handler
            let state_close = self.state.clone();
            let onclose_callback = Closure::<dyn FnMut(_)>::new(move |e: CloseEvent| {
                *state_close.borrow_mut() = ConnectionState::Disconnected;
                log::info!("[WsBackend] WebSocket closed (code: {}, reason: {})", 
                    e.code(), e.reason());
            });
            ws.set_onclose(Some(onclose_callback.as_ref().unchecked_ref()));
            onclose_callback.forget();
            
            self.ws = Some(ws);
            
            log::info!("[WsBackend] Initialized, connecting to {}", self.url);
            Ok(())
        }

        fn recv(&mut self) -> Result<Option<Vec<u8>>, String> {
            // Check connection state
            let state = *self.state.borrow();
            if state == ConnectionState::Error {
                if let Some(msg) = self.error_message.borrow().clone() {
                    return Err(msg);
                }
                return Err("WebSocket in error state".to_string());
            }
            
            Ok(self.rx_queue.borrow_mut().pop_front())
        }

        fn send(&self, buf: &[u8]) -> Result<(), String> {
            let state = *self.state.borrow();
            
            if state != ConnectionState::Connected {
                // Silently drop if not connected (don't spam errors)
                return Ok(());
            }
            
            if let Some(ref ws) = self.ws {
                let array = Uint8Array::from(buf);
                ws.send_with_array_buffer(&array.buffer())
                    .map_err(|e| format!("Send failed: {:?}", e))
            } else {
                Err("WebSocket not initialized".to_string())
            }
        }

        fn mac_address(&self) -> [u8; 6] {
            self.mac
        }
    }
}

// Re-export the appropriate backend based on target
#[cfg(not(target_arch = "wasm32"))]
pub use native::WsBackend;

#[cfg(target_arch = "wasm32")]
pub use wasm::WsBackend;
</file>

<file path="riscv-vm/src/net.rs">
//! Network backend abstraction for VirtIO networking.
//!
//! This module defines the `NetworkBackend` trait that abstracts packet I/O
//! to support both Host (TAP) and WASM (WebSocket) environments.

/// Trait for network backends that provide packet I/O.
/// 
/// Implementations must be `Send` to allow the backend to be used
/// across thread boundaries (e.g., when the VM runs in a separate thread).
pub trait NetworkBackend: Send {
    /// Initialize the backend (e.g., open TAP device or connect WebSocket).
    fn init(&mut self) -> Result<(), String>;
    
    /// Poll for an incoming packet. Returns None if no packet is available.
    /// This should be non-blocking.
    fn recv(&mut self) -> Result<Option<Vec<u8>>, String>;
    
    /// Send a packet.
    fn send(&self, buf: &[u8]) -> Result<(), String>;
    
    /// Get the MAC address of the backend (if available).
    /// Returns a default MAC if the backend doesn't have one.
    fn mac_address(&self) -> [u8; 6] {
        // Default MAC: locally administered, unicast
        [0x52, 0x54, 0x00, 0x12, 0x34, 0x56]
    }
}

/// A no-op network backend for testing purposes.
/// 
/// This backend discards all sent packets and never receives any packets.
pub struct DummyBackend {
    initialized: bool,
    mac: [u8; 6],
}

impl DummyBackend {
    pub fn new() -> Self {
        Self {
            initialized: false,
            mac: [0x52, 0x54, 0x00, 0x12, 0x34, 0x56],
        }
    }
    
    /// Create a dummy backend with a custom MAC address.
    pub fn with_mac(mac: [u8; 6]) -> Self {
        Self {
            initialized: false,
            mac,
        }
    }
}

impl Default for DummyBackend {
    fn default() -> Self {
        Self::new()
    }
}

impl NetworkBackend for DummyBackend {
    fn init(&mut self) -> Result<(), String> {
        self.initialized = true;
        log::debug!("[DummyBackend] Initialized (no-op)");
        Ok(())
    }
    
    fn recv(&mut self) -> Result<Option<Vec<u8>>, String> {
        // No packets ever available
        Ok(None)
    }
    
    fn send(&self, buf: &[u8]) -> Result<(), String> {
        // Discard packet, but log it for debugging
        log::trace!("[DummyBackend] Discarding {} byte packet", buf.len());
        Ok(())
    }
    
    fn mac_address(&self) -> [u8; 6] {
        self.mac
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_dummy_backend_init() {
        let mut backend = DummyBackend::new();
        assert!(backend.init().is_ok());
    }
    
    #[test]
    fn test_dummy_backend_recv_returns_none() {
        let mut backend = DummyBackend::new();
        backend.init().unwrap();
        assert!(backend.recv().unwrap().is_none());
    }
    
    #[test]
    fn test_dummy_backend_send_succeeds() {
        let backend = DummyBackend::new();
        assert!(backend.send(&[1, 2, 3, 4]).is_ok());
    }
    
    #[test]
    fn test_dummy_backend_mac_address() {
        let backend = DummyBackend::new();
        let mac = backend.mac_address();
        // Check locally administered bit is set (second bit of first byte)
        assert_eq!(mac[0] & 0x02, 0x02);
    }
    
    #[test]
    fn test_dummy_backend_custom_mac() {
        let custom_mac = [0xAA, 0xBB, 0xCC, 0xDD, 0xEE, 0xFF];
        let backend = DummyBackend::with_mac(custom_mac);
        assert_eq!(backend.mac_address(), custom_mac);
    }
}
</file>

<file path="riscv-vm/src/plic.rs">
use crate::dram::MemoryError;

pub const PLIC_BASE: u64 = 0x0C00_0000;
pub const PLIC_SIZE: u64 = 0x400_0000;

pub const UART_IRQ: u32 = 10;
pub const VIRTIO0_IRQ: u32 = 1;

const NUM_SOURCES: usize = 32;
const NUM_CONTEXTS: usize = 2; // 0 = M-mode hart0, 1 = S-mode hart0

pub struct Plic {
    pub priority: [u32; NUM_SOURCES],
    pub pending: u32, // Level-triggered mirror of device IRQ lines (bit per source)
    pub enable: [u32; NUM_CONTEXTS],
    pub threshold: [u32; NUM_CONTEXTS],
    pub active: [u32; NUM_CONTEXTS], // Per-context in-flight IRQs (claimed but not completed)
    pub debug: bool,
    // Multi-context arrays enable SMP readiness while preserving single-hart behavior.
}

impl Plic {
    pub fn new() -> Self {
        Self {
            priority: [0; NUM_SOURCES],
            pending: 0,
            enable: [0; NUM_CONTEXTS],
            threshold: [0; NUM_CONTEXTS],
            active: [0; NUM_CONTEXTS],
            debug: false,
        }
    }

    pub fn update_pending(&mut self, source: u32) {
        // Backward compatibility helper: set as pending (edge  level).
        // Bus.refresh_irqs() may later clear this if device line is low.
        if source < 32 {
            if self.debug {
                 eprintln!("[PLIC] Update Pending source={}", source);
            }
            self.pending |= 1 << source;
        }
    }

    // New: level-triggered source line setter
    pub fn set_source_level(&mut self, source: u32, level: bool) {
        if source >= 32 {
            return;
        }
        let was_pending = (self.pending & (1 << source)) != 0;
        if level {
            if self.debug && !was_pending {
                 eprintln!("[PLIC] IRQ Line High: source={} enable[0]=0x{:x} enable[1]=0x{:x} prio={}", 
                          source, self.enable[0], self.enable[1], self.priority[source as usize]);
            }
            self.pending |= 1 << source;
        } else {
            self.pending &= !(1 << source);
        }
    }

    pub fn load(&mut self, offset: u64, size: u64) -> Result<u64, MemoryError> {
        if size != 4 {
            return Ok(0); 
        }

        // Priority registers: 0x000000 .. 0x0000FC (4 bytes each)
        if offset < 0x001000 {
            let idx = (offset >> 2) as usize;
            if idx < NUM_SOURCES {
                return Ok(self.priority[idx] as u64);
            }
        }
        // Pending bits: 0x001000
        if offset == 0x001000 {
            return Ok(self.pending as u64);
        }
        // Enable per context: 0x002000 + 0x80 * context
        if offset >= 0x002000 && offset < 0x002000 + 0x80 * (NUM_CONTEXTS as u64) {
            let ctx = ((offset - 0x002000) / 0x80) as usize;
            let inner = (offset - 0x002000) % 0x80;
            if ctx < NUM_CONTEXTS && inner == 0 {
                return Ok(self.enable[ctx] as u64);
            }
        }
        // Context registers: threshold @ 0x200000 + 0x1000 * ctx, claim @ +4
        if offset >= 0x200000 {
            let ctx = ((offset - 0x200000) / 0x1000) as usize;
            if ctx < NUM_CONTEXTS {
                let base = 0x200000 + (0x1000 * ctx as u64);
                if offset == base {
                    return Ok(self.threshold[ctx] as u64);
                }
                if offset == base + 4 {
                    let claim = self.claim_interrupt_for(ctx);
                    if crate::plic::Plic::debug_trace() {
                        eprintln!("[PLIC] SCLAIM ctx={} -> {}", ctx, claim);
                    }
                    return Ok(claim as u64);
                }
            }
        }

        Ok(0)
    }

    fn debug_trace() -> bool {
        // Helper to check if trace logging is enabled without importing log everywhere if not needed
        // or just use std::env
        std::env::var("RUST_LOG").map(|s| s.contains("trace")).unwrap_or(false)
    }

    pub fn store(&mut self, offset: u64, size: u64, value: u64) -> Result<(), MemoryError> {
        if size != 4 {
            return Ok(());
        }
        let val = value as u32;

        // Priority
        if offset < 0x001000 {
            let idx = (offset >> 2) as usize;
            if idx < NUM_SOURCES {
                self.priority[idx] = val;
            }
            return Ok(());
        }
        // Pending is read-only to software
        if offset == 0x001000 {
            return Ok(());
        }
        // Enable per context
        if offset >= 0x002000 && offset < 0x002000 + 0x80 * (NUM_CONTEXTS as u64) {
            let ctx = ((offset - 0x002000) / 0x80) as usize;
            let inner = (offset - 0x002000) % 0x80;
            if ctx < NUM_CONTEXTS && inner == 0 {
                self.enable[ctx] = val;
            }
            return Ok(());
        }
        // Threshold / Claim-Complete per context
        if offset >= 0x200000 {
            let ctx = ((offset - 0x200000) / 0x1000) as usize;
            if ctx < NUM_CONTEXTS {
                let base = 0x200000 + (0x1000 * ctx as u64);
                if offset == base {
                    self.threshold[ctx] = val;
                    return Ok(());
                }
                if offset == base + 4 {
                    // Completion: value is the source ID to complete
                    let id = (val & 0xffff) as u32;
                    if id > 0 && (id as usize) < NUM_SOURCES {
                        // eprintln!("[PLIC] Completed IRQ {} for context {}", id, ctx);
                        self.active[ctx] &= !(1 << id);
                    }
                    return Ok(());
                }
            }
            return Ok(());
        }

        Ok(())
    }

    fn eligible_for_context(&self, source: usize, ctx: usize) -> bool {
        let pending = ((self.pending >> source) & 1) == 1;
        let enabled = ((self.enable[ctx] >> source) & 1) == 1;
        let over_threshold = self.priority[source] > self.threshold[ctx];
        let not_active = ((self.active[ctx] >> source) & 1) == 0;
        pending && enabled && over_threshold && not_active
    }

    pub fn claim_interrupt_for(&mut self, ctx: usize) -> u32 {
        let mut max_prio = 0;
        let mut max_id = 0;

        for i in 1..NUM_SOURCES {
            if self.eligible_for_context(i, ctx) {
                let prio = self.priority[i];
                if prio > max_prio {
                    max_prio = prio;
                    max_id = i as u32;
                }
            }
        }

        if max_id != 0 {
            // eprintln!("[PLIC] Claimed IRQ {} for context {} (prio {})", max_id, ctx, max_prio);
            // Mark in-flight for this context until completed.
            self.active[ctx] |= 1 << max_id;
        }
        max_id
    }
    
    pub fn is_interrupt_pending(&self) -> bool {
        // For current single-hart flow, report S-mode context (1) if available, else context 0.
        let ctx = if NUM_CONTEXTS > 1 { 1 } else { 0 };
        self.is_interrupt_pending_for(ctx)
    }

    pub fn is_interrupt_pending_for(&self, ctx: usize) -> bool {
        if ctx >= NUM_CONTEXTS {
            return false;
        }
        for i in 1..NUM_SOURCES {
            if self.eligible_for_context(i, ctx) {
                if self.debug {
                    eprintln!("[PLIC] Interrupt pending for ctx={} source={}", ctx, i);
                }
                return true;
            }
        }
        // Debug: show why no interrupt
        if self.debug && self.pending != 0 {
            for i in 1..NUM_SOURCES {
                let pending = ((self.pending >> i) & 1) == 1;
                let enabled = ((self.enable[ctx] >> i) & 1) == 1;
                let over_threshold = self.priority[i] > self.threshold[ctx];
                let not_active = ((self.active[ctx] >> i) & 1) == 0;
                if pending {
                    eprintln!("[PLIC] Source {} pending but not eligible for ctx={}: enabled={} over_threshold={} (prio={} > thresh={}) not_active={}", 
                             i, ctx, enabled, over_threshold, self.priority[i], self.threshold[ctx], not_active);
                }
            }
        }
        false
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_plic_claim_complete_context1() {
        let mut plic = Plic::new();
        // Priorities
        plic.priority[1] = 5;
        plic.priority[10] = 3;
        // Enable sources 1 and 10 for context 1 (S-mode)
        let enable_val = (1u32 << 1) | (1u32 << 10);
        let _ = plic.store(0x002000 + 0x80 * 1, 4, enable_val as u64);
        // Threshold 0 for context 1
        let _ = plic.store(0x200000 + 0x1000 * 1, 4, 0);
        // Assert device lines
        plic.set_source_level(1, true);
        plic.set_source_level(10, true);

        // Claim highest priority first (source 1)
        let id1 = plic.claim_interrupt_for(1);
        assert_eq!(id1, 1);
        // Next claim should return source 10 (since 1 is active)
        let id2 = plic.claim_interrupt_for(1);
        assert_eq!(id2, 10);
        // Complete source 1
        let _ = plic.store(0x200004 + 0x1000 * 1, 4, 1);
        // Claim again should allow source 1
        let id3 = plic.claim_interrupt_for(1);
        assert_eq!(id3, 1);
    }
}
</file>

<file path="riscv-vm/src/uart.rs">
use crate::dram::MemoryError;
use std::collections::VecDeque;

pub const UART_BASE: u64 = 0x1000_0000;
pub const UART_SIZE: u64 = 0x100;

// Registers (offset)
const RBR: u64 = 0x00; // Receiver Buffer (Read)
const THR: u64 = 0x00; // Transmitter Holding (Write)
const DLL: u64 = 0x00; // Divisor Latch LSB (Read/Write if DLAB=1)
const IER: u64 = 0x01; // Interrupt Enable
const DLM: u64 = 0x01; // Divisor Latch MSB (Read/Write if DLAB=1)
const IIR: u64 = 0x02; // Interrupt Identity (Read)
const FCR: u64 = 0x02; // FIFO Control (Write)
const LCR: u64 = 0x03; // Line Control
const MCR: u64 = 0x04; // Modem Control
const LSR: u64 = 0x05; // Line Status
const MSR: u64 = 0x06; // Modem Status
const SCR: u64 = 0x07; // Scratch

pub struct Uart {
    pub input: VecDeque<u8>,
    pub output: VecDeque<u8>,
    
    // Registers
    pub ier: u8,
    pub iir: u8,
    pub fcr: u8,
    pub lcr: u8,
    pub mcr: u8,
    pub lsr: u8,
    pub msr: u8,
    pub scr: u8,
    
    // Divisor
    pub dll: u8,
    pub dlm: u8,

    pub interrupting: bool,
    
    /// Internal state to track if THRE interrupt is pending (waiting for IIR read or THR write).
    /// This separates the "condition" (THR empty) from the "event" (Interrupt Pending).
    thre_ip: bool,
}

impl Uart {
    pub fn new() -> Self {
        Self {
            input: VecDeque::new(),
            output: VecDeque::new(),
            
            ier: 0x00,
            iir: 0x01, // Default: no interrupt pending
            fcr: 0x00,
            lcr: 0x00,
            mcr: 0x00,
            lsr: 0x60, // Transmitter Empty (bit 5) | Transmitter Holding Register Empty (bit 6)
            msr: 0x00,
            scr: 0x00,
            
            dll: 0x00,
            dlm: 0x00,

            interrupting: false,
            thre_ip: true, // Starts empty, so initial state could be pending if enabled
        }
    }

    pub fn update_interrupts(&mut self) {
        self.interrupting = false;
        self.iir = 0x01; // Default: no interrupt pending

        // Priority 1: Receiver Line Status (not implemented extensively)

        // Priority 2: Received Data Available
        if (self.lsr & 0x01) != 0 && (self.ier & 0x01) != 0 {
            self.interrupting = true;
            self.iir = 0x04; // Recieved Data Available
            return;
        }

        // Priority 3: Transmitter Holding Register Empty
        // Triggered if THR is empty AND IER bit 1 is set AND we haven't acknowledged it yet.
        if self.thre_ip && (self.ier & 0x02) != 0 {
             self.interrupting = true;
             self.iir = 0x02; // THRE
             return;
        }
        
        // Priority 4: Modem Status (not implemented)
    }

    pub fn load(&mut self, offset: u64, size: u64) -> Result<u64, MemoryError> {
        if size != 1 {
            // Some OS might try 4-byte reads, technically not allowed by spec but we can be lenient or strict.
            // Spec says 8-bit width. Let's return 0 for now if not byte access.
            return Ok(0);
        }

        let val = match offset {
            RBR => {
                if (self.lcr & 0x80) != 0 {
                    self.dll
                } else {
                    // RBR: Read from input FIFO
                    let byte = self.input.pop_front().unwrap_or(0);
                    // Update LSR: if more data, set bit 0, else clear it
                    if self.input.is_empty() {
                        self.lsr &= !0x01;
                    } else {
                        self.lsr |= 0x01;
                    }
                    self.update_interrupts();
                    byte
                }
            }
            IER => {
                if (self.lcr & 0x80) != 0 {
                    self.dlm
                } else {
                    self.ier
                }
            }
            IIR => {
                let val = self.iir;
                // Reading IIR clears THRE interrupt if it is the indicated interrupt
                if (val & 0x0F) == 0x02 {
                    self.thre_ip = false;
                    self.update_interrupts();
                    log::trace!("[UART] IIR read cleared THRE ip");
                } else {
                    log::trace!("[UART] IIR read val={:x} (thre_ip={})", val, self.thre_ip);
                }
                val
            }
            LCR => self.lcr,
            MCR => self.mcr,
            LSR => self.lsr,
            MSR => self.msr,
            SCR => self.scr,
            _ => 0,
        };

        Ok(val as u64)
    }

    pub fn store(&mut self, offset: u64, size: u64, value: u64) -> Result<(), MemoryError> {
        if size != 1 {
            return Ok(());
        }

        let val = (value & 0xff) as u8;

        match offset {
            THR => {
                if (self.lcr & 0x80) != 0 {
                    self.dll = val;
                } else {
                    // THR: Write to output
                    log::trace!(
                        "[UART] TX '{}' (0x{:02x})",
                        if val.is_ascii_graphic() {
                            val as char
                        } else {
                            '.'
                        },
                        val
                    );
                    self.output.push_back(val);
                    // We instantly "transmit", so THRE (bit 5) is always set.
                    // Writing to THR clears the THRE interrupt (if pending),
                    // but since it becomes empty immediately, we set thre_ip to true again?
                    // In real HW, it goes Not Empty -> Empty.
                    // So we should clear it, then re-assert it.
                    // For edge-triggered emulation, simply re-asserting is correct because we transitioned.
                    self.lsr |= 0x20; 
                    self.thre_ip = true; 
                    self.update_interrupts();
                }
            }
            IER => {
                if (self.lcr & 0x80) != 0 {
                    self.dlm = val;
                } else {
                    self.ier = val;
                    self.update_interrupts();
                }
            }
            FCR => {
                self.fcr = val;
                if (self.fcr & 0x02) != 0 {
                    self.input.clear();
                    self.lsr &= !0x01;
                }
                if (self.fcr & 0x04) != 0 {
                    self.output.clear();
                    self.lsr |= 0x60; // Empty
                }
                self.update_interrupts();
            }
            LCR => {
                self.lcr = val;
            }
            MCR => {
                self.mcr = val;
            }
            LSR => {
                // Usually read-only, but factory test mode might write. Ignore.
            }
            MSR => {
                // Read-only.
            }
            SCR => {
                self.scr = val;
            }
            _ => {}
        }
        Ok(())
    }

    // Interface for the Host
    pub fn push_input(&mut self, byte: u8) {
        self.input.push_back(byte);
        self.lsr |= 0x01; // Data Ready
        self.update_interrupts();
    }

    pub fn pop_output(&mut self) -> Option<u8> {
        self.output.pop_front()
    }
}
</file>

<file path="riscv-vm/src/virtio.rs">
use crate::dram::{Dram, MemoryError};
use crate::bus::DRAM_BASE;
use crate::net::NetworkBackend;

// MMIO register *values* expected by the xv6 VirtIO driver.
const MAGIC_VALUE: u64 = 0x7472_6976;
const VERSION: u64 = 2; // Legacy VirtIO MMIO version

const VENDOR_ID: u64 = 0x554d_4551;

// Common MMIO register offsets
const MAGIC_VALUE_OFFSET: u64 = 0x000;
const VERSION_OFFSET: u64 = 0x004;
const DEVICE_ID_OFFSET: u64 = 0x008;
const VENDOR_ID_OFFSET: u64 = 0x00c;
const DEVICE_FEATURES_OFFSET: u64 = 0x010;
const DEVICE_FEATURES_SEL_OFFSET: u64 = 0x014;
const DRIVER_FEATURES_OFFSET: u64 = 0x020;
const DRIVER_FEATURES_SEL_OFFSET: u64 = 0x024;
const GUEST_PAGE_SIZE_OFFSET: u64 = 0x028;
const QUEUE_SEL_OFFSET: u64 = 0x030;
const QUEUE_NUM_MAX_OFFSET: u64 = 0x034;
const QUEUE_NUM_OFFSET: u64 = 0x038;
const QUEUE_PFN_OFFSET: u64 = 0x040;
const QUEUE_READY_OFFSET: u64 = 0x044;
const QUEUE_NOTIFY_OFFSET: u64 = 0x050;
const INTERRUPT_STATUS_OFFSET: u64 = 0x060;
const INTERRUPT_ACK_OFFSET: u64 = 0x064;
const STATUS_OFFSET: u64 = 0x070;
const QUEUE_DESC_LOW_OFFSET: u64 = 0x080;
const QUEUE_DESC_HIGH_OFFSET: u64 = 0x084;
const QUEUE_DRIVER_LOW_OFFSET: u64 = 0x090;
const QUEUE_DRIVER_HIGH_OFFSET: u64 = 0x094;
const QUEUE_DEVICE_LOW_OFFSET: u64 = 0x0a0;
const QUEUE_DEVICE_HIGH_OFFSET: u64 = 0x0a4;
const CONFIG_GENERATION_OFFSET: u64 = 0x0fc;
const CONFIG_SPACE_OFFSET: u64 = 0x100;

// Device IDs
const VIRTIO_BLK_DEVICE_ID: u32 = 2;
const VIRTIO_NET_DEVICE_ID: u32 = 1;
const VIRTIO_RNG_DEVICE_ID: u32 = 4;
#[allow(dead_code)]
const VIRTIO_CONSOLE_DEVICE_ID: u32 = 3;

// VirtIO Block Features
#[allow(dead_code)]
const VIRTIO_BLK_F_SIZE_MAX: u64 = 1;
#[allow(dead_code)]
const VIRTIO_BLK_F_SEG_MAX: u64 = 2;
#[allow(dead_code)]
const VIRTIO_BLK_F_GEOMETRY: u64 = 4;
#[allow(dead_code)]
const VIRTIO_BLK_F_RO: u64 = 5;
#[allow(dead_code)]
const VIRTIO_BLK_F_BLK_SIZE: u64 = 6;
const VIRTIO_BLK_F_FLUSH: u64 = 9;

// VirtIO Net Features
const VIRTIO_NET_F_MAC: u64 = 5;           // Device has given MAC address
const VIRTIO_NET_F_STATUS: u64 = 16;       // Configuration status field available
#[allow(dead_code)]
const VIRTIO_NET_F_MRG_RXBUF: u64 = 15;    // Driver can merge receive buffers
#[allow(dead_code)]
const VIRTIO_NET_F_CSUM: u64 = 0;          // Device handles checksum
#[allow(dead_code)]
const VIRTIO_NET_F_GUEST_CSUM: u64 = 1;    // Driver handles checksum

// VirtIO Net Status bits
const VIRTIO_NET_S_LINK_UP: u16 = 1;

const QUEUE_SIZE: u32 = 16;

const VRING_DESC_F_NEXT: u64 = 1;
const VRING_DESC_F_WRITE: u64 = 2;

/// Trait for all VirtIO devices to implement.
pub trait VirtioDevice: Send {
    fn read(&mut self, offset: u64) -> Result<u64, MemoryError>;
    fn write(&mut self, offset: u64, val: u64, dram: &mut Dram) -> Result<(), MemoryError>;
    fn is_interrupting(&self) -> bool;
    fn device_id(&self) -> u32;
    fn reg_read_size(&self, _offset: u64) -> u64 {
        // Most registers are 4 bytes.
        // Config space (>= 0x100) might be different but for now we assume 4-byte access.
        4
    }
    
    /// Poll the device for any pending work (e.g., incoming network packets).
    /// This is called periodically by the emulator's main loop.
    /// Default implementation does nothing.
    fn poll(&mut self, _dram: &mut Dram) -> Result<(), MemoryError> {
        Ok(())
    }
}

pub struct VirtioBlock {
    driver_features: u32,
    driver_features_sel: u32,
    device_features_sel: u32,
    page_size: u32,
    queue_sel: u32,
    queue_num: u32,
    queue_desc: u64,
    queue_avail: u64,
    queue_used: u64,
    queue_ready: bool,
    interrupt_status: u32,
    status: u32,
    disk: Vec<u8>,
    last_avail_idx: u16,
    pub debug: bool,
}

impl VirtioBlock {
    pub fn new(disk_image: Vec<u8>) -> Self {
        Self {
            driver_features: 0,
            driver_features_sel: 0,
            device_features_sel: 0,
            page_size: 4096,
            queue_sel: 0,
            queue_num: 0,
            queue_desc: 0,
            queue_avail: 0,
            queue_used: 0,
            queue_ready: false,
            interrupt_status: 0,
            status: 0,
            disk: disk_image,
            last_avail_idx: 0,
            debug: false,
        }
    }

    fn phys_to_offset(&self, addr: u64) -> Result<u64, MemoryError> {
        if addr < DRAM_BASE {
            return Err(MemoryError::OutOfBounds(addr));
        }
        Ok(addr - DRAM_BASE)
    }

    fn process_queue(&mut self, dram: &mut Dram) -> Result<(), MemoryError> {
        let avail_idx_addr = self.queue_avail.wrapping_add(2);
        let avail_idx = dram.load_16(self.phys_to_offset(avail_idx_addr)?)? as u16;

        let mut processed_any = false;
        while self.last_avail_idx != avail_idx {
            let qsz = if self.queue_num > 0 { self.queue_num } else { QUEUE_SIZE };
            let ring_slot = (self.last_avail_idx as u32 % qsz) as u64;
            let head_idx_addr = self.queue_avail.wrapping_add(4).wrapping_add(ring_slot * 2);
            let head_desc_idx = dram.load_16(self.phys_to_offset(head_idx_addr)?)? as u16;

            if self.debug {
                 eprintln!("[VirtioBlock] Processing queue idx={} head_desc={}", self.last_avail_idx, head_desc_idx);
            }

            let desc_idx = head_desc_idx;

            let desc_addr0 = self.queue_desc.wrapping_add((desc_idx as u64) * 16);
            let off_desc_addr0 = self.phys_to_offset(desc_addr0)?;
            let header_addr = dram.load_64(off_desc_addr0)?;
            let header_len = dram.load_32(off_desc_addr0 + 8)?;
            let header_flags = dram.load_16(off_desc_addr0 + 12)? as u64;
            let mut next_desc_idx = dram.load_16(off_desc_addr0 + 14)?;

            if header_len < 16 {
                if self.debug {
                     eprintln!("[VirtioBlock] Header too short: {}", header_len);
                }
                // Consume malformed descriptor to avoid loop
                self.last_avail_idx = self.last_avail_idx.wrapping_add(1);
                processed_any = true;
                continue;
            }

            let off_header_addr = self.phys_to_offset(header_addr)?;
            let blk_type = dram.load_32(off_header_addr)?;
            let _blk_reserved = dram.load_32(off_header_addr + 4)?;
            let blk_sector = dram.load_64(off_header_addr + 8)?;

            if self.debug {
                 eprintln!("[VirtioBlock] Request type={} sector={}", blk_type, blk_sector);
            }

            let mut data_len_done: u32 = 0;

            if (header_flags & VRING_DESC_F_NEXT) != 0 {
                let desc2_addr = self.queue_desc.wrapping_add((next_desc_idx as u64) * 16);
                let off_desc2_addr = self.phys_to_offset(desc2_addr)?;
                let data_addr = dram.load_64(off_desc2_addr)?;
                let data_len = dram.load_32(off_desc2_addr + 8)?;
                let flags2 = dram.load_16(off_desc2_addr + 12)? as u64;
                next_desc_idx = dram.load_16(off_desc2_addr + 14)?;

                if blk_type == 0 { // IN (Read)
                    let offset = blk_sector * 512;
                    if offset + (data_len as u64) <= self.disk.len() as u64 {
                        let slice = &self.disk[offset as usize..(offset as usize + data_len as usize)];
                        dram.write_bytes(self.phys_to_offset(data_addr)?, slice)?;
                        data_len_done = data_len as u32;
                    }
                } else if blk_type == 1 { // OUT (Write)
                    let offset = blk_sector * 512;
                    if offset + (data_len as u64) <= self.disk.len() as u64 {
                        for i in 0..data_len {
                            let b = dram.load_8(self.phys_to_offset(data_addr + i as u64)?)? as u8;
                            self.disk[offset as usize + i as usize] = b;
                        }
                        data_len_done = data_len as u32;
                    }
                }

                if (flags2 & VRING_DESC_F_NEXT) != 0 {
                    let desc3_addr = self.queue_desc.wrapping_add((next_desc_idx as u64) * 16);
                    let off_desc3_addr = self.phys_to_offset(desc3_addr)?;
                    let status_addr = dram.load_64(off_desc3_addr)?;
                    dram.store_8(self.phys_to_offset(status_addr)?, 0)?; // Status: OK
                }
            }

            let used_idx_addr = self.queue_used.wrapping_add(2);
            let mut used_idx = dram.load_16(self.phys_to_offset(used_idx_addr)?)? as u16;
            let elem_addr = self.queue_used.wrapping_add(4).wrapping_add((used_idx as u64 % qsz as u64) * 8);
            let off_elem_addr = self.phys_to_offset(elem_addr)?;
            dram.store_32(off_elem_addr, head_desc_idx as u64)?;
            dram.store_32(off_elem_addr + 4, data_len_done as u64)?;
            used_idx = used_idx.wrapping_add(1);
            dram.store_16(self.phys_to_offset(used_idx_addr)?, used_idx as u64)?;

            self.last_avail_idx = self.last_avail_idx.wrapping_add(1);
            processed_any = true;
        }

        if processed_any {
            self.interrupt_status |= 1;
        }

        Ok(())
    }
}

impl VirtioDevice for VirtioBlock {
    fn device_id(&self) -> u32 {
        VIRTIO_BLK_DEVICE_ID
    }

    fn is_interrupting(&self) -> bool {
        self.interrupt_status != 0
    }

    fn read(&mut self, offset: u64) -> Result<u64, MemoryError> {
        let val = match offset {
            MAGIC_VALUE_OFFSET => MAGIC_VALUE,
            VERSION_OFFSET => VERSION,
            DEVICE_ID_OFFSET => VIRTIO_BLK_DEVICE_ID as u64,
            VENDOR_ID_OFFSET => VENDOR_ID,
            DEVICE_FEATURES_OFFSET => {
                if self.device_features_sel == 0 {
                    1u64 << VIRTIO_BLK_F_FLUSH
                } else {
                    0
                }
            }
            DEVICE_FEATURES_SEL_OFFSET => self.device_features_sel as u64,
            DRIVER_FEATURES_OFFSET => self.driver_features as u64,
            DRIVER_FEATURES_SEL_OFFSET => self.driver_features_sel as u64,
            GUEST_PAGE_SIZE_OFFSET => self.page_size as u64,
            QUEUE_NUM_MAX_OFFSET => QUEUE_SIZE as u64,
            QUEUE_SEL_OFFSET => self.queue_sel as u64,
            QUEUE_NUM_OFFSET => self.queue_num as u64,
            QUEUE_READY_OFFSET => if self.queue_ready { 1 } else { 0 },
            INTERRUPT_STATUS_OFFSET => self.interrupt_status as u64,
            STATUS_OFFSET => self.status as u64,
            CONFIG_GENERATION_OFFSET => 0,
            _ if offset >= 0x100 => {
                if offset == 0x100 {
                     let cap = self.disk.len() as u64 / 512;
                     cap & 0xffffffff
                } else if offset == 0x104 {
                     let cap = self.disk.len() as u64 / 512;
                     cap >> 32
                } else {
                    0
                }
            }
            _ => 0,
        };
        Ok(val)
    }

    fn write(&mut self, offset: u64, val: u64, dram: &mut Dram) -> Result<(), MemoryError> {
        let val32 = val as u32;

        match offset {
            DEVICE_FEATURES_SEL_OFFSET => { 
                self.device_features_sel = val32; 
            }
            DRIVER_FEATURES_OFFSET => { 
                self.driver_features = val32; 
            }
            DRIVER_FEATURES_SEL_OFFSET => { 
                self.driver_features_sel = val32; 
            }
            QUEUE_SEL_OFFSET => { 
                self.queue_sel = val32; 
            }
            QUEUE_NUM_OFFSET => { 
                self.queue_num = val32; 
            }
            GUEST_PAGE_SIZE_OFFSET => { 
                self.page_size = val32; 
            }
            QUEUE_PFN_OFFSET => {
                let pfn = val32 as u64;
                if pfn != 0 {
                    let desc = pfn * (self.page_size as u64);
                    self.queue_desc = desc;
                    self.queue_avail = desc + 16 * (self.queue_num as u64);
                    // Avail ring size: flags(2) + idx(2) + ring(2*n) + used_event(2) = 6 + 2*n
                    let avail_size = 6 + 2 * (self.queue_num as u64);
                    let used = (self.queue_avail + avail_size + (self.page_size as u64) - 1) & !((self.page_size as u64) - 1);
                    self.queue_used = used;
                    self.queue_ready = true;
                    if self.debug {
                        eprintln!("[VirtIO] Queue configured: desc=0x{:x} avail=0x{:x} used=0x{:x}", self.queue_desc, self.queue_avail, self.queue_used);
                    }
                }
            }
            QUEUE_READY_OFFSET => { 
                self.queue_ready = val32 != 0; 
            }
            QUEUE_NOTIFY_OFFSET => {
                if val32 == 0 {
                    self.process_queue(dram)?;
                }
            }
            INTERRUPT_ACK_OFFSET => {
                self.interrupt_status &= !val32;
            }
            STATUS_OFFSET => { 
                if val32 == 0 {
                    // Reset
                    self.status = 0;
                    self.queue_ready = false;
                    self.interrupt_status = 0;
                    self.last_avail_idx = 0;
                } else {
                    self.status = val32; 
                }
            }
            QUEUE_DESC_LOW_OFFSET => { 
                self.queue_desc = (self.queue_desc & 0xffffffff00000000) | (val32 as u64); 
            }
            QUEUE_DESC_HIGH_OFFSET => { 
                self.queue_desc = (self.queue_desc & 0x00000000ffffffff) | ((val32 as u64) << 32); 
            }
            QUEUE_DRIVER_LOW_OFFSET => { 
                self.queue_avail = (self.queue_avail & 0xffffffff00000000) | (val32 as u64); 
            }
            QUEUE_DRIVER_HIGH_OFFSET => { 
                self.queue_avail = (self.queue_avail & 0x00000000ffffffff) | ((val32 as u64) << 32); 
            }
            QUEUE_DEVICE_LOW_OFFSET => { 
                self.queue_used = (self.queue_used & 0xffffffff00000000) | (val32 as u64); 
            }
            QUEUE_DEVICE_HIGH_OFFSET => { 
                self.queue_used = (self.queue_used & 0x00000000ffffffff) | ((val32 as u64) << 32); 
            }
            _ => {}
        }
        Ok(())
    }
}

pub struct VirtioRng {
    driver_features: u32,
    driver_features_sel: u32,
    device_features_sel: u32,
    page_size: u32,
    queue_sel: u32,
    queue_num: u32,
    queue_desc: u64,
    queue_avail: u64,
    queue_used: u64,
    queue_ready: bool,
    interrupt_status: u32,
    status: u32,
    last_avail_idx: u16,
    pub debug: bool,
}

impl VirtioRng {
    pub fn new() -> Self {
        Self {
            driver_features: 0,
            driver_features_sel: 0,
            device_features_sel: 0,
            page_size: 4096,
            queue_sel: 0,
            queue_num: 0,
            queue_desc: 0,
            queue_avail: 0,
            queue_used: 0,
            queue_ready: false,
            interrupt_status: 0,
            status: 0,
            last_avail_idx: 0,
            debug: false,
        }
    }

    fn phys_to_offset(&self, addr: u64) -> Result<u64, MemoryError> {
        if addr < DRAM_BASE {
            return Err(MemoryError::OutOfBounds(addr));
        }
        Ok(addr - DRAM_BASE)
    }

    fn process_queue(&mut self, dram: &mut Dram) -> Result<(), MemoryError> {
        let avail_idx_addr = self.queue_avail.wrapping_add(2);
        let avail_idx = dram.load_16(self.phys_to_offset(avail_idx_addr)?)? as u16;

        let mut processed_any = false;
        while self.last_avail_idx != avail_idx {
            let ring_slot = (self.last_avail_idx as u32 % QUEUE_SIZE) as u64;
            let head_idx_addr = self.queue_avail.wrapping_add(4).wrapping_add(ring_slot * 2);
            let head_desc_idx = dram.load_16(self.phys_to_offset(head_idx_addr)?)? as u16;

            let desc_addr0 = self.queue_desc.wrapping_add((head_desc_idx as u64) * 16);
            let off_desc_addr0 = self.phys_to_offset(desc_addr0)?;
            let buffer_addr = dram.load_64(off_desc_addr0)?;
            let buffer_len = dram.load_32(off_desc_addr0 + 8)?;
            let flags = dram.load_16(off_desc_addr0 + 12)? as u64;

            if (flags & VRING_DESC_F_WRITE) != 0 {
                // Fill with pseudo-random data
                for i in 0..buffer_len {
                    dram.store_8(self.phys_to_offset(buffer_addr + i as u64)?, ((i as u8).wrapping_add(42)).into())?;
                }
            }

            let used_idx_addr = self.queue_used.wrapping_add(2);
            let mut used_idx = dram.load_16(self.phys_to_offset(used_idx_addr)?)? as u16;
            let elem_addr = self.queue_used.wrapping_add(4).wrapping_add((used_idx as u64 % QUEUE_SIZE as u64) * 8);
            let off_elem_addr = self.phys_to_offset(elem_addr)?;
            dram.store_32(off_elem_addr, head_desc_idx as u64)?;
            dram.store_32(off_elem_addr + 4, buffer_len as u64)?;
            used_idx = used_idx.wrapping_add(1);
            dram.store_16(self.phys_to_offset(used_idx_addr)?, used_idx as u64)?;

            self.last_avail_idx = self.last_avail_idx.wrapping_add(1);
            processed_any = true;
        }

        if processed_any {
            self.interrupt_status |= 1;
        }

        Ok(())
    }
}

impl VirtioDevice for VirtioRng {
    fn device_id(&self) -> u32 {
        VIRTIO_RNG_DEVICE_ID
    }

    fn is_interrupting(&self) -> bool {
        self.interrupt_status != 0
    }

    fn read(&mut self, offset: u64) -> Result<u64, MemoryError> {
        let val = match offset {
            MAGIC_VALUE_OFFSET => MAGIC_VALUE,
            VERSION_OFFSET => VERSION,
            DEVICE_ID_OFFSET => VIRTIO_RNG_DEVICE_ID as u64,
            VENDOR_ID_OFFSET => VENDOR_ID,
            DEVICE_FEATURES_OFFSET => 0,
            DEVICE_FEATURES_SEL_OFFSET => self.device_features_sel as u64,
            DRIVER_FEATURES_OFFSET => self.driver_features as u64,
            DRIVER_FEATURES_SEL_OFFSET => self.driver_features_sel as u64,
            GUEST_PAGE_SIZE_OFFSET => self.page_size as u64,
            QUEUE_NUM_MAX_OFFSET => QUEUE_SIZE as u64,
            QUEUE_SEL_OFFSET => self.queue_sel as u64,
            QUEUE_NUM_OFFSET => self.queue_num as u64,
            QUEUE_READY_OFFSET => if self.queue_ready { 1 } else { 0 },
            INTERRUPT_STATUS_OFFSET => self.interrupt_status as u64,
            STATUS_OFFSET => self.status as u64,
            CONFIG_GENERATION_OFFSET => 0,
            _ => 0,
        };
        Ok(val)
    }

    fn write(&mut self, offset: u64, val: u64, dram: &mut Dram) -> Result<(), MemoryError> {
        let val32 = val as u32;
        match offset {
            DEVICE_FEATURES_SEL_OFFSET => { self.device_features_sel = val32; }
            DRIVER_FEATURES_OFFSET => { self.driver_features = val32; }
            DRIVER_FEATURES_SEL_OFFSET => { self.driver_features_sel = val32; }
            QUEUE_SEL_OFFSET => { self.queue_sel = val32; }
            QUEUE_NUM_OFFSET => { self.queue_num = val32; }
            GUEST_PAGE_SIZE_OFFSET => { self.page_size = val32; }
            QUEUE_PFN_OFFSET => {
                let pfn = val32 as u64;
                if pfn != 0 {
                    let desc = pfn * (self.page_size as u64);
                    self.queue_desc = desc;
                    self.queue_avail = desc + 16 * (self.queue_num as u64);
                    // Avail ring size: flags(2) + idx(2) + ring(2*n) + used_event(2) = 6 + 2*n
                    let avail_size = 6 + 2 * (self.queue_num as u64);
                    let used = (self.queue_avail + avail_size + (self.page_size as u64) - 1) & !((self.page_size as u64) - 1);
                    self.queue_used = used;
                    self.queue_ready = true;
                }
            }
            QUEUE_READY_OFFSET => { self.queue_ready = val32 != 0; }
            QUEUE_NOTIFY_OFFSET => {
                if val32 == 0 {
                    self.process_queue(dram)?;
                }
            }
            INTERRUPT_ACK_OFFSET => {
                self.interrupt_status &= !val32;
            }
            STATUS_OFFSET => { 
                if val32 == 0 {
                    self.status = 0;
                    self.queue_ready = false;
                    self.interrupt_status = 0;
                    self.last_avail_idx = 0;
                } else {
                    self.status = val32; 
                }
            }
            QUEUE_DESC_LOW_OFFSET => { self.queue_desc = (self.queue_desc & 0xffffffff00000000) | (val32 as u64); }
            QUEUE_DESC_HIGH_OFFSET => { self.queue_desc = (self.queue_desc & 0x00000000ffffffff) | ((val32 as u64) << 32); }
            QUEUE_DRIVER_LOW_OFFSET => { self.queue_avail = (self.queue_avail & 0xffffffff00000000) | (val32 as u64); }
            QUEUE_DRIVER_HIGH_OFFSET => { self.queue_avail = (self.queue_avail & 0x00000000ffffffff) | ((val32 as u64) << 32); }
            QUEUE_DEVICE_LOW_OFFSET => { self.queue_used = (self.queue_used & 0xffffffff00000000) | (val32 as u64); }
            QUEUE_DEVICE_HIGH_OFFSET => { self.queue_used = (self.queue_used & 0x00000000ffffffff) | ((val32 as u64) << 32); }
            _ => {}
        }
        Ok(())
    }
}

/// VirtIO Network Queue state
struct NetQueue {
    num: u32,
    desc: u64,
    avail: u64,
    used: u64,
    ready: bool,
    last_avail_idx: u16,
}

impl NetQueue {
    fn new() -> Self {
        Self {
            num: 0,
            desc: 0,
            avail: 0,
            used: 0,
            ready: false,
            last_avail_idx: 0,
        }
    }
    
    fn reset(&mut self) {
        self.num = 0;
        self.desc = 0;
        self.avail = 0;
        self.used = 0;
        self.ready = false;
        self.last_avail_idx = 0;
    }
}

/// Network statistics for monitoring and debugging (Phase 5)
#[derive(Default)]
pub struct NetStats {
    /// Packets transmitted
    pub tx_packets: u64,
    /// Packets received and delivered to guest
    pub rx_packets: u64,
    /// TX errors (send failures)
    pub tx_errors: u64,
    /// RX errors (receive/delivery failures)
    pub rx_errors: u64,
    /// Packets dropped due to no available RX buffers
    pub rx_dropped: u64,
}

/// VirtIO Network Device
/// 
/// Implements a VirtIO network device that uses a NetworkBackend
/// for actual packet I/O. Supports RX (receive) and TX (transmit) queues.
/// 
/// Config space layout (starting at offset 0x100):
/// - 0x00-0x05: MAC address (6 bytes)
/// - 0x06-0x07: Status (2 bytes) - VIRTIO_NET_S_LINK_UP if negotiated
pub struct VirtioNet {
    // Standard VirtIO fields
    driver_features: u32,
    driver_features_sel: u32,
    device_features_sel: u32,
    page_size: u32,
    queue_sel: u32,
    interrupt_status: u32,
    status: u32,
    
    // Network specific
    mac: [u8; 6],
    backend: Box<dyn NetworkBackend>,
    
    // Queues: 0 = RX, 1 = TX
    rx_queue: NetQueue,  // Queue 0: receive queue (device writes to guest)
    tx_queue: NetQueue,  // Queue 1: transmit queue (guest writes to device)
    
    // Statistics (Phase 5)
    stats: NetStats,
    
    pub debug: bool,
}

impl VirtioNet {
    /// Create a new VirtIO network device with the given backend.
    pub fn new(mut backend: Box<dyn NetworkBackend>) -> Self {
        let mac = backend.mac_address();
        
        // Initialize the backend
        if let Err(e) = backend.init() {
            log::error!("[VirtioNet] Failed to initialize backend: {}", e);
        }
        
        Self {
            driver_features: 0,
            driver_features_sel: 0,
            device_features_sel: 0,
            page_size: 4096,
            queue_sel: 0,
            interrupt_status: 0,
            status: 0,
            mac,
            backend,
            rx_queue: NetQueue::new(),
            tx_queue: NetQueue::new(),
            stats: NetStats::default(),
            debug: false,
        }
    }
    
    /// Get network statistics (Phase 5)
    pub fn get_stats(&self) -> &NetStats {
        &self.stats
    }
    
    fn phys_to_offset(&self, addr: u64) -> Result<u64, MemoryError> {
        if addr < DRAM_BASE {
            return Err(MemoryError::OutOfBounds(addr));
        }
        Ok(addr - DRAM_BASE)
    }
    
    fn current_queue(&self) -> &NetQueue {
        match self.queue_sel {
            0 => &self.rx_queue,
            1 => &self.tx_queue,
            _ => &self.rx_queue, // Default to RX for invalid selections
        }
    }
    
    fn current_queue_mut(&mut self) -> &mut NetQueue {
        match self.queue_sel {
            0 => &mut self.rx_queue,
            1 => &mut self.tx_queue,
            _ => &mut self.rx_queue,
        }
    }
    
    /// Process the RX queue - check backend for incoming packets and deliver to guest.
    /// This processes ALL available packets in a single call.
    fn process_rx_queue(&mut self, dram: &mut Dram) -> Result<(), MemoryError> {
        // Check if queue is ready
        if !self.rx_queue.ready || self.rx_queue.desc == 0 {
            return Ok(());
        }
        
        let debug = self.debug;
        let mut packets_delivered = 0;
        
        // Process all available packets from the backend
        loop {
            // Poll the backend for incoming packets
            let packet = match self.backend.recv() {
                Ok(Some(pkt)) => {
                    log::debug!("[VirtioNet] Received {} byte packet from backend", pkt.len());
                    pkt
                }
                Ok(None) => break, // No more packets available
                Err(e) => {
                    log::warn!("[VirtioNet] RX backend error: {}", e);
                    self.stats.rx_errors += 1;
                    break;
                }
            };
            
            // Extract queue state
            let queue_avail = self.rx_queue.avail;
            let queue_desc = self.rx_queue.desc;
            let queue_used = self.rx_queue.used;
            let queue_num = self.rx_queue.num;
            let last_avail_idx = self.rx_queue.last_avail_idx;
            
            let avail_idx_addr = queue_avail.wrapping_add(2);
            let avail_idx = dram.load_16(self.phys_to_offset(avail_idx_addr)?)? as u16;
            
            if last_avail_idx == avail_idx {
                // No available buffers from guest - drop the packet
                log::warn!("[VirtioNet] No RX buffers available (last_avail={}, avail={}), dropping {} byte packet", 
                    last_avail_idx, avail_idx, packet.len());
                self.stats.rx_dropped += 1;
                // Don't break - the backend has already consumed this packet, continue to next
                continue;
            }
            
            let qsz = if queue_num > 0 { queue_num } else { QUEUE_SIZE };
            let ring_slot = (last_avail_idx as u32 % qsz) as u64;
            let head_idx_addr = queue_avail.wrapping_add(4).wrapping_add(ring_slot * 2);
            let head_desc_idx = dram.load_16(self.phys_to_offset(head_idx_addr)?)? as u16;
            
            if debug {
                log::debug!("[VirtioNet] RX: Processing buffer idx={} head_desc={} pkt_len={}", 
                    last_avail_idx, head_desc_idx, packet.len());
            }
            
            // Read first descriptor - should be writable (device writes to it)
            let desc_addr = queue_desc.wrapping_add((head_desc_idx as u64) * 16);
            let off_desc = self.phys_to_offset(desc_addr)?;
            let buffer_addr = dram.load_64(off_desc)?;
            let buffer_len = dram.load_32(off_desc + 8)? as usize;
            let flags = dram.load_16(off_desc + 12)? as u64;
            
            if debug {
                log::debug!("[VirtioNet] RX desc: desc_addr=0x{:x} buffer_addr=0x{:x} len={} flags=0x{:x}", 
                    desc_addr, buffer_addr, buffer_len, flags);
            }
            
            if (flags & VRING_DESC_F_WRITE) == 0 {
                log::warn!("[VirtioNet] RX descriptor not writable");
                self.rx_queue.last_avail_idx = last_avail_idx.wrapping_add(1);
                self.stats.rx_errors += 1;
                continue;
            }
            
            // VirtIO net header (12 bytes)
            let virtio_hdr = [0u8; 12]; // All zeros - no offloading features
            let total_len = virtio_hdr.len() + packet.len();
            
            if total_len > buffer_len {
                log::warn!("[VirtioNet] Packet too large for buffer ({} > {})", total_len, buffer_len);
                self.rx_queue.last_avail_idx = last_avail_idx.wrapping_add(1);
                self.stats.rx_dropped += 1;
                continue;
            }
            
            // Write virtio header + packet data to guest buffer
            let off_buffer = self.phys_to_offset(buffer_addr)?;
            dram.write_bytes(off_buffer, &virtio_hdr)?;
            dram.write_bytes(off_buffer + virtio_hdr.len() as u64, &packet)?;
            
            // Update used ring
            let used_idx_addr = queue_used.wrapping_add(2);
            let mut used_idx = dram.load_16(self.phys_to_offset(used_idx_addr)?)? as u16;
            let elem_addr = queue_used.wrapping_add(4).wrapping_add((used_idx as u64 % qsz as u64) * 8);
            let off_elem = self.phys_to_offset(elem_addr)?;
            dram.store_32(off_elem, head_desc_idx as u64)?;
            dram.store_32(off_elem + 4, total_len as u64)?;
            used_idx = used_idx.wrapping_add(1);
            dram.store_16(self.phys_to_offset(used_idx_addr)?, used_idx as u64)?;
            
            self.rx_queue.last_avail_idx = last_avail_idx.wrapping_add(1);
            self.stats.rx_packets += 1;
            packets_delivered += 1;
            
            log::debug!("[VirtioNet] RX: Delivered {} bytes to guest", total_len);
        }
        
        // Only raise interrupt if we delivered at least one packet
        if packets_delivered > 0 {
            self.interrupt_status |= 1;
            if debug {
                log::debug!("[VirtioNet] RX: Delivered {} packets total", packets_delivered);
            }
        }
        
        Ok(())
    }
    
    /// Process the TX queue - read packets from guest and send via backend.
    fn process_tx_queue(&mut self, dram: &mut Dram) -> Result<(), MemoryError> {
        if !self.tx_queue.ready || self.tx_queue.desc == 0 {
            return Ok(());
        }
        
        // Extract queue state to avoid borrow checker issues
        let queue_avail = self.tx_queue.avail;
        let queue_desc = self.tx_queue.desc;
        let queue_used = self.tx_queue.used;
        let queue_num = self.tx_queue.num;
        let mut last_avail_idx = self.tx_queue.last_avail_idx;
        let debug = self.debug;
        
        let avail_idx_addr = queue_avail.wrapping_add(2);
        let avail_idx = dram.load_16(self.phys_to_offset(avail_idx_addr)?)? as u16;
        
        let mut processed_any = false;
        while last_avail_idx != avail_idx {
            let qsz = if queue_num > 0 { queue_num } else { QUEUE_SIZE };
            let ring_slot = (last_avail_idx as u32 % qsz) as u64;
            let head_idx_addr = queue_avail.wrapping_add(4).wrapping_add(ring_slot * 2);
            let head_desc_idx = dram.load_16(self.phys_to_offset(head_idx_addr)?)? as u16;
            
            if debug {
                log::debug!("[VirtioNet] TX: Processing buffer idx={} head_desc={}", 
                    last_avail_idx, head_desc_idx);
            }
            
            // Collect all data from descriptor chain
            let mut packet_data = Vec::new();
            let mut desc_idx = head_desc_idx;
            let mut chain_limit = 16; // Prevent infinite loops
            
            while chain_limit > 0 {
                chain_limit -= 1;
                
                let desc_addr = queue_desc.wrapping_add((desc_idx as u64) * 16);
                let off_desc = self.phys_to_offset(desc_addr)?;
                let buffer_addr = dram.load_64(off_desc)?;
                let buffer_len = dram.load_32(off_desc + 8)? as usize;
                let flags = dram.load_16(off_desc + 12)? as u64;
                let next_idx = dram.load_16(off_desc + 14)? as u16;
                
                // Read data from this descriptor
                let off_buffer = self.phys_to_offset(buffer_addr)?;
                for i in 0..buffer_len {
                    let byte = dram.load_8(off_buffer + i as u64)? as u8;
                    packet_data.push(byte);
                }
                
                if (flags & VRING_DESC_F_NEXT) == 0 {
                    break;
                }
                desc_idx = next_idx;
            }
            
            // Skip the virtio_net_hdr (12 bytes) and send the actual packet
            if packet_data.len() > 12 {
                let actual_packet = &packet_data[12..];
                if let Err(e) = self.backend.send(actual_packet) {
                    log::warn!("[VirtioNet] TX backend error: {}", e);
                    self.stats.tx_errors += 1;
                } else {
                    self.stats.tx_packets += 1;
                    if debug {
                        log::debug!("[VirtioNet] TX: Sent {} byte packet (total: {})", 
                            actual_packet.len(), self.stats.tx_packets);
                    }
                }
            }
            
            // Update used ring
            let used_idx_addr = queue_used.wrapping_add(2);
            let mut used_idx = dram.load_16(self.phys_to_offset(used_idx_addr)?)? as u16;
            let elem_addr = queue_used.wrapping_add(4).wrapping_add((used_idx as u64 % qsz as u64) * 8);
            let off_elem = self.phys_to_offset(elem_addr)?;
            dram.store_32(off_elem, head_desc_idx as u64)?;
            dram.store_32(off_elem + 4, packet_data.len() as u64)?;
            used_idx = used_idx.wrapping_add(1);
            dram.store_16(self.phys_to_offset(used_idx_addr)?, used_idx as u64)?;
            
            last_avail_idx = last_avail_idx.wrapping_add(1);
            processed_any = true;
        }
        
        // Update the actual queue state
        self.tx_queue.last_avail_idx = last_avail_idx;
        
        if processed_any {
            self.interrupt_status |= 1;
        }
        
        Ok(())
    }
    
    /// Poll for incoming packets - should be called periodically.
    /// Also processes any completed TX buffers for proper flow control.
    pub fn poll(&mut self, dram: &mut Dram) -> Result<(), MemoryError> {
        // Process any completed TX buffers first (for flow control)
        self.process_tx_queue(dram)?;
        // Then deliver any incoming RX packets
        self.process_rx_queue(dram)
    }
}

impl VirtioDevice for VirtioNet {
    fn device_id(&self) -> u32 {
        VIRTIO_NET_DEVICE_ID
    }

    fn is_interrupting(&self) -> bool {
        self.interrupt_status != 0
    }

    fn read(&mut self, offset: u64) -> Result<u64, MemoryError> {
        let val = match offset {
            MAGIC_VALUE_OFFSET => MAGIC_VALUE,
            VERSION_OFFSET => VERSION,
            DEVICE_ID_OFFSET => VIRTIO_NET_DEVICE_ID as u64,
            VENDOR_ID_OFFSET => VENDOR_ID,
            DEVICE_FEATURES_OFFSET => {
                if self.device_features_sel == 0 {
                    // Feature bits 0-31
                    (1u64 << VIRTIO_NET_F_MAC) | (1u64 << VIRTIO_NET_F_STATUS)
                } else {
                    0
                }
            }
            DEVICE_FEATURES_SEL_OFFSET => self.device_features_sel as u64,
            DRIVER_FEATURES_OFFSET => self.driver_features as u64,
            DRIVER_FEATURES_SEL_OFFSET => self.driver_features_sel as u64,
            GUEST_PAGE_SIZE_OFFSET => self.page_size as u64,
            QUEUE_NUM_MAX_OFFSET => QUEUE_SIZE as u64,
            QUEUE_SEL_OFFSET => self.queue_sel as u64,
            QUEUE_NUM_OFFSET => self.current_queue().num as u64,
            QUEUE_READY_OFFSET => if self.current_queue().ready { 1 } else { 0 },
            INTERRUPT_STATUS_OFFSET => self.interrupt_status as u64,
            STATUS_OFFSET => self.status as u64,
            CONFIG_GENERATION_OFFSET => 0,
            // Config space: MAC address at 0x100-0x105, status at 0x106-0x107
            // VirtIO MMIO accesses are 32-bit aligned, so we pack bytes into 32-bit values
            _ if offset >= CONFIG_SPACE_OFFSET => {
                let config_offset = offset - CONFIG_SPACE_OFFSET;
                // Align to 4-byte boundary and return packed value
                let aligned = config_offset & !3;
                match aligned {
                    0 => {
                        // Bytes 0-3: MAC[0..4]
                        (self.mac[0] as u64) |
                        ((self.mac[1] as u64) << 8) |
                        ((self.mac[2] as u64) << 16) |
                        ((self.mac[3] as u64) << 24)
                    }
                    4 => {
                        // Bytes 4-7: MAC[4..6], Status[0..2]
                        (self.mac[4] as u64) |
                        ((self.mac[5] as u64) << 8) |
                        ((VIRTIO_NET_S_LINK_UP as u64) << 16)
                    }
                    _ => 0,
                }
            }
            _ => 0,
        };
        Ok(val)
    }

    fn write(&mut self, offset: u64, val: u64, dram: &mut Dram) -> Result<(), MemoryError> {
        let val32 = val as u32;
        
        match offset {
            DEVICE_FEATURES_SEL_OFFSET => { 
                self.device_features_sel = val32; 
            }
            DRIVER_FEATURES_OFFSET => { 
                self.driver_features = val32; 
            }
            DRIVER_FEATURES_SEL_OFFSET => { 
                self.driver_features_sel = val32; 
            }
            QUEUE_SEL_OFFSET => { 
                self.queue_sel = val32; 
            }
            QUEUE_NUM_OFFSET => { 
                self.current_queue_mut().num = val32; 
            }
            GUEST_PAGE_SIZE_OFFSET => { 
                self.page_size = val32; 
            }
            QUEUE_PFN_OFFSET => {
                let pfn = val32 as u64;
                if pfn != 0 {
                    let page_size = self.page_size as u64;
                    let queue_sel = self.queue_sel;
                    let queue = self.current_queue_mut();
                    let desc = pfn * page_size;
                    queue.desc = desc;
                    queue.avail = desc + 16 * (queue.num as u64);
                    // Avail ring size: flags(2) + idx(2) + ring(2*n) + used_event(2) = 6 + 2*n
                    let avail_size = 6 + 2 * (queue.num as u64);
                    let used = (queue.avail + avail_size + page_size - 1) & !(page_size - 1);
                    queue.used = used;
                    queue.ready = true;
                    log::debug!("[VirtioNet] Queue {} configured: pfn={} desc=0x{:x} avail=0x{:x} used=0x{:x} num={}", 
                        queue_sel, pfn, queue.desc, queue.avail, queue.used, queue.num);
                }
            }
            QUEUE_READY_OFFSET => { 
                self.current_queue_mut().ready = val32 != 0; 
            }
            QUEUE_NOTIFY_OFFSET => {
                // val32 is the queue index being notified
                match val32 {
                    0 => {
                        // RX queue notification - guest has provided new buffers
                        // We'll try to deliver any pending packets
                        self.process_rx_queue(dram)?;
                    }
                    1 => {
                        // TX queue notification - guest has packets to send
                        self.process_tx_queue(dram)?;
                    }
                    _ => {}
                }
            }
            INTERRUPT_ACK_OFFSET => {
                self.interrupt_status &= !val32;
            }
            STATUS_OFFSET => { 
                if val32 == 0 {
                    // Reset
                    self.status = 0;
                    self.rx_queue.reset();
                    self.tx_queue.reset();
                    self.interrupt_status = 0;
                } else {
                    self.status = val32; 
                }
            }
            QUEUE_DESC_LOW_OFFSET => { 
                let queue = self.current_queue_mut();
                queue.desc = (queue.desc & 0xffffffff00000000) | (val32 as u64); 
            }
            QUEUE_DESC_HIGH_OFFSET => { 
                let queue = self.current_queue_mut();
                queue.desc = (queue.desc & 0x00000000ffffffff) | ((val32 as u64) << 32); 
            }
            QUEUE_DRIVER_LOW_OFFSET => { 
                let queue = self.current_queue_mut();
                queue.avail = (queue.avail & 0xffffffff00000000) | (val32 as u64); 
            }
            QUEUE_DRIVER_HIGH_OFFSET => { 
                let queue = self.current_queue_mut();
                queue.avail = (queue.avail & 0x00000000ffffffff) | ((val32 as u64) << 32); 
            }
            QUEUE_DEVICE_LOW_OFFSET => { 
                let queue = self.current_queue_mut();
                queue.used = (queue.used & 0xffffffff00000000) | (val32 as u64); 
            }
            QUEUE_DEVICE_HIGH_OFFSET => { 
                let queue = self.current_queue_mut();
                queue.used = (queue.used & 0x00000000ffffffff) | ((val32 as u64) << 32); 
            }
            _ => {}
        }
        Ok(())
    }
    
    fn poll(&mut self, dram: &mut Dram) -> Result<(), MemoryError> {
        self.process_rx_queue(dram)
    }
}
</file>

<file path="riscv-vm/Cargo.toml">
[package]
name = "riscv-vm"
version = "0.1.0"
edition = "2021"

[lib]
crate-type = ["cdylib", "rlib"]

[dependencies]
log = "0.4"
thiserror = "1.0"
hex = "0.4"
env_logger = "0.10"
clap = { version = "4.4", features = ["derive"] }
libc = "0.2"
goblin = "0.8"
serde = { version = "1.0", features = ["derive"] }
bincode = "1.3"
sha2 = "0.10"
wasm-bindgen = "0.2"

[target.'cfg(not(target_arch = "wasm32"))'.dependencies]
tun-tap = "0.1"
tungstenite = "0.21"
# libp2p for connecting to the QUIC relay
libp2p = { version = "0.54", features = [
    "tokio",
    "quic",
    "tcp",
    "relay",
    "identify",
    "ping",
    "gossipsub",
    "noise",
    "yamux",
    "macros",
] }
tokio = { version = "1", features = ["full"] }
futures = "0.3"

[target.'cfg(target_arch = "wasm32")'.dependencies]
console_error_panic_hook = "0.1"
web-sys = { version = "0.3", features = ["WebSocket", "MessageEvent", "BinaryType", "ErrorEvent", "CloseEvent"] }
js-sys = "0.3"
wasm-bindgen-futures = "0.4"
</file>

<file path="relay/.dockerignore">
target/
</file>

<file path="relay/app.json">
{
    "schemaVersion": 2,
    "dockerfilePath": "./Dockerfile",
    "args": {
      "NODE_ENV": "production"
    }
  }
</file>

<file path="relay/Cargo.toml">
[package]
name = "relay"
version = "0.1.0"
edition = "2021"
description = "libp2p QUIC relay server for NAT traversal and peer connectivity"

[dependencies]
# libp2p with required features for relay functionality
libp2p = { version = "0.54", features = [
    "tokio",
    "quic",
    "relay",
    "dcutr",
    "identify",
    "ping",
    "gossipsub",
    "noise",
    "yamux",
    "macros",
    "tcp",
    "dns",
    "websocket",
    "request-response",
    "cbor",
    "kad",
    "autonat",
] }

# Async runtime
tokio = { version = "1", features = ["full"] }
futures = "0.3"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# CLI
clap = { version = "4.4", features = ["derive"] }

# Serialization for messages
serde = { version = "1.0", features = ["derive"] }

# Error handling
anyhow = "1.0"
thiserror = "1.0"

# Utilities
rand = "0.8"
base64 = "0.22"
hex = "0.4"

# For peer ID generation
bs58 = "0.5"
</file>

<file path="relay/Dockerfile">
# Multi-stage build for smaller final image
FROM rust:1.82-slim-bookworm AS builder

# Install build dependencies
RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /usr/src/relay

# Copy manifests first for better caching
COPY Cargo.toml Cargo.lock* ./

# Create a dummy main.rs to build dependencies
RUN mkdir -p src && \
    echo "fn main() {}" > src/main.rs

# Build dependencies only (this layer will be cached)
RUN cargo build --release && rm -rf src

# Copy the actual source code
COPY src ./src

# Build the release binary (touch to ensure rebuild)
RUN touch src/main.rs && cargo build --release

# Runtime stage - minimal image
FROM debian:bookworm-slim

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl3 \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy the binary from builder
COPY --from=builder /usr/src/relay/target/release/relay /app/relay

# Expose ports:
# 4001/udp - QUIC transport
# 4002     - TCP transport
EXPOSE 4001/udp
EXPOSE 4002

# Default environment
ENV RUST_LOG=info

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD pgrep -x relay || exit 1

# Run the relay server
# --bind 0.0.0.0 ensures it listens on all interfaces in container
CMD ["/app/relay", "--bind", "0.0.0.0", "--port", "4001", "--tcp-port", "4002"]
</file>

<file path="relay/src/main.rs">
//! libp2p QUIC Relay Service
//!
//! A relay server that enables NAT traversal and peer connectivity for:
//! - Server to server (direct QUIC)
//! - Browser to server (WebSocket to QUIC bridge)
//! - Browser to browser (via relay + DCUtR hole punching)
//! - NAT traversal (circuit relay v2 + DCUtR)
//!
//! Usage:
//!   cargo run --release -- --port 4001
//!
//! Features:
//! - QUIC transport for efficient, secure connections
//! - TCP + WebSocket for browser compatibility
//! - Circuit Relay v2 for NAT traversal
//! - DCUtR for direct connection upgrade (hole punching)
//! - Kademlia DHT for peer discovery
//! - AutoNAT for NAT detection
//! - Gossipsub for pub/sub messaging

use anyhow::Result;
use clap::Parser;
use futures::StreamExt;
use libp2p::{
    autonat,
    dcutr,
    gossipsub::{self, IdentTopic, MessageAuthenticity},
    identify,
    identity::Keypair,
    kad::{self, store::MemoryStore, Mode as KadMode},
    noise,
    ping,
    relay,
    request_response::{self, ProtocolSupport},
    swarm::{NetworkBehaviour, SwarmEvent},
    tcp, yamux, Multiaddr, PeerId, StreamProtocol, Swarm, SwarmBuilder,
};
use serde::{Deserialize, Serialize};
use std::{
    collections::{HashMap, HashSet},
    error::Error,
    time::Duration,
};
use tracing::{debug, error, info, warn};
use tracing_subscriber::EnvFilter;

#[derive(Parser, Debug)]
#[command(
    author,
    version,
    about = "libp2p QUIC Relay Server for NAT traversal and peer connectivity"
)]
struct Args {
    /// QUIC port to listen on
    #[arg(short, long, default_value_t = 4001)]
    port: u16,

    /// TCP port for connections
    #[arg(long, default_value_t = 4002)]
    tcp_port: u16,

    /// Bind address
    #[arg(short, long, default_value = "0.0.0.0")]
    bind: String,

    /// External address to announce (for servers behind NAT/load balancer)
    #[arg(long)]
    external_addr: Option<String>,

    /// Enable verbose logging
    #[arg(short, long)]
    verbose: bool,

    /// Relay reservation duration in seconds
    #[arg(long, default_value_t = 3600)]
    reservation_duration: u64,

    /// Maximum number of relay reservations
    #[arg(long, default_value_t = 1024)]
    max_reservations: usize,

    /// Maximum circuits per peer
    #[arg(long, default_value_t = 16)]
    max_circuits_per_peer: usize,
}

/// Custom protocol for application-level messages
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum RelayMessage {
    /// Broadcast data to all peers in a topic
    Broadcast { topic: String, data: Vec<u8> },
    /// Direct message to a specific peer
    Direct { data: Vec<u8> },
    /// Peer discovery request
    DiscoverPeers,
    /// Peer list response
    PeerList { peers: Vec<String> },
}

/// Combined network behaviour for the relay
#[derive(NetworkBehaviour)]
struct RelayServerBehaviour {
    /// Circuit relay v2 (server mode) for NAT traversal
    relay: relay::Behaviour,

    /// DCUtR for direct connection upgrade after relay
    dcutr: dcutr::Behaviour,

    /// Identify protocol for peer info exchange
    identify: identify::Behaviour,

    /// Ping for connection liveness
    ping: ping::Behaviour,

    /// Kademlia DHT for peer discovery
    kademlia: kad::Behaviour<MemoryStore>,

    /// AutoNAT for NAT detection
    autonat: autonat::Behaviour,

    /// Gossipsub for pub/sub messaging
    gossipsub: gossipsub::Behaviour,

    /// Request-response for direct messaging
    request_response: request_response::cbor::Behaviour<RelayMessage, RelayMessage>,
}

/// Relay server state
struct RelayServer {
    /// The libp2p swarm
    swarm: Swarm<RelayServerBehaviour>,

    /// Connected peers
    connected_peers: HashSet<PeerId>,

    /// Peer addresses for routing
    peer_addresses: HashMap<PeerId, Vec<Multiaddr>>,

    /// Active relay reservations
    reservations: HashSet<PeerId>,

    /// Topics we're subscribed to
    topics: HashSet<String>,
}

impl RelayServer {
    /// Create a new relay server
    async fn new(args: &Args) -> Result<Self> {
        // Generate a persistent keypair (in production, load from file)
        let local_key = Keypair::generate_ed25519();
        let local_peer_id = PeerId::from(local_key.public());
        info!("Local peer ID: {}", local_peer_id);

        // Build the swarm with TCP and QUIC transports
        let swarm = SwarmBuilder::with_existing_identity(local_key.clone())
            .with_tokio()
            .with_tcp(
                tcp::Config::default(),
                noise::Config::new,
                yamux::Config::default,
            )?
            .with_quic()
            .with_dns()?
            .with_behaviour(|keypair| {
                // Relay behaviour configuration
                let relay_config = relay::Config {
                    reservation_duration: Duration::from_secs(args.reservation_duration),
                    max_reservations: args.max_reservations,
                    max_circuits_per_peer: args.max_circuits_per_peer,
                    ..Default::default()
                };

                // Identify configuration
                let identify = identify::Behaviour::new(identify::Config::new(
                    "/riscv-relay/1.0.0".to_string(),
                    keypair.public(),
                ));

                // Kademlia configuration for DHT
                let store = MemoryStore::new(keypair.public().to_peer_id());
                let mut kademlia_config = kad::Config::new(StreamProtocol::new("/riscv-kad/1.0.0"));
                kademlia_config.set_query_timeout(Duration::from_secs(60));
                let mut kademlia = kad::Behaviour::with_config(
                    keypair.public().to_peer_id(),
                    store,
                    kademlia_config,
                );
                kademlia.set_mode(Some(KadMode::Server));

                // Gossipsub configuration
                let gossipsub_config = gossipsub::ConfigBuilder::default()
                    .heartbeat_interval(Duration::from_secs(10))
                    .validation_mode(gossipsub::ValidationMode::Strict)
                    .message_id_fn(|msg| {
                        // Use content hash as message ID for deduplication
                        let mut hasher = std::collections::hash_map::DefaultHasher::new();
                        std::hash::Hash::hash(&msg.data, &mut hasher);
                        std::hash::Hash::hash(&msg.source, &mut hasher);
                        gossipsub::MessageId::from(
                            std::hash::Hasher::finish(&hasher).to_string(),
                        )
                    })
                    .build()
                    .expect("Valid gossipsub config");

                let gossipsub = gossipsub::Behaviour::new(
                    MessageAuthenticity::Signed(keypair.clone()),
                    gossipsub_config,
                )
                .expect("Valid gossipsub behaviour");

                // Request-response for direct messaging
                let request_response = request_response::cbor::Behaviour::new(
                    [(StreamProtocol::new("/riscv-relay/msg/1.0.0"), ProtocolSupport::Full)],
                    request_response::Config::default(),
                );

                // AutoNAT configuration
                let autonat = autonat::Behaviour::new(
                    keypair.public().to_peer_id(),
                    autonat::Config {
                        only_global_ips: false,
                        ..Default::default()
                    },
                );

                RelayServerBehaviour {
                    relay: relay::Behaviour::new(keypair.public().to_peer_id(), relay_config),
                    dcutr: dcutr::Behaviour::new(keypair.public().to_peer_id()),
                    identify,
                    ping: ping::Behaviour::new(ping::Config::new()),
                    kademlia,
                    autonat,
                    gossipsub,
                    request_response,
                }
            })?
            .with_swarm_config(|cfg| {
                cfg.with_idle_connection_timeout(Duration::from_secs(60))
            })
            .build();

        Ok(Self {
            swarm,
            connected_peers: HashSet::new(),
            peer_addresses: HashMap::new(),
            reservations: HashSet::new(),
            topics: HashSet::new(),
        })
    }

    /// Get the local peer ID
    fn local_peer_id(&self) -> PeerId {
        *self.swarm.local_peer_id()
    }

    /// Start listening on configured addresses
    fn start_listening(&mut self, args: &Args) -> Result<()> {
        // Listen on TCP
        let tcp_addr: Multiaddr = format!("/ip4/{}/tcp/{}", args.bind, args.tcp_port).parse()?;
        self.swarm.listen_on(tcp_addr.clone())?;
        info!("Listening on TCP: {}", tcp_addr);

        // Listen on QUIC
        let quic_addr: Multiaddr = format!(
            "/ip4/{}/udp/{}/quic-v1",
            args.bind,
            args.port
        )
        .parse()?;
        self.swarm.listen_on(quic_addr.clone())?;
        info!("Listening on QUIC: {}", quic_addr);

        // Add external address if specified
        if let Some(ref external) = args.external_addr {
            let external_addr: Multiaddr = external.parse()?;
            self.swarm.add_external_address(external_addr.clone());
            info!("Announced external address: {}", external_addr);
        }

        Ok(())
    }

    /// Subscribe to a gossipsub topic
    fn subscribe(&mut self, topic: &str) -> Result<()> {
        let topic = IdentTopic::new(topic);
        self.swarm.behaviour_mut().gossipsub.subscribe(&topic)?;
        self.topics.insert(topic.to_string());
        info!("Subscribed to topic: {}", topic);
        Ok(())
    }

    /// Publish a message to a gossipsub topic
    fn publish(&mut self, topic: &str, data: Vec<u8>) -> Result<()> {
        let topic = IdentTopic::new(topic);
        self.swarm
            .behaviour_mut()
            .gossipsub
            .publish(topic, data)?;
        Ok(())
    }

    /// Run the relay server event loop
    async fn run(mut self) -> Result<()> {
        // Subscribe to default topics
        self.subscribe("riscv-vm")?;
        self.subscribe("relay-announce")?;

        loop {
            match self.swarm.select_next_some().await {
                SwarmEvent::NewListenAddr { address, .. } => {
                    let peer_id = *self.swarm.local_peer_id();
                    let full_addr = format!("{}/p2p/{}", address, peer_id);
                    info!("New listening address: {}", full_addr);
                }

                SwarmEvent::ConnectionEstablished {
                    peer_id,
                    endpoint,
                    num_established,
                    ..
                } => {
                    info!(
                        "Connection established with {} via {:?} (total: {})",
                        peer_id,
                        endpoint.get_remote_address(),
                        num_established
                    );
                    self.connected_peers.insert(peer_id);
                    self.peer_addresses
                        .entry(peer_id)
                        .or_default()
                        .push(endpoint.get_remote_address().clone());
                }

                SwarmEvent::ConnectionClosed {
                    peer_id,
                    num_established,
                    cause,
                    ..
                } => {
                    if num_established == 0 {
                        info!("Connection closed with {} (cause: {:?})", peer_id, cause);
                        self.connected_peers.remove(&peer_id);
                        self.peer_addresses.remove(&peer_id);
                    }
                }

                SwarmEvent::Behaviour(event) => {
                    self.handle_behaviour_event(event).await;
                }

                SwarmEvent::IncomingConnection { local_addr, .. } => {
                    debug!("Incoming connection on {}", local_addr);
                }

                SwarmEvent::OutgoingConnectionError { peer_id, error, .. } => {
                    if let Some(peer) = peer_id {
                        warn!("Outgoing connection error to {}: {}", peer, error);
                    }
                }

                SwarmEvent::IncomingConnectionError { local_addr, error, .. } => {
                    warn!("Incoming connection error on {}: {}", local_addr, error);
                }

                event => {
                    debug!("Unhandled swarm event: {:?}", event);
                }
            }
        }
    }

    /// Handle behaviour-specific events
    async fn handle_behaviour_event(&mut self, event: RelayServerBehaviourEvent) {
        match event {
            RelayServerBehaviourEvent::Relay(relay_event) => {
                self.handle_relay_event(relay_event);
            }

            RelayServerBehaviourEvent::Dcutr(dcutr_event) => {
                self.handle_dcutr_event(dcutr_event);
            }

            RelayServerBehaviourEvent::Identify(identify_event) => {
                self.handle_identify_event(identify_event);
            }

            RelayServerBehaviourEvent::Ping(ping_event) => {
                if let ping::Event { peer, result: Ok(rtt), .. } = ping_event {
                    debug!("Ping to {} succeeded: {:?}", peer, rtt);
                }
            }

            RelayServerBehaviourEvent::Kademlia(kad_event) => {
                self.handle_kademlia_event(kad_event);
            }

            RelayServerBehaviourEvent::Autonat(autonat_event) => {
                self.handle_autonat_event(autonat_event);
            }

            RelayServerBehaviourEvent::Gossipsub(gossipsub_event) => {
                self.handle_gossipsub_event(gossipsub_event);
            }

            RelayServerBehaviourEvent::RequestResponse(rr_event) => {
                self.handle_request_response_event(rr_event);
            }
        }
    }

    fn handle_relay_event(&mut self, event: relay::Event) {
        match event {
            relay::Event::ReservationReqAccepted { src_peer_id, .. } => {
                info!("Relay reservation accepted for {}", src_peer_id);
                self.reservations.insert(src_peer_id);
            }

            relay::Event::ReservationReqDenied { src_peer_id } => {
                warn!("Relay reservation denied for {}", src_peer_id);
            }

            relay::Event::ReservationTimedOut { src_peer_id } => {
                info!("Relay reservation timed out for {}", src_peer_id);
                self.reservations.remove(&src_peer_id);
            }

            relay::Event::CircuitReqAccepted { src_peer_id, dst_peer_id, .. } => {
                info!(
                    "Circuit established: {} -> {} (via relay)",
                    src_peer_id, dst_peer_id
                );
            }

            relay::Event::CircuitReqDenied { src_peer_id, dst_peer_id } => {
                warn!(
                    "Circuit request denied: {} -> {}",
                    src_peer_id, dst_peer_id
                );
            }

            relay::Event::CircuitClosed { src_peer_id, dst_peer_id, .. } => {
                debug!(
                    "Circuit closed: {} -> {}",
                    src_peer_id, dst_peer_id
                );
            }

            _ => {}
        }
    }

    fn handle_dcutr_event(&mut self, event: dcutr::Event) {
        // dcutr::Event is a struct with remote_peer_id and result
        let dcutr::Event { remote_peer_id, result } = event;
        match result {
            Ok(connection_id) => {
                info!(
                    "DCUtR: Direct connection established with {} (connection: {:?}, hole punch success!)",
                    remote_peer_id, connection_id
                );
            }
            Err(error) => {
                warn!(
                    "DCUtR: Failed to establish direct connection with {}: {:?}",
                    remote_peer_id, error
                );
            }
        }
    }

    fn handle_identify_event(&mut self, event: identify::Event) {
        match event {
            identify::Event::Received { peer_id, info, .. } => {
                debug!(
                    "Identified peer {}: {} {:?}",
                    peer_id, info.protocol_version, info.listen_addrs
                );

                // Add peer's addresses to Kademlia
                for addr in info.listen_addrs {
                    self.swarm
                        .behaviour_mut()
                        .kademlia
                        .add_address(&peer_id, addr);
                }
            }

            identify::Event::Sent { peer_id, .. } => {
                debug!("Sent identify info to {}", peer_id);
            }

            _ => {}
        }
    }

    fn handle_kademlia_event(&mut self, event: kad::Event) {
        match event {
            kad::Event::RoutingUpdated {
                peer, is_new_peer, ..
            } => {
                if is_new_peer {
                    debug!("Kademlia: Added new peer {} to routing table", peer);
                }
            }

            kad::Event::OutboundQueryProgressed { result, .. } => {
                if let kad::QueryResult::GetClosestPeers(Ok(ok)) = result {
                    debug!("Kademlia: Found {} closest peers", ok.peers.len());
                }
            }

            _ => {}
        }
    }

    fn handle_autonat_event(&mut self, event: autonat::Event) {
        match event {
            autonat::Event::StatusChanged { old, new } => {
                info!("AutoNAT status changed: {:?} -> {:?}", old, new);
                match new {
                    autonat::NatStatus::Public(addr) => {
                        info!("NAT Status: Public at {}", addr);
                    }
                    autonat::NatStatus::Private => {
                        info!("NAT Status: Private (behind NAT)");
                    }
                    autonat::NatStatus::Unknown => {
                        info!("NAT Status: Unknown");
                    }
                }
            }

            autonat::Event::InboundProbe(probe) => {
                debug!("AutoNAT inbound probe: {:?}", probe);
            }

            autonat::Event::OutboundProbe(probe) => {
                debug!("AutoNAT outbound probe: {:?}", probe);
            }
        }
    }

    fn handle_gossipsub_event(&mut self, event: gossipsub::Event) {
        match event {
            gossipsub::Event::Message {
                propagation_source,
                message_id,
                message,
            } => {
                info!(
                    "Gossipsub message from {}: topic={}, id={}, {} bytes",
                    propagation_source,
                    message.topic,
                    message_id,
                    message.data.len()
                );

                // Handle the message (in a real app, parse and process)
                debug!("Message data: {:?}", String::from_utf8_lossy(&message.data));
            }

            gossipsub::Event::Subscribed { peer_id, topic } => {
                info!("Peer {} subscribed to {}", peer_id, topic);
            }

            gossipsub::Event::Unsubscribed { peer_id, topic } => {
                info!("Peer {} unsubscribed from {}", peer_id, topic);
            }

            _ => {}
        }
    }

    fn handle_request_response_event(
        &mut self,
        event: request_response::Event<RelayMessage, RelayMessage>,
    ) {
        match event {
            request_response::Event::Message { peer, message } => match message {
                request_response::Message::Request {
                    request, channel, ..
                } => {
                    info!("Request from {}: {:?}", peer, request);

                    // Handle the request
                    let response = match request {
                        RelayMessage::DiscoverPeers => RelayMessage::PeerList {
                            peers: self.connected_peers.iter().map(|p| p.to_string()).collect(),
                        },
                        RelayMessage::Broadcast { topic, data } => {
                            // Publish to gossipsub
                            if let Err(e) = self.publish(&topic, data) {
                                error!("Failed to publish: {}", e);
                            }
                            RelayMessage::Direct {
                                data: b"OK".to_vec(),
                            }
                        }
                        _ => RelayMessage::Direct {
                            data: b"OK".to_vec(),
                        },
                    };

                    // Send response
                    if let Err(e) = self
                        .swarm
                        .behaviour_mut()
                        .request_response
                        .send_response(channel, response)
                    {
                        error!("Failed to send response: {:?}", e);
                    }
                }

                request_response::Message::Response { response, .. } => {
                    debug!("Response from {}: {:?}", peer, response);
                }
            },

            request_response::Event::OutboundFailure { peer, error, .. } => {
                warn!("Outbound request to {} failed: {:?}", peer, error);
            }

            request_response::Event::InboundFailure { peer, error, .. } => {
                warn!("Inbound request from {} failed: {:?}", peer, error);
            }

            _ => {}
        }
    }
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    // Initialize logging
    tracing_subscriber::fmt()
        .with_env_filter(
            EnvFilter::try_from_default_env().unwrap_or_else(|_| EnvFilter::new("info")),
        )
        .init();

    let args = Args::parse();

    info!("Starting libp2p QUIC Relay Server...");
    info!("QUIC port: {}", args.port);
    info!("TCP port: {}", args.tcp_port);

    // Create and configure the relay server
    let mut server = RelayServer::new(&args).await?;
    server.start_listening(&args)?;

    // Get peer ID for connection strings
    let peer_id = server.local_peer_id();

    // Print connection info
    println!();
    println!("");
    println!("                    libp2p QUIC Relay Server for RISC-V VM                      ");
    println!("");
    println!("  Peer ID: {}  ", peer_id);
    println!("");
    println!("  Connect via QUIC (recommended):                                               ");
    println!("    /ip4/127.0.0.1/udp/{}/quic-v1/p2p/{}", args.port, peer_id);
    println!("                                                                                ");
    println!("  Connect via TCP:                                                              ");
    println!("    /ip4/127.0.0.1/tcp/{}/p2p/{}", args.tcp_port, peer_id);
    println!("");
    println!("  Features: Circuit Relay v2  DCUtR  Kademlia DHT  Gossipsub  AutoNAT       ");
    println!("");
    println!();

    // Run the server
    server.run().await?;

    Ok(())
}
</file>

</files>
